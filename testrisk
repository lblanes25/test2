import pandas as pd
import re

# =============================================================================
# CONFIGURATION - UPDATE YOUR FILE/COLUMN NAMES HERE
# =============================================================================

# Input file names
RISKS_FILE = "audit_entity_risks.xlsx"
KPA_FILE = "kpa_tagging.xlsx"

# Sheet names
RISKS_SHEET = 0
KPA_SHEET = 0

# Column names in RISKS file (case-insensitive matching will be applied)
RISKS_AE_ID_COL = "Audit Entity ID"
RISKS_IT_COL = "Information Technology Inherent Risk"
RISKS_IS_COL = "Information Security Inherent Risk"
RISKS_PRIMARY_APPS_COL = "Primary IT applications (mapped)"
RISKS_SECONDARY_APPS_COL = "Secondary IT applications (Related or Relied on)"
RISKS_CORE_TEAM_COL = "Core Audit Team"
RISKS_AUDIT_LEADER_COL = "Audit Leader"

# Column names in KPA file (case-insensitive matching will be applied)
KPA_AE_ID_COL = "Audit Entity ID"
KPA_ID_COL = "KPA ID"
KPA_KEY_APPS_COL = "KEY PRIMARY & SECONDARY IT applications"

# Output file names - ORGANIZED BY OBSERVATION
OUTPUT_OBSERVATION_1 = "Observation1_GhostApps.xlsx"
OUTPUT_OBSERVATION_2 = "Observation2_PrimaryNotKey.xlsx"
OUTPUT_OBSERVATION_3 = "Observation3_SecondaryNotKey.xlsx"
OUTPUT_OBSERVATION_4 = "Observation4_AutomationFailures.xlsx"
OUTPUT_EXECUTIVE_SUMMARY = "00_ExecutiveSummary.xlsx"
OUTPUT_FULL_ANALYSIS = "SourceData_FullAnalysis.xlsx"

# Risk values that indicate the risk IS applicable
RISK_APPLICABLE_VALUES = ['Critical', 'High', 'Medium', 'Low']

# =============================================================================
# LOAD DATA
# =============================================================================

print("="*70)
print("LOADING DATA")
print("="*70)

risks_df = pd.read_excel(RISKS_FILE, sheet_name=RISKS_SHEET)
kpa_df = pd.read_excel(KPA_FILE, sheet_name=KPA_SHEET)

print(f"‚úì Loaded {len(risks_df)} audit entities from risks file")
print(f"‚úì Loaded {len(kpa_df)} KPA records")
print()

# =============================================================================
# HELPER FUNCTION: CASE-INSENSITIVE COLUMN MATCHING
# =============================================================================

def find_column(df, target_col, optional=False):
    """
    Find a column in the dataframe using case-insensitive matching.
    Returns the actual column name from the dataframe.
    If optional=True, returns None if column not found.
    """
    if target_col is None:
        return None
        
    col_map = {col.lower().strip(): col for col in df.columns}
    actual_col = col_map.get(target_col.lower().strip())
    
    if actual_col is None and not optional:
        raise ValueError(f"Column '{target_col}' not found in dataframe. Available columns: {list(df.columns)}")
    
    return actual_col

# Map configured column names to actual column names
RISKS_AE_ID_ACTUAL = find_column(risks_df, RISKS_AE_ID_COL)
RISKS_IT_ACTUAL = find_column(risks_df, RISKS_IT_COL)
RISKS_IS_ACTUAL = find_column(risks_df, RISKS_IS_COL)
RISKS_PRIMARY_APPS_ACTUAL = find_column(risks_df, RISKS_PRIMARY_APPS_COL)
RISKS_SECONDARY_APPS_ACTUAL = find_column(risks_df, RISKS_SECONDARY_APPS_COL)
RISKS_CORE_TEAM_ACTUAL = find_column(risks_df, RISKS_CORE_TEAM_COL, optional=True)
RISKS_AUDIT_LEADER_ACTUAL = find_column(risks_df, RISKS_AUDIT_LEADER_COL, optional=True)

KPA_AE_ID_ACTUAL = find_column(kpa_df, KPA_AE_ID_COL)
KPA_ID_ACTUAL = find_column(kpa_df, KPA_ID_COL)
KPA_KEY_APPS_ACTUAL = find_column(kpa_df, KPA_KEY_APPS_COL)

print("="*70)
print("COLUMN MAPPING")
print("="*70)
print(f"‚úì Risks file - AE ID: '{RISKS_AE_ID_ACTUAL}'")
print(f"‚úì Risks file - IT Risk: '{RISKS_IT_ACTUAL}'")
print(f"‚úì Risks file - IS Risk: '{RISKS_IS_ACTUAL}'")
if RISKS_CORE_TEAM_ACTUAL:
    print(f"‚úì Risks file - Core Team: '{RISKS_CORE_TEAM_ACTUAL}'")
if RISKS_AUDIT_LEADER_ACTUAL:
    print(f"‚úì Risks file - Audit Leader: '{RISKS_AUDIT_LEADER_ACTUAL}'")
print(f"‚úì KPA file - AE ID: '{KPA_AE_ID_ACTUAL}'")
print()

# =============================================================================
# HELPER FUNCTION: PARSE MULTI-VALUE CELLS
# =============================================================================

def split_ids(value):
    """
    Convert comma/newline/semicolon-separated IDs into a clean list.
    Strips whitespace from each ID and filters out empty strings.
    """
    if pd.isna(value):
        return []
    ids = re.split(r'[\n,;]+', str(value).strip())
    return [x.strip() for x in ids if x.strip()]

# =============================================================================
# EXTRACT PRIMARY AND SECONDARY APPS PER AUDIT ENTITY
# =============================================================================

risks_df['Primary_List'] = risks_df[RISKS_PRIMARY_APPS_ACTUAL].apply(split_ids)
risks_df['Secondary_List'] = risks_df[RISKS_SECONDARY_APPS_ACTUAL].apply(split_ids)

ae_primary_map = dict(zip(risks_df[RISKS_AE_ID_ACTUAL], risks_df['Primary_List']))
ae_secondary_map = dict(zip(risks_df[RISKS_AE_ID_ACTUAL], risks_df['Secondary_List']))

# Extract team info if available
if RISKS_CORE_TEAM_ACTUAL:
    ae_core_team_map = dict(zip(risks_df[RISKS_AE_ID_ACTUAL], risks_df[RISKS_CORE_TEAM_ACTUAL]))
else:
    ae_core_team_map = {}

if RISKS_AUDIT_LEADER_ACTUAL:
    ae_audit_leader_map = dict(zip(risks_df[RISKS_AE_ID_ACTUAL], risks_df[RISKS_AUDIT_LEADER_ACTUAL]))
else:
    ae_audit_leader_map = {}

# =============================================================================
# EXTRACT KEY-TAGGED APPS FROM KPA DATA (PER ENTITY)
# =============================================================================

kpa_df['Key_List'] = kpa_df[KPA_KEY_APPS_ACTUAL].apply(split_ids)

# Aggregate all Key apps per AE (across all KPAs)
kpa_key_map = (
    kpa_df.groupby(KPA_AE_ID_ACTUAL)['Key_List']
    .apply(lambda x: set([item for sublist in x for item in sublist]))
    .to_dict()
)

# =============================================================================
# MAIN ANALYSIS: BUILD COMPREHENSIVE DATASET
# =============================================================================

print("="*70)
print("ANALYZING DATA")
print("="*70)

rows = []

for ae_id in risks_df[RISKS_AE_ID_ACTUAL]:
    # Get primary and secondary apps
    primary_apps = ae_primary_map.get(ae_id, [])
    secondary_apps = ae_secondary_map.get(ae_id, [])
    
    # Get team info
    core_team = ae_core_team_map.get(ae_id, 'Unknown') if ae_core_team_map else 'Unknown'
    audit_leader = ae_audit_leader_map.get(ae_id, 'Unknown') if ae_audit_leader_map else 'Unknown'
    
    # Get all mapped apps
    all_mapped_apps = set(primary_apps + secondary_apps)
    
    # Get Key apps for THIS entity's KPAs
    key_apps_set = kpa_key_map.get(ae_id, set())
    
    # ========== GHOST APP DETECTION ==========
    ghost_apps = [aid for aid in key_apps_set if aid and aid not in all_mapped_apps]
    
    # ========== PRIMARY APP ANALYSIS ==========
    primary_key = [aid for aid in primary_apps if aid and aid in key_apps_set]
    primary_not_key = [aid for aid in primary_apps if aid and aid not in key_apps_set]
    
    # ========== SECONDARY APP ANALYSIS ==========
    secondary_key = [aid for aid in secondary_apps if aid and aid in key_apps_set]
    secondary_not_key = [aid for aid in secondary_apps if aid and aid not in key_apps_set]
    
    # Calculate metrics
    total_primary = len([aid for aid in primary_apps if aid])
    total_secondary = len([aid for aid in secondary_apps if aid])
    total_apps = total_primary + total_secondary
    total_mapped_apps = len(all_mapped_apps)
    
    total_primary_key = len(primary_key)
    total_secondary_key = len(secondary_key)
    total_key_apps = len(key_apps_set)
    
    num_ghost_apps = len(ghost_apps)
    num_primary_not_key = len(primary_not_key)
    num_secondary_not_key = len(secondary_not_key)
    
    pct_primary_not_key = round((num_primary_not_key / total_primary) * 100, 1) if total_primary else 0
    pct_secondary_not_key = round((num_secondary_not_key / total_secondary) * 100, 1) if total_secondary else 0
    
    # Pull risk applicability
    risks_row = risks_df[risks_df[RISKS_AE_ID_ACTUAL] == ae_id]
    
    if len(risks_row) > 0:
        it_risk = risks_row[RISKS_IT_ACTUAL].values[0]
        is_risk = risks_row[RISKS_IS_ACTUAL].values[0]
    else:
        it_risk = 'N/A'
        is_risk = 'N/A'
    
    # Build output row
    rows.append({
        'Audit Entity ID': ae_id,
        'Core Audit Team': core_team,
        'Audit Leader': audit_leader,
        
        # Mapping counts
        'Total Primary Apps': total_primary,
        'Total Secondary Apps': total_secondary,
        'Total Mapped Apps': total_mapped_apps,
        
        # Key designation counts
        'Primary Key Apps': total_primary_key,
        'Secondary Key Apps': total_secondary_key,
        'Total Key Apps': total_key_apps,
        
        # Issues - Ghost Apps (CRITICAL)
        '# Ghost Apps (Key but Not Mapped)': num_ghost_apps,
        'Ghost App IDs': ','.join(ghost_apps) if ghost_apps else '',
        
        # Issues - Primary Apps Not Key
        '# Primary Apps Not Key': num_primary_not_key,
        '% Primary Apps Not Key': pct_primary_not_key,
        'Primary Not Key IDs': ','.join(primary_not_key) if primary_not_key else '',
        
        # Issues - Secondary Apps Not Key
        '# Secondary Apps Not Key': num_secondary_not_key,
        '% Secondary Apps Not Key': pct_secondary_not_key,
        'Secondary Not Key IDs': ','.join(secondary_not_key) if secondary_not_key else '',
        
        # Risk status
        'IT Risk': it_risk,
        'IS Risk': is_risk
    })

# =============================================================================
# CREATE SUMMARY DATAFRAME
# =============================================================================

summary_df = pd.DataFrame(rows)

print(f"‚úì Analyzed {len(summary_df)} audit entities")
print()

# =============================================================================
# HELPER FUNCTION: CHECK IF RISK IS APPLICABLE
# =============================================================================

def is_risk_applicable(risk_value):
    """Check if a risk value indicates the risk is applicable"""
    if pd.isna(risk_value):
        return False
    return str(risk_value).strip() in RISK_APPLICABLE_VALUES

# Add boolean columns
summary_df['IT Risk Applicable'] = summary_df['IT Risk'].apply(is_risk_applicable)
summary_df['IS Risk Applicable'] = summary_df['IS Risk'].apply(is_risk_applicable)
summary_df['Any IT/IS Risk Applicable'] = summary_df['IT Risk Applicable'] | summary_df['IS Risk Applicable']

# =============================================================================
# FLAG CRITICAL ISSUES
# =============================================================================

# CRITICAL: Ghost Apps
summary_df['CRITICAL: Ghost Apps'] = summary_df['# Ghost Apps (Key but Not Mapped)'] > 0

# HIGH: Primary apps not Key
summary_df['HIGH: Primary Not Key'] = summary_df['# Primary Apps Not Key'] > 0

# HIGH: Secondary apps not Key
summary_df['HIGH: Secondary Not Key'] = summary_df['# Secondary Apps Not Key'] > 0

# COMBINED: Any mapping/tagging issues
summary_df['ANY ISSUE'] = (
    summary_df['CRITICAL: Ghost Apps'] |
    summary_df['HIGH: Primary Not Key'] |
    summary_df['HIGH: Secondary Not Key']
)

# Specific patterns for impact analysis
summary_df['Ghost Apps + No Risk'] = (
    (summary_df['# Ghost Apps (Key but Not Mapped)'] > 0) &
    (~summary_df['Any IT/IS Risk Applicable'])
)

summary_df['Primary Not Key + No Risk'] = (
    (summary_df['# Primary Apps Not Key'] > 0) &
    (summary_df['Primary Key Apps'] == 0) &
    (summary_df['Secondary Key Apps'] == 0) &
    (~summary_df['Any IT/IS Risk Applicable'])
)

summary_df['Secondary Not Key + No Risk'] = (
    (summary_df['# Secondary Apps Not Key'] > 0) &
    (summary_df['Total Key Apps'] == 0) &
    (~summary_df['Any IT/IS Risk Applicable'])
)

# Automation failures
summary_df['Primary Key Auto Failure'] = (
    (summary_df['Primary Key Apps'] > 0) &
    (~summary_df['Any IT/IS Risk Applicable'])
)

summary_df['Secondary Key Auto Failure'] = (
    (summary_df['Secondary Key Apps'] > 0) &
    (~summary_df['Any IT/IS Risk Applicable'])
)

# =============================================================================
# CONSOLE OUTPUT WITH STATISTICS
# =============================================================================

print("="*70)
print("OBSERVATION 1: GHOST APPLICATIONS")
print("="*70)
print()

ghost_entities = summary_df[summary_df['CRITICAL: Ghost Apps']]
total_ghost_apps = summary_df['# Ghost Apps (Key but Not Mapped)'].sum()

if len(ghost_entities) > 0:
    print(f"‚ö†Ô∏è  CRITICAL DATA INTEGRITY ISSUE")
    print(f"   Entities affected: {len(ghost_entities)} ({len(ghost_entities)/len(summary_df)*100:.1f}%)")
    print(f"   Total ghost apps: {int(total_ghost_apps)}")
    print(f"   Avg per entity: {total_ghost_apps/len(ghost_entities):.1f}")
    
    ghost_no_risk = summary_df[summary_df['Ghost Apps + No Risk']]
    print(f"   With NO IT/IS risk: {len(ghost_no_risk)}")
    print(f"   With IT/IS risk (using wrong apps): {len(ghost_entities) - len(ghost_no_risk)}")
else:
    print(f"‚úì No ghost applications detected")

print()

# =============================================================================

print("="*70)
print("OBSERVATION 2: PRIMARY APPS NOT TAGGED AS KEY")
print("="*70)
print()

primary_issue = summary_df[summary_df['HIGH: Primary Not Key']]
total_primary_not_key = summary_df['# Primary Apps Not Key'].sum()
primary_no_risk = summary_df[summary_df['Primary Not Key + No Risk']]
primary_have_risk = primary_issue[primary_issue['Any IT/IS Risk Applicable']]

if len(primary_issue) > 0:
    print(f"‚ö†Ô∏è  HIGH PRIORITY ISSUE")
    print(f"   Entities with Primary apps: {len(summary_df[summary_df['Total Primary Apps'] > 0])}")
    print(f"   Entities with Primary NOT Key: {len(primary_issue)} ({len(primary_issue)/len(summary_df[summary_df['Total Primary Apps'] > 0])*100:.1f}% of entities with Primary)")
    print(f"   Total Primary apps NOT Key: {int(total_primary_not_key)}")
    print(f"   ")
    print(f"   With NO IT/IS risk: {len(primary_no_risk)} (confirmed understated)")
    print(f"   With IT/IS risk: {len(primary_have_risk)} (potentially understated)")
    print(f"   ")
    print(f"   Distribution:")
    print(f"   1-2 apps not Key: {len(primary_issue[primary_issue['# Primary Apps Not Key'] <= 2])}")
    print(f"   3-5 apps not Key: {len(primary_issue[(primary_issue['# Primary Apps Not Key'] > 2) & (primary_issue['# Primary Apps Not Key'] <= 5)])}")
    print(f"   6+ apps not Key: {len(primary_issue[primary_issue['# Primary Apps Not Key'] > 5])}")
else:
    print(f"‚úì No issues with Primary app tagging")

print()

# =============================================================================

print("="*70)
print("OBSERVATION 3: SECONDARY APPS NOT TAGGED AS KEY")
print("="*70)
print()

secondary_issue = summary_df[summary_df['HIGH: Secondary Not Key']]
total_secondary_not_key = summary_df['# Secondary Apps Not Key'].sum()
secondary_no_risk = summary_df[summary_df['Secondary Not Key + No Risk']]
secondary_have_risk = secondary_issue[secondary_issue['Any IT/IS Risk Applicable']]

if len(secondary_issue) > 0:
    print(f"‚ö†Ô∏è  HIGH PRIORITY ISSUE - METHODOLOGY VIOLATION")
    print(f"   Entities with Secondary apps: {len(summary_df[summary_df['Total Secondary Apps'] > 0])}")
    print(f"   Entities with Secondary NOT Key: {len(secondary_issue)} ({len(secondary_issue)/len(summary_df[summary_df['Total Secondary Apps'] > 0])*100:.1f}% of entities with Secondary)")
    print(f"   Total Secondary apps NOT Key: {int(total_secondary_not_key)}")
    print(f"   ")
    print(f"   With NO IT/IS risk: {len(secondary_no_risk)} (confirmed understated)")
    print(f"   With IT/IS risk: {len(secondary_have_risk)} (potentially understated)")
else:
    print(f"‚úì No issues with Secondary app tagging")

print()

# =============================================================================

print("="*70)
print("OBSERVATION 4: AUTOMATION FAILURES")
print("="*70)
print()

primary_auto_fail = summary_df[summary_df['Primary Key Auto Failure']]
secondary_auto_fail = summary_df[summary_df['Secondary Key Auto Failure']]
all_auto_fail = summary_df[summary_df['Primary Key Auto Failure'] | summary_df['Secondary Key Auto Failure']]

if len(all_auto_fail) > 0:
    print(f"‚ö†Ô∏è  AUTOMATION FAILURES DETECTED")
    print(f"   Primary Key apps + no risk: {len(primary_auto_fail)}")
    if len(primary_auto_fail) > 0:
        print(f"   ‚îî‚îÄ Total Primary Key apps affected: {int(primary_auto_fail['Primary Key Apps'].sum())}")
    print(f"   Secondary Key apps + no risk: {len(secondary_auto_fail)}")
    if len(secondary_auto_fail) > 0:
        print(f"   ‚îî‚îÄ Total Secondary Key apps affected: {int(secondary_auto_fail['Secondary Key Apps'].sum())}")
    print(f"   ")
    print(f"   Total entities with automation failures: {len(all_auto_fail)}")
else:
    print(f"‚úì No automation failures detected")

print()

# =============================================================================
# EXPORT OBSERVATION 1: GHOST APPS
# =============================================================================

print("="*70)
print("EXPORTING OBSERVATION FILES")
print("="*70)

if len(ghost_entities) > 0:
    with pd.ExcelWriter(OUTPUT_OBSERVATION_1, engine='openpyxl') as writer:
        # Tab 1: Summary
        obs1_summary = pd.DataFrame([
            {'Metric': 'OBSERVATION 1: GHOST APPLICATIONS', 'Value': ''},
            {'Metric': '', 'Value': ''},
            {'Metric': 'Definition', 'Value': 'Apps tagged as Key in KPAs but NOT mapped to entity'},
            {'Metric': 'Severity', 'Value': 'CRITICAL'},
            {'Metric': '', 'Value': ''},
            {'Metric': 'Entities affected', 'Value': len(ghost_entities)},
            {'Metric': '% of total', 'Value': f"{len(ghost_entities)/len(summary_df)*100:.1f}%"},
            {'Metric': 'Total ghost apps', 'Value': int(total_ghost_apps)},
            {'Metric': 'Avg per entity', 'Value': f"{total_ghost_apps/len(ghost_entities):.1f}"},
            {'Metric': '', 'Value': ''},
            {'Metric': 'With NO IT/IS risk', 'Value': len(ghost_no_risk)},
            {'Metric': 'With IT/IS risk (using wrong apps)', 'Value': len(ghost_entities) - len(ghost_no_risk)},
            {'Metric': '', 'Value': ''},
            {'Metric': 'Impact', 'Value': 'Risk ratings are WRONG (using wrong application data)'},
        ])
        obs1_summary.to_excel(writer, sheet_name='Summary', index=False)
        
        # Tab 2: All entities with ghost apps
        ghost_export = ghost_entities.sort_values('# Ghost Apps (Key but Not Mapped)', ascending=False)
        ghost_export.to_excel(writer, sheet_name='All Ghost Apps', index=False)
        
        # Tab 3: Top 10 by ghost app count
        top_ghost = ghost_export.head(10)
        top_ghost.to_excel(writer, sheet_name='Top 10', index=False)
        
        # Tab 4: Distribution by team (if available)
        if RISKS_CORE_TEAM_ACTUAL:
            team_dist = ghost_entities.groupby('Core Audit Team').agg({
                'Audit Entity ID': 'count',
                '# Ghost Apps (Key but Not Mapped)': 'sum'
            }).reset_index()
            team_dist.columns = ['Core Audit Team', '# Entities', 'Total Ghost Apps']
            team_dist = team_dist.sort_values('# Entities', ascending=False)
            team_dist.to_excel(writer, sheet_name='By Team', index=False)
        
    print(f"‚úì {OUTPUT_OBSERVATION_1}")

# =============================================================================
# EXPORT OBSERVATION 2: PRIMARY APPS NOT KEY
# =============================================================================

if len(primary_issue) > 0:
    with pd.ExcelWriter(OUTPUT_OBSERVATION_2, engine='openpyxl') as writer:
        # Tab 1: Summary
        obs2_summary = pd.DataFrame([
            {'Metric': 'OBSERVATION 2: PRIMARY APPS NOT TAGGED AS KEY', 'Value': ''},
            {'Metric': '', 'Value': ''},
            {'Metric': 'Definition', 'Value': 'Apps mapped as Primary but NOT tagged as Key in any KPA'},
            {'Metric': 'Severity', 'Value': 'HIGH'},
            {'Metric': '', 'Value': ''},
            {'Metric': 'Entities with Primary apps', 'Value': len(summary_df[summary_df['Total Primary Apps'] > 0])},
            {'Metric': 'Entities with Primary NOT Key', 'Value': len(primary_issue)},
            {'Metric': '% non-compliance', 'Value': f"{len(primary_issue)/len(summary_df[summary_df['Total Primary Apps'] > 0])*100:.1f}%"},
            {'Metric': 'Total Primary apps NOT Key', 'Value': int(total_primary_not_key)},
            {'Metric': '', 'Value': ''},
            {'Metric': 'With NO IT/IS risk', 'Value': len(primary_no_risk)},
            {'Metric': 'With IT/IS risk', 'Value': len(primary_have_risk)},
            {'Metric': '', 'Value': ''},
            {'Metric': 'Distribution:', 'Value': ''},
            {'Metric': '1-2 apps not Key', 'Value': len(primary_issue[primary_issue['# Primary Apps Not Key'] <= 2])},
            {'Metric': '3-5 apps not Key', 'Value': len(primary_issue[(primary_issue['# Primary Apps Not Key'] > 2) & (primary_issue['# Primary Apps Not Key'] <= 5)])},
            {'Metric': '6+ apps not Key', 'Value': len(primary_issue[primary_issue['# Primary Apps Not Key'] > 5])},
        ])
        obs2_summary.to_excel(writer, sheet_name='Summary', index=False)
        
        # Tab 2: All entities
        primary_export = primary_issue.sort_values('# Primary Apps Not Key', ascending=False)
        primary_export.to_excel(writer, sheet_name='All Primary Not Key', index=False)
        
        # Tab 3: High count (6+)
        high_count = primary_issue[primary_issue['# Primary Apps Not Key'] > 5].sort_values('# Primary Apps Not Key', ascending=False)
        high_count.to_excel(writer, sheet_name='High Count (6+)', index=False)
        
        # Tab 4: No Risk (confirmed understated)
        primary_no_risk.to_excel(writer, sheet_name='No Risk (Confirmed)', index=False)
        
        # Tab 5: Has Risk (potentially understated)
        primary_have_risk_sorted = primary_have_risk.sort_values('# Primary Apps Not Key', ascending=False).head(20)
        primary_have_risk_sorted.to_excel(writer, sheet_name='Has Risk (Potential)', index=False)
        
        # Tab 6: By Team (if available)
        if RISKS_CORE_TEAM_ACTUAL:
            team_dist = primary_issue.groupby('Core Audit Team').agg({
                'Audit Entity ID': 'count',
                '# Primary Apps Not Key': 'sum'
            }).reset_index()
            team_dist.columns = ['Core Audit Team', '# Entities', 'Total Primary Apps Not Key']
            team_dist = team_dist.sort_values('# Entities', ascending=False)
            team_dist.to_excel(writer, sheet_name='By Team', index=False)
    
    print(f"‚úì {OUTPUT_OBSERVATION_2}")

# =============================================================================
# EXPORT OBSERVATION 3: SECONDARY APPS NOT KEY
# =============================================================================

if len(secondary_issue) > 0:
    with pd.ExcelWriter(OUTPUT_OBSERVATION_3, engine='openpyxl') as writer:
        # Tab 1: Summary
        obs3_summary = pd.DataFrame([
            {'Metric': 'OBSERVATION 3: SECONDARY APPS NOT TAGGED AS KEY', 'Value': ''},
            {'Metric': '', 'Value': ''},
            {'Metric': 'Definition', 'Value': 'Apps mapped as Secondary but NOT tagged as Key in any KPA'},
            {'Metric': 'Rule', 'Value': 'Secondary apps should be Key in at least one KPA'},
            {'Metric': 'Severity', 'Value': 'HIGH - Methodology Violation'},
            {'Metric': '', 'Value': ''},
            {'Metric': 'Entities with Secondary apps', 'Value': len(summary_df[summary_df['Total Secondary Apps'] > 0])},
            {'Metric': 'Entities with Secondary NOT Key', 'Value': len(secondary_issue)},
            {'Metric': '% non-compliance', 'Value': f"{len(secondary_issue)/len(summary_df[summary_df['Total Secondary Apps'] > 0])*100:.1f}%"},
            {'Metric': 'Total Secondary apps NOT Key', 'Value': int(total_secondary_not_key)},
            {'Metric': '', 'Value': ''},
            {'Metric': 'With NO IT/IS risk', 'Value': len(secondary_no_risk)},
            {'Metric': 'With IT/IS risk', 'Value': len(secondary_have_risk)},
        ])
        obs3_summary.to_excel(writer, sheet_name='Summary', index=False)
        
        # Tab 2: All entities
        secondary_export = secondary_issue.sort_values('# Secondary Apps Not Key', ascending=False)
        secondary_export.to_excel(writer, sheet_name='All Secondary Not Key', index=False)
        
        # Tab 3: No Risk (confirmed understated)
        secondary_no_risk.to_excel(writer, sheet_name='No Risk (Confirmed)', index=False)
        
        # Tab 4: Has Risk (potentially understated)
        secondary_have_risk_sorted = secondary_have_risk.sort_values('# Secondary Apps Not Key', ascending=False).head(20)
        secondary_have_risk_sorted.to_excel(writer, sheet_name='Has Risk (Potential)', index=False)
        
        # Tab 5: By Team (if available)
        if RISKS_CORE_TEAM_ACTUAL:
            team_dist = secondary_issue.groupby('Core Audit Team').agg({
                'Audit Entity ID': 'count',
                '# Secondary Apps Not Key': 'sum'
            }).reset_index()
            team_dist.columns = ['Core Audit Team', '# Entities', 'Total Secondary Apps Not Key']
            team_dist = team_dist.sort_values('# Entities', ascending=False)
            team_dist.to_excel(writer, sheet_name='By Team', index=False)
    
    print(f"‚úì {OUTPUT_OBSERVATION_3}")

# =============================================================================
# EXPORT OBSERVATION 4: AUTOMATION FAILURES
# =============================================================================

if len(all_auto_fail) > 0:
    with pd.ExcelWriter(OUTPUT_OBSERVATION_4, engine='openpyxl') as writer:
        # Tab 1: Summary
        obs4_summary = pd.DataFrame([
            {'Metric': 'OBSERVATION 4: AUTOMATION FAILURES', 'Value': ''},
            {'Metric': '', 'Value': ''},
            {'Metric': 'Definition', 'Value': 'Key apps exist but IT/IS risk NOT populated'},
            {'Metric': 'Severity', 'Value': 'HIGH'},
            {'Metric': '', 'Value': ''},
            {'Metric': 'Primary Key + no risk', 'Value': len(primary_auto_fail)},
            {'Metric': 'Secondary Key + no risk', 'Value': len(secondary_auto_fail)},
            {'Metric': 'Total entities', 'Value': len(all_auto_fail)},
            {'Metric': '', 'Value': ''},
            {'Metric': 'Total Primary Key apps affected', 'Value': int(primary_auto_fail['Primary Key Apps'].sum()) if len(primary_auto_fail) > 0 else 0},
            {'Metric': 'Total Secondary Key apps affected', 'Value': int(secondary_auto_fail['Secondary Key Apps'].sum()) if len(secondary_auto_fail) > 0 else 0},
            {'Metric': '', 'Value': ''},
            {'Metric': 'Impact', 'Value': 'Risk should be populated but is not'},
        ])
        obs4_summary.to_excel(writer, sheet_name='Summary', index=False)
        
        # Tab 2: All automation failures
        all_auto_fail_sorted = all_auto_fail.sort_values(['Primary Key Apps', 'Secondary Key Apps'], ascending=False)
        all_auto_fail_sorted.to_excel(writer, sheet_name='All Automation Failures', index=False)
        
        # Tab 3: Primary Key failures (if any)
        if len(primary_auto_fail) > 0:
            primary_auto_fail.to_excel(writer, sheet_name='Primary Key Failures', index=False)
        
        # Tab 4: Secondary Key failures (if any)
        if len(secondary_auto_fail) > 0:
            secondary_auto_fail.to_excel(writer, sheet_name='Secondary Key Failures', index=False)
    
    print(f"‚úì {OUTPUT_OBSERVATION_4}")

# =============================================================================
# EXPORT EXECUTIVE SUMMARY
# =============================================================================

with pd.ExcelWriter(OUTPUT_EXECUTIVE_SUMMARY, engine='openpyxl') as writer:
    # Tab 1: Overall Summary
    exec_summary = pd.DataFrame([
        {'Metric': 'IT/IS RISK APPLICABILITY ANALYSIS', 'Value': '', 'Details': ''},
        {'Metric': 'EXECUTIVE SUMMARY', 'Value': '', 'Details': ''},
        {'Metric': '', 'Value': '', 'Details': ''},
        {'Metric': 'Scope', 'Value': len(summary_df), 'Details': 'audit entities analyzed'},
        {'Metric': '', 'Value': '', 'Details': ''},
        {'Metric': 'OBSERVATION 1: Ghost Applications', 'Value': '', 'Details': 'CRITICAL'},
        {'Metric': '‚îî‚îÄ Entities affected', 'Value': len(ghost_entities) if len(ghost_entities) > 0 else 0, 'Details': f"{len(ghost_entities)/len(summary_df)*100:.1f}%" if len(ghost_entities) > 0 else '0%'},
        {'Metric': '‚îî‚îÄ Total ghost apps', 'Value': int(total_ghost_apps) if len(ghost_entities) > 0 else 0, 'Details': 'risk calculated from WRONG apps'},
        {'Metric': '', 'Value': '', 'Details': ''},
        {'Metric': 'OBSERVATION 2: Primary Apps Not Key', 'Value': '', 'Details': 'HIGH'},
        {'Metric': '‚îî‚îÄ Entities affected', 'Value': len(primary_issue) if len(primary_issue) > 0 else 0, 'Details': f"{len(primary_issue)/len(summary_df)*100:.1f}%" if len(primary_issue) > 0 else '0%'},
        {'Metric': '‚îî‚îÄ Total Primary apps not Key', 'Value': int(total_primary_not_key) if len(primary_issue) > 0 else 0, 'Details': ''},
        {'Metric': '‚îî‚îÄ With NO IT/IS risk', 'Value': len(primary_no_risk) if len(primary_issue) > 0 else 0, 'Details': 'confirmed understated'},
        {'Metric': '‚îî‚îÄ With IT/IS risk', 'Value': len(primary_have_risk) if len(primary_issue) > 0 else 0, 'Details': 'potentially understated'},
        {'Metric': '', 'Value': '', 'Details': ''},
        {'Metric': 'OBSERVATION 3: Secondary Apps Not Key', 'Value': '', 'Details': 'HIGH'},
        {'Metric': '‚îî‚îÄ Entities affected', 'Value': len(secondary_issue) if len(secondary_issue) > 0 else 0, 'Details': f"{len(secondary_issue)/len(summary_df)*100:.1f}%" if len(secondary_issue) > 0 else '0%'},
        {'Metric': '‚îî‚îÄ Total Secondary apps not Key', 'Value': int(total_secondary_not_key) if len(secondary_issue) > 0 else 0, 'Details': 'methodology violation'},
        {'Metric': '‚îî‚îÄ With NO IT/IS risk', 'Value': len(secondary_no_risk) if len(secondary_issue) > 0 else 0, 'Details': 'confirmed understated'},
        {'Metric': '‚îî‚îÄ With IT/IS risk', 'Value': len(secondary_have_risk) if len(secondary_issue) > 0 else 0, 'Details': 'potentially understated'},
        {'Metric': '', 'Value': '', 'Details': ''},
        {'Metric': 'OBSERVATION 4: Automation Failures', 'Value': '', 'Details': 'HIGH'},
        {'Metric': '‚îî‚îÄ Entities affected', 'Value': len(all_auto_fail) if len(all_auto_fail) > 0 else 0, 'Details': 'Key apps but no risk'},
        {'Metric': '', 'Value': '', 'Details': ''},
        {'Metric': 'TOTAL ENTITIES WITH ANY ISSUE', 'Value': len(summary_df[summary_df['ANY ISSUE']]), 'Details': f"{len(summary_df[summary_df['ANY ISSUE']])/len(summary_df)*100:.1f}%"},
        {'Metric': '', 'Value': '', 'Details': ''},
        {'Metric': 'CONFIRMED IMPACT', 'Value': '', 'Details': ''},
        {'Metric': '‚îî‚îÄ Wrong risk ratings (ghost apps)', 'Value': len(ghost_entities) - len(ghost_no_risk) if len(ghost_entities) > 0 else 0, 'Details': 'entities'},
        {'Metric': '‚îî‚îÄ Understated risk (no IT/IS risk)', 'Value': len(primary_no_risk) + len(secondary_no_risk) + len(ghost_no_risk), 'Details': 'entities'},
        {'Metric': 'TOTAL CONFIRMED', 'Value': len(ghost_entities) + len(primary_no_risk) + len(secondary_no_risk), 'Details': f"{(len(ghost_entities) + len(primary_no_risk) + len(secondary_no_risk))/len(summary_df)*100:.1f}%"},
    ])
    exec_summary.to_excel(writer, sheet_name='Executive Summary', index=False)
    
    # Tab 2: Observation Comparison
    obs_comparison = pd.DataFrame([
        {
            'Observation': '1 - Ghost Apps',
            'Severity': 'CRITICAL',
            'Entities': len(ghost_entities) if len(ghost_entities) > 0 else 0,
            '% of Total': f"{len(ghost_entities)/len(summary_df)*100:.1f}%" if len(ghost_entities) > 0 else '0%',
            'Apps Affected': int(total_ghost_apps) if len(ghost_entities) > 0 else 0,
            'Impact': 'Risk ratings WRONG',
            'File': OUTPUT_OBSERVATION_1 if len(ghost_entities) > 0 else 'N/A'
        },
        {
            'Observation': '2 - Primary Not Key',
            'Severity': 'HIGH',
            'Entities': len(primary_issue) if len(primary_issue) > 0 else 0,
            '% of Total': f"{len(primary_issue)/len(summary_df)*100:.1f}%" if len(primary_issue) > 0 else '0%',
            'Apps Affected': int(total_primary_not_key) if len(primary_issue) > 0 else 0,
            'Impact': f"{len(primary_no_risk)} confirmed, {len(primary_have_risk)} potential" if len(primary_issue) > 0 else 'None',
            'File': OUTPUT_OBSERVATION_2 if len(primary_issue) > 0 else 'N/A'
        },
        {
            'Observation': '3 - Secondary Not Key',
            'Severity': 'HIGH',
            'Entities': len(secondary_issue) if len(secondary_issue) > 0 else 0,
            '% of Total': f"{len(secondary_issue)/len(summary_df)*100:.1f}%" if len(secondary_issue) > 0 else '0%',
            'Apps Affected': int(total_secondary_not_key) if len(secondary_issue) > 0 else 0,
            'Impact': f"{len(secondary_no_risk)} confirmed, {len(secondary_have_risk)} potential" if len(secondary_issue) > 0 else 'None',
            'File': OUTPUT_OBSERVATION_3 if len(secondary_issue) > 0 else 'N/A'
        },
        {
            'Observation': '4 - Automation Failures',
            'Severity': 'HIGH',
            'Entities': len(all_auto_fail) if len(all_auto_fail) > 0 else 0,
            '% of Total': f"{len(all_auto_fail)/len(summary_df)*100:.1f}%" if len(all_auto_fail) > 0 else '0%',
            'Apps Affected': int(primary_auto_fail['Primary Key Apps'].sum() + secondary_auto_fail['Secondary Key Apps'].sum()) if len(all_auto_fail) > 0 else 0,
            'Impact': 'Risk should exist but missing',
            'File': OUTPUT_OBSERVATION_4 if len(all_auto_fail) > 0 else 'N/A'
        }
    ])
    obs_comparison.to_excel(writer, sheet_name='Observation Comparison', index=False)
    
    # Tab 3: Team Analysis (if available)
    if RISKS_CORE_TEAM_ACTUAL:
        # Count issues by team across all observations
        team_summary = summary_df.groupby('Core Audit Team').agg({
            'Audit Entity ID': 'count',
            'CRITICAL: Ghost Apps': 'sum',
            'HIGH: Primary Not Key': 'sum',
            'HIGH: Secondary Not Key': 'sum',
            'Primary Key Auto Failure': 'sum',
            'Secondary Key Auto Failure': 'sum'
        }).reset_index()
        
        team_summary.columns = [
            'Core Audit Team',
            'Total Entities',
            'Ghost Apps',
            'Primary Not Key',
            'Secondary Not Key',
            'Primary Auto Fail',
            'Secondary Auto Fail'
        ]
        
        # Add total issues column
        team_summary['Total Issues'] = (
            team_summary['Ghost Apps'] +
            team_summary['Primary Not Key'] +
            team_summary['Secondary Not Key'] +
            team_summary['Primary Auto Fail'] +
            team_summary['Secondary Auto Fail']
        )
        
        # Calculate percentages
        team_summary['% With Issues'] = round((team_summary['Total Issues'] / team_summary['Total Entities']) * 100, 1)
        
        # Sort by total issues
        team_summary = team_summary.sort_values('Total Issues', ascending=False)
        
        team_summary.to_excel(writer, sheet_name='By Team', index=False)

print(f"‚úì {OUTPUT_EXECUTIVE_SUMMARY}")

# =============================================================================
# EXPORT FULL ANALYSIS (SOURCE DATA)
# =============================================================================

summary_df.to_excel(OUTPUT_FULL_ANALYSIS, index=False)
print(f"‚úì {OUTPUT_FULL_ANALYSIS}")

# =============================================================================
# FINAL SUMMARY
# =============================================================================

print("\n" + "="*70)
print("ANALYSIS COMPLETE")
print("="*70)
print(f"\nüìä Files Created:")
print(f"   {OUTPUT_EXECUTIVE_SUMMARY}")
if len(ghost_entities) > 0:
    print(f"   {OUTPUT_OBSERVATION_1}")
if len(primary_issue) > 0:
    print(f"   {OUTPUT_OBSERVATION_2}")
if len(secondary_issue) > 0:
    print(f"   {OUTPUT_OBSERVATION_3}")
if len(all_auto_fail) > 0:
    print(f"   {OUTPUT_OBSERVATION_4}")
print(f"   {OUTPUT_FULL_ANALYSIS}")

print(f"\nüìÅ Each observation file contains multiple tabs:")
print(f"   - Summary (metrics and impact)")
print(f"   - All data (complete list)")
print(f"   - Filtered views (samples, high priority)")
if RISKS_CORE_TEAM_ACTUAL:
    print(f"   - By Team (distribution analysis)")

print("\n" + "="*70)
```

---

## **What This Updated Script Does**

### **1. Organized Output Files by Observation**

Each observation gets its own file with multiple tabs:

**Observation1_GhostApps.xlsx:**
- Summary tab
- All Ghost Apps tab
- Top 10 tab
- By Team tab (if team data available)

**Observation2_PrimaryNotKey.xlsx:**
- Summary tab
- All Primary Not Key tab
- High Count (6+) tab
- No Risk (Confirmed) tab
- Has Risk (Potential) tab
- By Team tab

**Observation3_SecondaryNotKey.xlsx:**
- Summary tab
- All Secondary Not Key tab
- No Risk (Confirmed) tab
- Has Risk (Potential) tab
- By Team tab

**Observation4_AutomationFailures.xlsx:**
- Summary tab
- All Automation Failures tab
- Primary Key Failures tab (if any)
- Secondary Key Failures tab (if any)

### **2. Executive Summary File**

**00_ExecutiveSummary.xlsx:**
- Executive Summary tab (overall metrics)
- Observation Comparison tab (side-by-side)
- By Team tab (team analysis across all observations)

### **3. Team Analysis**

If Core Audit Team and Audit Leader columns exist, the script:
- Includes them in all data exports
- Creates "By Team" tabs showing distribution of issues
- Creates team summary in Executive Summary showing which teams have most issues

### **4. Easy Navigation**

**File names are numbered and descriptive:**
```
00_ExecutiveSummary.xlsx
Observation1_GhostApps.xlsx
Observation2_PrimaryNotKey.xlsx
Observation3_SecondaryNotKey.xlsx
Observation4_AutomationFailures.xlsx
SourceData_FullAnalysis.xlsx
