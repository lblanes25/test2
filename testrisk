"""
IT/IS RISK APPLICABILITY ANALYSIS WITH L2 KEY RISK CONTEXT
Version: 2.0
Created: [Date]
Analyst: [Your Name]

SCRIPT LOCATION: [To be filled in - path to this script file]

PURPOSE:
Validates accuracy of IT/IS risk ratings across audit universe by:
1. Identifying ghost applications (apps in KPAs not mapped to entity)
2. Identifying apps not tagged as Key (Primary and Secondary)
3. Validating impact using ARA scores
4. Comparing to current system risk
5. Analyzing L2 Key Risk mappings to understand risk calculation pathways

OUTPUTS:
- 00_ExecutiveSummary.xlsx (overall results with methodology)
- Observation1_GhostApps.xlsx (if found)
- Observation2_PrimaryNotKey.xlsx (if found)
- Observation3_SecondaryNotKey.xlsx (if found)
- Observation4_AutomationFailures.xlsx (if found)
- SourceData_FullAnalysis.xlsx (complete dataset)

Each output file includes Methodology tab for reperformance.

CONFIGURATION:
Update file names and column names in CONFIGURATION section below.
"""

import pandas as pd
import re

# =============================================================================
# CONFIGURATION - UPDATE YOUR FILE/COLUMN NAMES HERE
# =============================================================================

# Input file names
RISKS_FILE = "audit_entity_risks.xlsx"
KPA_FILE = "kpa_tagging.xlsx"
ARA_FILE = "all_applications.xlsx"
L2_MAPPING_FILE = "l2_key_risks.xlsx"  # NEW: L2 Key Risk mappings

# Sheet names
RISKS_SHEET = 0
KPA_SHEET = 0
ARA_SHEET = 0
L2_SHEET = 0

# Column names in RISKS file (case-insensitive matching will be applied)
RISKS_AE_ID_COL = "Audit Entity ID"
RISKS_IT_COL = "Information Technology Inherent Risk"
RISKS_IS_COL = "Information Security Inherent Risk"
RISKS_PRIMARY_APPS_COL = "Primary IT applications (mapped)"
RISKS_SECONDARY_APPS_COL = "Secondary IT applications (Related or Relied on)"
RISKS_CORE_TEAM_COL = "Core Audit Team"
RISKS_AUDIT_LEADER_COL = "Audit Leader"

# Column names in KPA file (case-insensitive matching will be applied)
KPA_AE_ID_COL = "Audit Entity ID"
KPA_ID_COL = "KPA ID"
KPA_KEY_APPS_COL = "KEY PRIMARY & SECONDARY IT applications"

# Column names in ARA file
ARA_APP_ID_COL = "Application Risk Assessment(ARA) Records (Centall Applications)"
ARA_AVAILABILITY_COL = "Availability Risk"
ARA_INTEGRITY_COL = "Integrity Risk"
ARA_CONFIDENTIALITY_COL = "Confidentiality Risk"

# Column names in L2 file
L2_AE_ID_COL = "Audit Entity ID"
L2_KEY_RISK_COL = "Key Risk"  # L2 Key Risk name
L2_L1_CATEGORIES_COL = "Tagged L1s"  # Multi-value cell with L1 categories

# Output file names - ORGANIZED BY OBSERVATION
OUTPUT_OBSERVATION_1 = "Observation1_GhostApps.xlsx"
OUTPUT_OBSERVATION_2 = "Observation2_PrimaryNotKey.xlsx"
OUTPUT_OBSERVATION_3 = "Observation3_SecondaryNotKey.xlsx"
OUTPUT_OBSERVATION_4 = "Observation4_AutomationFailures.xlsx"
OUTPUT_EXECUTIVE_SUMMARY = "00_ExecutiveSummary.xlsx"
OUTPUT_FULL_ANALYSIS = "SourceData_FullAnalysis.xlsx"

# Risk values that indicate the risk IS applicable
RISK_APPLICABLE_VALUES = ['Critical', 'High', 'Medium', 'Low']

# Risk scale for comparison (in order of severity)
RISK_SCALE = {
    'Critical': 4,
    'High': 3,
    'Medium': 2,
    'Low': 1,
    'N/A': 0,
    None: 0,
    '': 0
}

# =============================================================================
# LOAD DATA
# =============================================================================

print("="*70)
print("LOADING DATA")
print("="*70)

risks_df = pd.read_excel(RISKS_FILE, sheet_name=RISKS_SHEET)
kpa_df = pd.read_excel(KPA_FILE, sheet_name=KPA_SHEET)
ara_df = pd.read_excel(ARA_FILE, sheet_name=ARA_SHEET)
l2_df = pd.read_excel(L2_MAPPING_FILE, sheet_name=L2_SHEET)

print(f"✓ Loaded {len(risks_df)} audit entities from risks file")
print(f"✓ Loaded {len(kpa_df)} KPA records")
print(f"✓ Loaded {len(ara_df)} ARA records")
print(f"✓ Loaded {len(l2_df)} L2 Key Risk mappings")
print()

# =============================================================================
# HELPER FUNCTION: CASE-INSENSITIVE COLUMN MATCHING
# =============================================================================

def find_column(df, target_col, optional=False):
    """
    Find a column in the dataframe using case-insensitive matching.
    Returns the actual column name from the dataframe.
    If optional=True, returns None if column not found.
    """
    if target_col is None:
        return None
        
    col_map = {col.lower().strip(): col for col in df.columns}
    actual_col = col_map.get(target_col.lower().strip())
    
    if actual_col is None and not optional:
        raise ValueError(f"Column '{target_col}' not found in dataframe. Available columns: {list(df.columns)}")
    
    return actual_col

# Map configured column names to actual column names
RISKS_AE_ID_ACTUAL = find_column(risks_df, RISKS_AE_ID_COL)
RISKS_IT_ACTUAL = find_column(risks_df, RISKS_IT_COL)
RISKS_IS_ACTUAL = find_column(risks_df, RISKS_IS_COL)
RISKS_PRIMARY_APPS_ACTUAL = find_column(risks_df, RISKS_PRIMARY_APPS_COL)
RISKS_SECONDARY_APPS_ACTUAL = find_column(risks_df, RISKS_SECONDARY_APPS_COL)
RISKS_CORE_TEAM_ACTUAL = find_column(risks_df, RISKS_CORE_TEAM_COL, optional=True)
RISKS_AUDIT_LEADER_ACTUAL = find_column(risks_df, RISKS_AUDIT_LEADER_COL, optional=True)

KPA_AE_ID_ACTUAL = find_column(kpa_df, KPA_AE_ID_COL)
KPA_ID_ACTUAL = find_column(kpa_df, KPA_ID_COL)
KPA_KEY_APPS_ACTUAL = find_column(kpa_df, KPA_KEY_APPS_COL)

ARA_APP_ID_ACTUAL = find_column(ara_df, ARA_APP_ID_COL)
ARA_AVAILABILITY_ACTUAL = find_column(ara_df, ARA_AVAILABILITY_COL)
ARA_INTEGRITY_ACTUAL = find_column(ara_df, ARA_INTEGRITY_COL)
ARA_CONFIDENTIALITY_ACTUAL = find_column(ara_df, ARA_CONFIDENTIALITY_COL)

L2_AE_ID_ACTUAL = find_column(l2_df, L2_AE_ID_COL)
L2_KEY_RISK_ACTUAL = find_column(l2_df, L2_KEY_RISK_COL)
L2_L1_CATEGORIES_ACTUAL = find_column(l2_df, L2_L1_CATEGORIES_COL)

print("="*70)
print("COLUMN MAPPING")
print("="*70)
print(f"✓ Risks file - AE ID: '{RISKS_AE_ID_ACTUAL}'")
print(f"✓ Risks file - IT Risk: '{RISKS_IT_ACTUAL}'")
print(f"✓ Risks file - IS Risk: '{RISKS_IS_ACTUAL}'")
if RISKS_CORE_TEAM_ACTUAL:
    print(f"✓ Risks file - Core Team: '{RISKS_CORE_TEAM_ACTUAL}'")
if RISKS_AUDIT_LEADER_ACTUAL:
    print(f"✓ Risks file - Audit Leader: '{RISKS_AUDIT_LEADER_ACTUAL}'")
print(f"✓ KPA file - AE ID: '{KPA_AE_ID_ACTUAL}'")
print(f"✓ ARA file - App ID: '{ARA_APP_ID_ACTUAL}'")
print(f"✓ L2 file - AE ID: '{L2_AE_ID_ACTUAL}'")
print(f"✓ L2 file - L1 Categories: '{L2_L1_CATEGORIES_ACTUAL}'")
print()

# =============================================================================
# CREATE ARA LOOKUP DICTIONARY
# =============================================================================

print("="*70)
print("BUILDING ARA LOOKUP")
print("="*70)

ara_lookup = {}
for _, row in ara_df.iterrows():
    app_id = str(row[ARA_APP_ID_ACTUAL]).strip()
    ara_lookup[app_id] = {
        'availability': row[ARA_AVAILABILITY_ACTUAL] if pd.notna(row[ARA_AVAILABILITY_ACTUAL]) else 'N/A',
        'integrity': row[ARA_INTEGRITY_ACTUAL] if pd.notna(row[ARA_INTEGRITY_ACTUAL]) else 'N/A',
        'confidentiality': row[ARA_CONFIDENTIALITY_ACTUAL] if pd.notna(row[ARA_CONFIDENTIALITY_ACTUAL]) else 'N/A'
    }

print(f"✓ Created ARA lookup for {len(ara_lookup)} applications")
print()

# =============================================================================
# PARSE L2 KEY RISK MAPPINGS
# =============================================================================

print("="*70)
print("BUILDING L2 KEY RISK MAPPINGS")
print("="*70)

def parse_l1_categories(value):
    """
    Parse L1 categories from a cell like:
    "Compliance, Third Party, Information Systems Information Technology"
    
    Returns dict: {'IT': bool, 'IS': bool, 'TP': bool, 'Compliance': bool}
    """
    if pd.isna(value):
        return {'IT': False, 'IS': False, 'TP': False, 'Compliance': False}
    
    # Convert to string and lowercase for matching
    text = str(value).lower()
    
    result = {
        'IT': False,
        'IS': False,
        'TP': False,
        'Compliance': False
    }
    
    # Check for each L1 category
    # Information Technology (various possible spellings)
    if any(phrase in text for phrase in ['information technology', 'info technology', 'it risk']):
        result['IT'] = True
    
    # Information Security (various possible spellings)
    if any(phrase in text for phrase in ['information security', 'info security', 'information systems', 'is risk']):
        result['IS'] = True
    
    # Third Party
    if any(phrase in text for phrase in ['third party', 'third-party', '3rd party']):
        result['TP'] = True
    
    # Compliance
    if 'compliance' in text:
        result['Compliance'] = True
    
    return result

# Show sample parsing
print("Sample L1 category parsing (first 3 rows):")
for i in range(min(3, len(l2_df))):
    sample_value = l2_df.iloc[i][L2_L1_CATEGORIES_ACTUAL]
    parsed = parse_l1_categories(sample_value)
    print(f"  '{sample_value}' → IT:{parsed['IT']}, IS:{parsed['IS']}, TP:{parsed['TP']}")
print()

# Build L2 summary per entity
l2_summary = {}
for _, row in l2_df.iterrows():
    ae_id = row[L2_AE_ID_ACTUAL]
    l1_cats = parse_l1_categories(row[L2_L1_CATEGORIES_ACTUAL])
    l2_name = str(row[L2_KEY_RISK_ACTUAL]) if pd.notna(row[L2_KEY_RISK_ACTUAL]) else ''
    
    if ae_id not in l2_summary:
        l2_summary[ae_id] = {
            'has_it': False, 
            'has_is': False, 
            'has_tp': False,
            'it_l2s': [],
            'is_l2s': [],
            'tp_l2s': []
        }
    
    # If this L2 has IT category, mark entity as having IT L2
    if l1_cats['IT']:
        l2_summary[ae_id]['has_it'] = True
        if l2_name:
            l2_summary[ae_id]['it_l2s'].append(l2_name)
    
    # If this L2 has IS category, mark entity as having IS L2
    if l1_cats['IS']:
        l2_summary[ae_id]['has_is'] = True
        if l2_name:
            l2_summary[ae_id]['is_l2s'].append(l2_name)
    
    # If this L2 has TP category, mark entity as having TP L2
    if l1_cats['TP']:
        l2_summary[ae_id]['has_tp'] = True
        if l2_name:
            l2_summary[ae_id]['tp_l2s'].append(l2_name)

print(f"✓ Created L2 mappings for {len(l2_summary)} entities")
print()

# =============================================================================
# HELPER FUNCTION: PARSE MULTI-VALUE CELLS
# =============================================================================

def split_ids(value):
    """
    Convert comma/newline/semicolon-separated IDs into a clean list.
    Strips whitespace from each ID and filters out empty strings.
    """
    if pd.isna(value):
        return []
    ids = re.split(r'[\n,;]+', str(value).strip())
    return [x.strip() for x in ids if x.strip()]

# =============================================================================
# HELPER FUNCTIONS: ARA RISK CALCULATIONS
# =============================================================================

def get_risk_level(risk_value):
    """Convert risk value to numeric level for comparison"""
    if pd.isna(risk_value):
        return 0
    return RISK_SCALE.get(str(risk_value).strip(), 0)

def risk_to_string(risk_level):
    """Convert numeric risk level back to string"""
    for key, value in RISK_SCALE.items():
        if value == risk_level and key not in ['N/A', None, '']:
            return key
    return 'N/A'

def calculate_it_risk_from_apps(app_ids, ara_lookup):
    """
    Calculate IT risk from list of apps using ARA scores.
    IT Risk = max(Availability, Integrity) across all apps.
    Returns tuple: (risk_level_numeric, risk_string, detail_dict)
    """
    if not app_ids:
        return 0, 'N/A', {}
    
    max_risk = 0
    detail = {'apps_evaluated': [], 'max_app': None, 'max_score_type': None}
    
    for app_id in app_ids:
        if not app_id or app_id not in ara_lookup:
            continue
            
        ara = ara_lookup[app_id]
        avail_level = get_risk_level(ara['availability'])
        integ_level = get_risk_level(ara['integrity'])
        
        # IT Risk is the HIGHER of availability or integrity
        app_it_risk = max(avail_level, integ_level)
        
        detail['apps_evaluated'].append({
            'app_id': app_id,
            'availability': ara['availability'],
            'integrity': ara['integrity'],
            'it_risk': risk_to_string(app_it_risk)
        })
        
        if app_it_risk > max_risk:
            max_risk = app_it_risk
            detail['max_app'] = app_id
            detail['max_score_type'] = 'Availability' if avail_level > integ_level else 'Integrity'
    
    return max_risk, risk_to_string(max_risk), detail

def calculate_is_risk_from_apps(app_ids, ara_lookup):
    """
    Calculate IS risk from list of apps using ARA scores.
    IS Risk = max(Confidentiality) across all apps.
    Returns tuple: (risk_level_numeric, risk_string, detail_dict)
    """
    if not app_ids:
        return 0, 'N/A', {}
    
    max_risk = 0
    detail = {'apps_evaluated': [], 'max_app': None}
    
    for app_id in app_ids:
        if not app_id or app_id not in ara_lookup:
            continue
            
        ara = ara_lookup[app_id]
        confid_level = get_risk_level(ara['confidentiality'])
        
        detail['apps_evaluated'].append({
            'app_id': app_id,
            'confidentiality': ara['confidentiality'],
            'is_risk': risk_to_string(confid_level)
        })
        
        if confid_level > max_risk:
            max_risk = confid_level
            detail['max_app'] = app_id
    
    return max_risk, risk_to_string(max_risk), detail

# =============================================================================
# EXTRACT PRIMARY AND SECONDARY APPS PER AUDIT ENTITY
# =============================================================================

risks_df['Primary_List'] = risks_df[RISKS_PRIMARY_APPS_ACTUAL].apply(split_ids)
risks_df['Secondary_List'] = risks_df[RISKS_SECONDARY_APPS_ACTUAL].apply(split_ids)

ae_primary_map = dict(zip(risks_df[RISKS_AE_ID_ACTUAL], risks_df['Primary_List']))
ae_secondary_map = dict(zip(risks_df[RISKS_AE_ID_ACTUAL], risks_df['Secondary_List']))

# Extract team info if available
if RISKS_CORE_TEAM_ACTUAL:
    ae_core_team_map = dict(zip(risks_df[RISKS_AE_ID_ACTUAL], risks_df[RISKS_CORE_TEAM_ACTUAL]))
else:
    ae_core_team_map = {}

if RISKS_AUDIT_LEADER_ACTUAL:
    ae_audit_leader_map = dict(zip(risks_df[RISKS_AE_ID_ACTUAL], risks_df[RISKS_AUDIT_LEADER_ACTUAL]))
else:
    ae_audit_leader_map = {}

# =============================================================================
# EXTRACT KEY-TAGGED APPS FROM KPA DATA (PER ENTITY)
# =============================================================================

kpa_df['Key_List'] = kpa_df[KPA_KEY_APPS_ACTUAL].apply(split_ids)

# Aggregate all Key apps per AE (across all KPAs)
kpa_key_map = (
    kpa_df.groupby(KPA_AE_ID_ACTUAL)['Key_List']
    .apply(lambda x: set([item for sublist in x for item in sublist]))
    .to_dict()
)

# =============================================================================
# MAIN ANALYSIS: BUILD COMPREHENSIVE DATASET WITH ARA VALIDATION
# =============================================================================

print("="*70)
print("ANALYZING DATA WITH ARA VALIDATION AND L2 CONTEXT")
print("="*70)
print("Comparison Logic: Apps vs CURRENT SYSTEM RISK")
print()

rows = []

for ae_id in risks_df[RISKS_AE_ID_ACTUAL]:
    # Get primary and secondary apps
    primary_apps = ae_primary_map.get(ae_id, [])
    secondary_apps = ae_secondary_map.get(ae_id, [])
    
    # Get team info
    core_team = ae_core_team_map.get(ae_id, 'Unknown') if ae_core_team_map else 'Unknown'
    audit_leader = ae_audit_leader_map.get(ae_id, 'Unknown') if ae_audit_leader_map else 'Unknown'
    
    # Get L2 mappings
    l2_info = l2_summary.get(ae_id, {
        'has_it': False, 
        'has_is': False, 
        'has_tp': False,
        'it_l2s': [],
        'is_l2s': [],
        'tp_l2s': []
    })
    
    # Get all mapped apps
    all_mapped_apps = set(primary_apps + secondary_apps)
    
    # Get Key apps for THIS entity's KPAs
    key_apps_set = kpa_key_map.get(ae_id, set())
    
    # ========== GHOST APP DETECTION ==========
    ghost_apps = [aid for aid in key_apps_set if aid and aid not in all_mapped_apps]
    
    # ========== PRIMARY APP ANALYSIS ==========
    primary_key = [aid for aid in primary_apps if aid and aid in key_apps_set]
    primary_not_key = [aid for aid in primary_apps if aid and aid not in key_apps_set]
    
    # ========== SECONDARY APP ANALYSIS ==========
    secondary_key = [aid for aid in secondary_apps if aid and aid in key_apps_set]
    secondary_not_key = [aid for aid in secondary_apps if aid and aid not in key_apps_set]
    
    # Calculate metrics
    total_primary = len([aid for aid in primary_apps if aid])
    total_secondary = len([aid for aid in secondary_apps if aid])
    total_apps = total_primary + total_secondary
    total_mapped_apps = len(all_mapped_apps)
    
    total_primary_key = len(primary_key)
    total_secondary_key = len(secondary_key)
    total_key_apps = len(key_apps_set)
    
    num_ghost_apps = len(ghost_apps)
    num_primary_not_key = len(primary_not_key)
    num_secondary_not_key = len(secondary_not_key)
    
    pct_primary_not_key = round((num_primary_not_key / total_primary) * 100, 1) if total_primary else 0
    pct_secondary_not_key = round((num_secondary_not_key / total_secondary) * 100, 1) if total_secondary else 0
    
    # Pull CURRENT risk from system
    risks_row = risks_df[risks_df[RISKS_AE_ID_ACTUAL] == ae_id]
    
    if len(risks_row) > 0:
        current_it_risk = risks_row[RISKS_IT_ACTUAL].values[0]
        current_is_risk = risks_row[RISKS_IS_ACTUAL].values[0]
    else:
        current_it_risk = 'N/A'
        current_is_risk = 'N/A'
    
    # Get numeric levels for CURRENT system risk
    current_it_level = get_risk_level(current_it_risk)
    current_is_level = get_risk_level(current_is_risk)
    
    # ========== ARA VALIDATION: COMPARE AGAINST CURRENT SYSTEM RISK ==========
    
    # Calculate risk from ALL mapped apps (what it COULD be if all were Key)
    all_mapped_app_ids = list(all_mapped_apps)
    all_apps_it_level, all_apps_it_risk, _ = calculate_it_risk_from_apps(all_mapped_app_ids, ara_lookup)
    all_apps_is_level, all_apps_is_risk, _ = calculate_is_risk_from_apps(all_mapped_app_ids, ara_lookup)
    
    # Calculate risk from Key apps (including ghost apps - what system is using)
    key_app_ids = list(key_apps_set)
    key_apps_it_level, key_apps_it_risk, it_detail = calculate_it_risk_from_apps(key_app_ids, ara_lookup)
    key_apps_is_level, key_apps_is_risk, is_detail = calculate_is_risk_from_apps(key_app_ids, ara_lookup)
    
    # Calculate risk from ghost apps alone
    ghost_it_level = 0
    ghost_is_level = 0
    ghost_it_risk = 'N/A'
    ghost_is_risk = 'N/A'
    if ghost_apps:
        ghost_it_level, ghost_it_risk, _ = calculate_it_risk_from_apps(ghost_apps, ara_lookup)
        ghost_is_level, ghost_is_risk, _ = calculate_is_risk_from_apps(ghost_apps, ara_lookup)
    
    # Calculate risk from untagged apps
    primary_not_key_it_level = 0
    primary_not_key_is_level = 0
    primary_not_key_it_risk = 'N/A'
    primary_not_key_is_risk = 'N/A'
    if primary_not_key:
        primary_not_key_it_level, primary_not_key_it_risk, _ = calculate_it_risk_from_apps(primary_not_key, ara_lookup)
        primary_not_key_is_level, primary_not_key_is_risk, _ = calculate_is_risk_from_apps(primary_not_key, ara_lookup)
    
    secondary_not_key_it_level = 0
    secondary_not_key_is_level = 0
    secondary_not_key_it_risk = 'N/A'
    secondary_not_key_is_risk = 'N/A'
    if secondary_not_key:
        secondary_not_key_it_level, secondary_not_key_it_risk, _ = calculate_it_risk_from_apps(secondary_not_key, ara_lookup)
        secondary_not_key_is_level, secondary_not_key_is_risk, _ = calculate_is_risk_from_apps(secondary_not_key, ara_lookup)
    
    # ========== KEY COMPARISON: Against CURRENT SYSTEM RISK ==========
    
    # Would risk be HIGHER than current if we included ghost apps' correct counterparts?
    # (We can't calculate this without knowing what the correct apps are, so we note the ghost apps exist)
    has_ghost_apps = num_ghost_apps > 0
    
    # Would risk be HIGHER than current if Primary not Key apps were tagged?
    primary_would_increase_it = primary_not_key_it_level > current_it_level
    primary_would_increase_is = primary_not_key_is_level > current_is_level
    
    # Would risk be HIGHER than current if Secondary not Key apps were tagged?
    secondary_would_increase_it = secondary_not_key_it_level > current_it_level
    secondary_would_increase_is = secondary_not_key_is_level > current_is_level
    
    # Would risk be HIGHER than current if ALL mapped apps were tagged?
    all_apps_would_increase_it = all_apps_it_level > current_it_level
    all_apps_would_increase_is = all_apps_is_level > current_is_level
    
    # Risk status assessment
    if has_ghost_apps:
        it_risk_assessment = 'Possibly Misstated (Ghost Apps)'
        is_risk_assessment = 'Possibly Misstated (Ghost Apps)'
    elif all_apps_would_increase_it or all_apps_would_increase_is:
        it_risk_assessment = 'Possibly Understated' if all_apps_would_increase_it else 'Appears Correct'
        is_risk_assessment = 'Possibly Understated' if all_apps_would_increase_is else 'Appears Correct'
    else:
        it_risk_assessment = 'Appears Correct'
        is_risk_assessment = 'Appears Correct'
    
    # Build output row
    rows.append({
        'Audit Entity ID': ae_id,
        'Core Audit Team': core_team,
        'Audit Leader': audit_leader,
        
        # L2 KEY RISK MAPPINGS (NEW)
        'Has IT L2 Mappings': l2_info['has_it'],
        'Has IS L2 Mappings': l2_info['has_is'],
        'Has Third Party L2 Mappings': l2_info['has_tp'],
        '# IT L2 Key Risks': len(l2_info['it_l2s']),
        '# IS L2 Key Risks': len(l2_info['is_l2s']),
        '# Third Party L2 Key Risks': len(l2_info['tp_l2s']),
        'IT L2 Risk Names': ', '.join(l2_info['it_l2s']) if l2_info['it_l2s'] else '',
        'IS L2 Risk Names': ', '.join(l2_info['is_l2s']) if l2_info['is_l2s'] else '',
        'Third Party L2 Risk Names': ', '.join(l2_info['tp_l2s']) if l2_info['tp_l2s'] else '',
        
        # Mapping counts
        'Total Primary Apps': total_primary,
        'Total Secondary Apps': total_secondary,
        'Total Mapped Apps': total_mapped_apps,
        
        # Key designation counts
        'Primary Key Apps': total_primary_key,
        'Secondary Key Apps': total_secondary_key,
        'Total Key Apps': total_key_apps,
        
        # Issues - Ghost Apps (CRITICAL)
        '# Ghost Apps (Key but Not Mapped)': num_ghost_apps,
        'Ghost App IDs': ','.join(ghost_apps) if ghost_apps else '',
        
        # Issues - Primary Apps Not Key
        '# Primary Apps Not Key': num_primary_not_key,
        '% Primary Apps Not Key': pct_primary_not_key,
        'Primary Not Key IDs': ','.join(primary_not_key) if primary_not_key else '',
        
        # Issues - Secondary Apps Not Key
        '# Secondary Apps Not Key': num_secondary_not_key,
        '% Secondary Apps Not Key': pct_secondary_not_key,
        'Secondary Not Key IDs': ','.join(secondary_not_key) if secondary_not_key else '',
        
        # CURRENT Risk (what's in the system NOW)
        'Current IT Risk': current_it_risk,
        'Current IS Risk': current_is_risk,
        
        # ARA ANALYSIS: What risks WOULD be from different app sets
        'Risk from Key Apps (incl ghosts)': key_apps_it_risk,
        'IS Risk from Key Apps (incl ghosts)': key_apps_is_risk,
        'Risk from ALL Mapped Apps': all_apps_it_risk,
        'IS Risk from ALL Mapped Apps': all_apps_is_risk,
        
        # Ghost app risk levels
        'Ghost Apps IT Risk': ghost_it_risk,
        'Ghost Apps IS Risk': ghost_is_risk,
        
        # Untagged apps risk levels
        'Primary Not Key IT Risk': primary_not_key_it_risk,
        'Primary Not Key IS Risk': primary_not_key_is_risk,
        'Secondary Not Key IT Risk': secondary_not_key_it_risk,
        'Secondary Not Key IS Risk': secondary_not_key_is_risk,
        
        # COMPARISON: Would apps change CURRENT risk?
        'Primary Not Key: Higher than Current IT': primary_would_increase_it,
        'Primary Not Key: Higher than Current IS': primary_would_increase_is,
        'Secondary Not Key: Higher than Current IT': secondary_would_increase_it,
        'Secondary Not Key: Higher than Current IS': secondary_would_increase_is,
        'ALL Mapped Apps: Higher than Current IT': all_apps_would_increase_it,
        'ALL Mapped Apps: Higher than Current IS': all_apps_would_increase_is,
        
        # Risk Assessment
        'IT Risk Assessment': it_risk_assessment,
        'IS Risk Assessment': is_risk_assessment,
        
        # Reference info
        'Key App Driving IT (incl ghosts)': it_detail.get('max_app', 'N/A'),
        'Key App Driving IS (incl ghosts)': is_detail.get('max_app', 'N/A'),
    })

# =============================================================================
# CREATE SUMMARY DATAFRAME
# =============================================================================

summary_df = pd.DataFrame(rows)

print(f"✓ Analyzed {len(summary_df)} audit entities")
print()

# =============================================================================
# HELPER FUNCTION: CHECK IF RISK IS APPLICABLE
# =============================================================================

def is_risk_applicable(risk_value):
    """Check if a risk value indicates the risk is applicable"""
    if pd.isna(risk_value):
        return False
    return str(risk_value).strip() in RISK_APPLICABLE_VALUES

# Add boolean columns
summary_df['IT Risk Applicable'] = summary_df['Current IT Risk'].apply(is_risk_applicable)
summary_df['IS Risk Applicable'] = summary_df['Current IS Risk'].apply(is_risk_applicable)
summary_df['Any IT/IS Risk Applicable'] = summary_df['IT Risk Applicable'] | summary_df['IS Risk Applicable']

# =============================================================================
# FLAG CRITICAL ISSUES
# =============================================================================

# CRITICAL: Ghost Apps
summary_df['CRITICAL: Ghost Apps'] = summary_df['# Ghost Apps (Key but Not Mapped)'] > 0

# HIGH: Primary apps not Key
summary_df['HIGH: Primary Not Key'] = summary_df['# Primary Apps Not Key'] > 0

# HIGH: Secondary apps not Key
summary_df['HIGH: Secondary Not Key'] = summary_df['# Secondary Apps Not Key'] > 0

# COMBINED: Any mapping/tagging issues
summary_df['ANY ISSUE'] = (
    summary_df['CRITICAL: Ghost Apps'] |
    summary_df['HIGH: Primary Not Key'] |
    summary_df['HIGH: Secondary Not Key']
)

# Specific impact flags
summary_df['Ghost Apps Present'] = summary_df['# Ghost Apps (Key but Not Mapped)'] > 0

summary_df['Primary Not Key + No Risk'] = (
    (summary_df['# Primary Apps Not Key'] > 0) &
    (summary_df['Primary Key Apps'] == 0) &
    (summary_df['Secondary Key Apps'] == 0) &
    (~summary_df['Any IT/IS Risk Applicable'])
)

summary_df['Secondary Not Key + No Risk'] = (
    (summary_df['# Secondary Apps Not Key'] > 0) &
    (summary_df['Total Key Apps'] == 0) &
    (~summary_df['Any IT/IS Risk Applicable'])
)

# Automation failures
summary_df['Primary Key Auto Failure'] = (
    (summary_df['Primary Key Apps'] > 0) &
    (~summary_df['Any IT/IS Risk Applicable'])
)

summary_df['Secondary Key Auto Failure'] = (
    (summary_df['Secondary Key Apps'] > 0) &
    (~summary_df['Any IT/IS Risk Applicable'])
)

# ARA-validated impact flags (compared to CURRENT risk)
summary_df['Possibly Misstated IT Risk'] = (
    (summary_df['IT Risk Assessment'] == 'Possibly Misstated (Ghost Apps)') |
    (summary_df['IT Risk Assessment'] == 'Possibly Understated')
)

summary_df['Possibly Misstated IS Risk'] = (
    (summary_df['IS Risk Assessment'] == 'Possibly Misstated (Ghost Apps)') |
    (summary_df['IS Risk Assessment'] == 'Possibly Understated')
)

# =============================================================================
# L2 SUMMARY STATISTICS
# =============================================================================

print("="*70)
print("L2 KEY RISK MAPPING SUMMARY")
print("="*70)
print()

both_l2 = len(summary_df[(summary_df['Has IT L2 Mappings']) & (summary_df['Has IS L2 Mappings'])])
only_it_l2 = len(summary_df[(summary_df['Has IT L2 Mappings']) & (~summary_df['Has IS L2 Mappings'])])
only_is_l2 = len(summary_df[(~summary_df['Has IT L2 Mappings']) & (summary_df['Has IS L2 Mappings'])])
neither_l2 = len(summary_df[(~summary_df['Has IT L2 Mappings']) & (~summary_df['Has IS L2 Mappings'])])

print(f"L2 Mapping Distribution:")
print(f"  Both IT and IS L2s:  {both_l2:4d} ({both_l2/len(summary_df)*100:5.1f}%)")
print(f"  Only IT L2s:         {only_it_l2:4d} ({only_it_l2/len(summary_df)*100:5.1f}%)")
print(f"  Only IS L2s:         {only_is_l2:4d} ({only_is_l2/len(summary_df)*100:5.1f}%)")
print(f"  No IT or IS L2s:     {neither_l2:4d} ({neither_l2/len(summary_df)*100:5.1f}%)")
print()

# =============================================================================
# CONSOLE OUTPUT WITH ARA-VALIDATED STATISTICS
# =============================================================================

print("="*70)
print("OBSERVATION 1: GHOST APPLICATIONS")
print("="*70)
print()

ghost_entities = summary_df[summary_df['CRITICAL: Ghost Apps']]
total_ghost_apps = summary_df['# Ghost Apps (Key but Not Mapped)'].sum()

if len(ghost_entities) > 0:
    print(f"⚠️  CRITICAL DATA INTEGRITY ISSUE")
    print(f"   Entities affected: {len(ghost_entities)} ({len(ghost_entities)/len(summary_df)*100:.1f}%)")
    print(f"   Total ghost apps: {int(total_ghost_apps)}")
    print(f"   Avg per entity: {total_ghost_apps/len(ghost_entities):.1f}")
    print(f"   ")
    print(f"   ✓ RISK ASSESSMENT:")
    print(f"   ALL {len(ghost_entities)} entities have POSSIBLY MISSTATED risk")
    print(f"   (Ghost apps are wrong apps - correct apps may have different risk)")
    print(f"   ")
    print(f"   Impact: Cannot validate accuracy without knowing correct apps")
else:
    print(f"✓ No ghost applications detected")

print()

# =============================================================================

print("="*70)
print("OBSERVATION 2: PRIMARY APPS NOT TAGGED AS KEY")
print("="*70)
print()

primary_issue = summary_df[summary_df['HIGH: Primary Not Key']]
total_primary_not_key = summary_df['# Primary Apps Not Key'].sum()
primary_no_risk = summary_df[summary_df['Primary Not Key + No Risk']]

if len(primary_issue) > 0:
    # Check how many would have HIGHER risk than CURRENT if Primary apps were Key
    primary_higher_it = primary_issue[primary_issue['Primary Not Key: Higher than Current IT'] == True]
    primary_higher_is = primary_issue[primary_issue['Primary Not Key: Higher than Current IS'] == True]
    primary_higher_either = primary_issue[
        (primary_issue['Primary Not Key: Higher than Current IT'] == True) |
        (primary_issue['Primary Not Key: Higher than Current IS'] == True)
    ]
    
    # NEW: Split by L2 availability for PRIORITY
    primary_higher_either_with_l2 = primary_higher_either[
        (primary_higher_either['Has IT L2 Mappings']) |
        (primary_higher_either['Has IS L2 Mappings'])
    ]
    
    primary_higher_either_without_l2 = primary_higher_either[
        (~primary_higher_either['Has IT L2 Mappings']) &
        (~primary_higher_either['Has IS L2 Mappings'])
    ]
    
    print(f"⚠️  HIGH PRIORITY ISSUE")
    print(f"   Entities with Primary apps: {len(summary_df[summary_df['Total Primary Apps'] > 0])}")
    print(f"   Entities with Primary NOT Key: {len(primary_issue)} ({len(primary_issue)/len(summary_df[summary_df['Total Primary Apps'] > 0])*100:.1f}% of entities with Primary)")
    print(f"   Total Primary apps NOT Key: {int(total_primary_not_key)}")
    print(f"   ")
    print(f"   ✓ ARA VALIDATION (vs CURRENT system risk):")
    print(f"   Possibly understated: {len(primary_higher_either)} entities")
    print(f"   ")
    print(f"   PRIORITY BREAKDOWN (TWO-PART FIX REQUIRED):")
    print(f"   ")
    print(f"   HIGH Priority (has relevant L2s): {len(primary_higher_either_with_l2)} entities")
    print(f"   └─ Issue: Apps not tagged as Key")
    print(f"   └─ Fix: Review and tag apps as Key in KPAs")
    print(f"   └─ Impact: IMMEDIATE (L2 pathway exists, risk will auto-calculate)")
    print(f"   ")
    print(f"   MEDIUM Priority (missing relevant L2s): {len(primary_higher_either_without_l2)} entities")
    print(f"   └─ Issue 1: L2 Key Risks not mapped (no pathway)")
    print(f"   └─ Issue 2: Apps not tagged as Key (no content)")
    print(f"   └─ Fix: Map L2s FIRST, then review and tag apps")
    print(f"   └─ Impact: BOTH fixes needed before risk improves")
    print(f"   ")
    print(f"   ROOT CAUSE: Missing L2 mappings (foundation) AND missing Key tagging (content)")
    print(f"   BOTH must be addressed for accurate risk ratings")
    print(f"   ")
    print(f"   Distribution:")
    print(f"   1-2 apps not Key: {len(primary_issue[primary_issue['# Primary Apps Not Key'] <= 2])}")
    print(f"   3-5 apps not Key: {len(primary_issue[(primary_issue['# Primary Apps Not Key'] > 2) & (primary_issue['# Primary Apps Not Key'] <= 5)])}")
    print(f"   6+ apps not Key: {len(primary_issue[primary_issue['# Primary Apps Not Key'] > 5])}")
else:
    print(f"✓ No issues with Primary app tagging")

print()

# =============================================================================

print("="*70)
print("OBSERVATION 3: SECONDARY APPS NOT TAGGED AS KEY")
print("="*70)
print()

secondary_issue = summary_df[summary_df['HIGH: Secondary Not Key']]
total_secondary_not_key = summary_df['# Secondary Apps Not Key'].sum()
secondary_no_risk = summary_df[summary_df['Secondary Not Key + No Risk']]

if len(secondary_issue) > 0:
    # Check how many would have HIGHER risk than CURRENT if Secondary apps were Key
    secondary_higher_it = secondary_issue[secondary_issue['Secondary Not Key: Higher than Current IT'] == True]
    secondary_higher_is = secondary_issue[secondary_issue['Secondary Not Key: Higher than Current IS'] == True]
    secondary_higher_either = secondary_issue[
        (secondary_issue['Secondary Not Key: Higher than Current IT'] == True) |
        (secondary_issue['Secondary Not Key: Higher than Current IS'] == True)
    ]
    
    # NEW: Split by L2 availability for PRIORITY
    secondary_higher_either_with_l2 = secondary_higher_either[
        (secondary_higher_either['Has IT L2 Mappings']) |
        (secondary_higher_either['Has IS L2 Mappings'])
    ]
    
    secondary_higher_either_without_l2 = secondary_higher_either[
        (~secondary_higher_either['Has IT L2 Mappings']) &
        (~secondary_higher_either['Has IS L2 Mappings'])
    ]
    
    print(f"⚠️  HIGH PRIORITY ISSUE - METHODOLOGY VIOLATION")
    print(f"   Entities with Secondary apps: {len(summary_df[summary_df['Total Secondary Apps'] > 0])}")
    print(f"   Entities with Secondary NOT Key: {len(secondary_issue)} ({len(secondary_issue)/len(summary_df[summary_df['Total Secondary Apps'] > 0])*100:.1f}% of entities with Secondary)")
    print(f"   Total Secondary apps NOT Key: {int(total_secondary_not_key)}")
    print(f"   ")
    print(f"   ✓ ARA VALIDATION (vs CURRENT system risk):")
    print(f"   Possibly understated: {len(secondary_higher_either)} entities")
    print(f"   ")
    print(f"   PRIORITY BREAKDOWN (TWO-PART FIX REQUIRED):")
    print(f"   ")
    print(f"   HIGH Priority (has relevant L2s): {len(secondary_higher_either_with_l2)} entities")
    print(f"   └─ Issue: Apps not tagged as Key (methodology violation)")
    print(f"   └─ Fix: Tag Secondary apps as Key per methodology")
    print(f"   └─ Impact: IMMEDIATE (L2 pathway exists, risk will auto-calculate)")
    print(f"   ")
    print(f"   MEDIUM Priority (missing relevant L2s): {len(secondary_higher_either_without_l2)} entities")
    print(f"   └─ Issue 1: L2 Key Risks not mapped (no pathway)")
    print(f"   └─ Issue 2: Apps not tagged as Key (methodology violation)")
    print(f"   └─ Fix: Map L2s FIRST, then tag Secondary apps as Key")
    print(f"   └─ Impact: BOTH fixes needed before risk improves")
    print(f"   ")
    print(f"   ROOT CAUSE: Missing L2 mappings (foundation) AND missing Key tagging (content)")
    print(f"   BOTH must be addressed for accurate risk ratings")
else:
    print(f"✓ No issues with Secondary app tagging")

print()

# =============================================================================

print("="*70)
print("OBSERVATION 4: AUTOMATION FAILURES")
print("="*70)
print()

primary_auto_fail = summary_df[summary_df['Primary Key Auto Failure']]
secondary_auto_fail = summary_df[summary_df['Secondary Key Auto Failure']]
all_auto_fail = summary_df[summary_df['Primary Key Auto Failure'] | summary_df['Secondary Key Auto Failure']]

if len(all_auto_fail) > 0:
    print(f"⚠️  AUTOMATION FAILURES DETECTED")
    print(f"   Primary Key apps + no risk: {len(primary_auto_fail)}")
    if len(primary_auto_fail) > 0:
        print(f"   └─ Total Primary Key apps affected: {int(primary_auto_fail['Primary Key Apps'].sum())}")
    print(f"   Secondary Key apps + no risk: {len(secondary_auto_fail)}")
    if len(secondary_auto_fail) > 0:
        print(f"   └─ Total Secondary Key apps affected: {int(secondary_auto_fail['Secondary Key Apps'].sum())}")
    print(f"   ")
    print(f"   Total entities with automation failures: {len(all_auto_fail)}")
    print(f"   ")
    print(f"   Note: Check if these entities have L2 mappings or if apps have N/A ARA scores")
else:
    print(f"✓ No automation failures detected")

print()

# =============================================================================
# SUMMARY STATISTICS
# =============================================================================

print("="*70)
print("OVERALL ARA-VALIDATED IMPACT SUMMARY")
print("="*70)
print()

# Count entities with possibly misstated risk
possibly_misstated_it = len(summary_df[summary_df['Possibly Misstated IT Risk']])
possibly_misstated_is = len(summary_df[summary_df['Possibly Misstated IS Risk']])
possibly_misstated_either = len(summary_df[
    (summary_df['Possibly Misstated IT Risk']) |
    (summary_df['Possibly Misstated IS Risk'])
])

print(f"Entities with POSSIBLY MISSTATED risk:")
print(f"   IT Risk: {possibly_misstated_it} entities")
print(f"   IS Risk: {possibly_misstated_is} entities")
print(f"   Either IT or IS Risk: {possibly_misstated_either} entities ({possibly_misstated_either/len(summary_df)*100:.1f}%)")
print()
print(f"Breakdown:")
print(f"   Ghost apps (possibly wrong): {len(ghost_entities)} entities")
if len(primary_issue) > 0:
    primary_higher_either = len(primary_issue[
        (primary_issue['Primary Not Key: Higher than Current IT'] == True) |
        (primary_issue['Primary Not Key: Higher than Current IS'] == True)
    ])
    print(f"   Primary not Key (possibly understated): {primary_higher_either} entities")
if len(secondary_issue) > 0:
    secondary_higher_either = len(secondary_issue[
        (secondary_issue['Secondary Not Key: Higher than Current IT'] == True) |
        (secondary_issue['Secondary Not Key: Higher than Current IS'] == True)
    ])
    print(f"   Secondary not Key (possibly understated): {secondary_higher_either} entities")

print()

print(f"L2 Context:")
print(f"   {neither_l2} entities have NO IT/IS L2 mappings")
print(f"   └─ These correctly have no risk (no L2 pathway exists)")
print(f"   └─ Action: Map relevant L2 Key Risks to KPAs")

print()

# =============================================================================
# CREATE METHODOLOGY DOCUMENTATION
# =============================================================================

print("="*70)
print("DOCUMENTING METHODOLOGY")
print("="*70)

# Count apps in ARA file for documentation
total_ara_apps = len(ara_lookup)
ara_apps_with_scores = len([app for app, scores in ara_lookup.items() 
                             if scores['availability'] != 'N/A' or 
                                scores['integrity'] != 'N/A' or 
                                scores['confidentiality'] != 'N/A'])

# Document what was analyzed
methodology_doc = {
    'analysis_date': pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S'),
    'total_entities_analyzed': len(summary_df),
    'total_ara_records': total_ara_apps,
    'ara_records_with_scores': ara_apps_with_scores,
    'risks_file': RISKS_FILE,
    'kpa_file': KPA_FILE,
    'ara_file': ARA_FILE,
    'l2_file': L2_MAPPING_FILE,
}

print(f"✓ Documented methodology")
print()

# =============================================================================
# HELPER FUNCTION: CREATE METHODOLOGY TAB
# =============================================================================

def create_methodology_tab(observation_number, observation_name, what_was_reviewed, 
                          data_sources, analysis_steps, output_interpretation):
    """
    Creates a standardized methodology documentation tab.
    """
    methodology_df = pd.DataFrame([
        {'Section': 'OBSERVATION METHODOLOGY', 'Detail': ''},
        {'Section': '', 'Detail': ''},
        {'Section': 'Observation Number', 'Detail': observation_number},
        {'Section': 'Observation Name', 'Detail': observation_name},
        {'Section': 'Analysis Date', 'Detail': methodology_doc['analysis_date']},
        {'Section': 'Analyst', 'Detail': '[Your Name]'},
        {'Section': '', 'Detail': ''},
        {'Section': '=' * 70, 'Detail': ''},
        {'Section': 'WHAT WAS REVIEWED', 'Detail': ''},
        {'Section': '=' * 70, 'Detail': ''},
    ])
    
    # Add what was reviewed items
    for item in what_was_reviewed:
        methodology_df = pd.concat([methodology_df, pd.DataFrame([{'Section': '  • ', 'Detail': item}])], ignore_index=True)
    
    methodology_df = pd.concat([methodology_df, pd.DataFrame([
        {'Section': '', 'Detail': ''},
        {'Section': '=' * 70, 'Detail': ''},
        {'Section': 'DATA SOURCES', 'Detail': ''},
        {'Section': '=' * 70, 'Detail': ''},
    ])], ignore_index=True)
    
    # Add data sources
    for source_name, source_detail in data_sources.items():
        methodology_df = pd.concat([methodology_df, pd.DataFrame([
            {'Section': source_name, 'Detail': ''},
        ])], ignore_index=True)
        for detail_key, detail_value in source_detail.items():
            methodology_df = pd.concat([methodology_df, pd.DataFrame([
                {'Section': f'  {detail_key}', 'Detail': str(detail_value)},
            ])], ignore_index=True)
        methodology_df = pd.concat([methodology_df, pd.DataFrame([{'Section': '', 'Detail': ''}])], ignore_index=True)
    
    methodology_df = pd.concat([methodology_df, pd.DataFrame([
        {'Section': '=' * 70, 'Detail': ''},
        {'Section': 'ANALYSIS STEPS', 'Detail': ''},
        {'Section': '=' * 70, 'Detail': ''},
    ])], ignore_index=True)
    
    # Add analysis steps
    for i, step in enumerate(analysis_steps, 1):
        methodology_df = pd.concat([methodology_df, pd.DataFrame([
            {'Section': f'Step {i}', 'Detail': step},
        ])], ignore_index=True)
    
    methodology_df = pd.concat([methodology_df, pd.DataFrame([
        {'Section': '', 'Detail': ''},
        {'Section': '=' * 70, 'Detail': ''},
        {'Section': 'OUTPUT INTERPRETATION', 'Detail': ''},
        {'Section': '=' * 70, 'Detail': ''},
    ])], ignore_index=True)
    
    # Add output interpretation
    for key, value in output_interpretation.items():
        methodology_df = pd.concat([methodology_df, pd.DataFrame([
            {'Section': key, 'Detail': value},
        ])], ignore_index=True)
    
    methodology_df = pd.concat([methodology_df, pd.DataFrame([
        {'Section': '', 'Detail': ''},
        {'Section': '=' * 70, 'Detail': ''},
        {'Section': 'REPERFORMANCE INSTRUCTIONS', 'Detail': ''},
        {'Section': '=' * 70, 'Detail': ''},
        {'Section': '', 'Detail': ''},
        {'Section': 'To reperform this analysis:', 'Detail': ''},
        {'Section': '1. Obtain the source files listed above', 'Detail': ''},
        {'Section': '2. Run the Python script with these files as inputs', 'Detail': ''},
        {'Section': '3. The script will regenerate all outputs', 'Detail': ''},
        {'Section': '4. Compare results to this file', 'Detail': ''},
        {'Section': '', 'Detail': ''},
        {'Section': 'Script Location', 'Detail': '[To be filled in]'},
        {'Section': 'Script Version', 'Detail': 'v2.0 - ' + methodology_doc['analysis_date']},
    ])], ignore_index=True)
    
    return methodology_df

# =============================================================================
# EXPORT OBSERVATION 1: GHOST APPS
# =============================================================================

print("="*70)
print("EXPORTING OBSERVATION FILES")
print("="*70)

if len(ghost_entities) > 0:
    with pd.ExcelWriter(OUTPUT_OBSERVATION_1, engine='openpyxl') as writer:
        
        # ========== METHODOLOGY TAB (FIRST) ==========
        methodology_obs1 = create_methodology_tab(
            observation_number='1',
            observation_name='Ghost Applications',
            what_was_reviewed=[
                f'All {len(summary_df)} audit entities',
                f'All {len(kpa_df)} KPA records across all entities',
                f'All application mappings (Primary and Secondary) for each entity',
                'Applications tagged as "Key" in KPAs for each entity',
                f'ARA scores (Availability, Integrity, Confidentiality) for {total_ara_apps} applications',
                f'L2 Key Risk mappings for {len(l2_summary)} entities'
            ],
            data_sources={
                'Source File 1: Audit Entity Risks': {
                    'File Name': methodology_doc['risks_file'],
                    'Records': methodology_doc['total_entities_analyzed'],
                    'Key Columns Used': f'{RISKS_AE_ID_COL}, {RISKS_IT_COL}, {RISKS_IS_COL}, {RISKS_PRIMARY_APPS_COL}, {RISKS_SECONDARY_APPS_COL}',
                    'Purpose': 'Source of entity list, current risk ratings, and application mappings'
                },
                'Source File 2: KPA Tagging': {
                    'File Name': methodology_doc['kpa_file'],
                    'Records': len(kpa_df),
                    'Key Columns Used': f'{KPA_AE_ID_COL}, {KPA_KEY_APPS_COL}',
                    'Purpose': 'Source of applications tagged as "Key" in KPAs per entity'
                },
                'Source File 3: ARA Scores': {
                    'File Name': methodology_doc['ara_file'],
                    'Records': methodology_doc['total_ara_records'],
                    'Records with Scores': methodology_doc['ara_records_with_scores'],
                    'Key Columns Used': f'{ARA_APP_ID_COL}, {ARA_AVAILABILITY_COL}, {ARA_INTEGRITY_COL}, {ARA_CONFIDENTIALITY_COL}',
                    'Purpose': 'Source of risk scores for each application'
                },
                'Source File 4: L2 Key Risk Mappings': {
                    'File Name': methodology_doc['l2_file'],
                    'Records': len(l2_df),
                    'Key Columns Used': f'{L2_AE_ID_COL}, {L2_KEY_RISK_COL}, {L2_L1_CATEGORIES_COL}',
                    'Purpose': 'L2 Key Risk mappings that establish RAI pathways for risk calculation'
                }
            },
            analysis_steps=[
                f'Extracted all applications mapped to each entity (Primary + Secondary) from {RISKS_FILE}',
                f'Extracted all applications tagged as "Key" in KPAs for each entity from {KPA_FILE}',
                'For each entity, compared Key-tagged apps against mapped apps',
                'Identified "ghost apps" = apps tagged as Key in KPAs but NOT in mapped apps list',
                'Flagged entities with any ghost apps as CRITICAL issue',
                f'Retrieved ARA scores from {ARA_FILE} for ghost apps and mapped apps',
                f'Retrieved L2 Key Risk mappings from {L2_MAPPING_FILE} for context',
                'Calculated what risk would be from ghost apps vs what mapped apps would give',
                'Assessed impact: All entities with ghost apps have POSSIBLY MISSTATED risk (wrong apps being used)'
            ],
            output_interpretation={
                'Ghost Apps': 'Applications in an entity\'s KPAs that are NOT mapped to that entity (Primary or Secondary)',
                'Why Critical': 'Risk calculation uses wrong application data - the apps don\'t belong to this entity',
                'Risk Assessment': 'POSSIBLY MISSTATED - Cannot validate accuracy without identifying correct apps',
                'Entities Affected': f'{len(ghost_entities)} entities ({len(ghost_entities)/len(summary_df)*100:.1f}%)',
                'Total Ghost Apps': f'{int(total_ghost_apps)} apps across all affected entities',
                'Next Steps': 'Investigate each entity to identify correct apps, update KPAs, recalculate risk'
            }
        )
        methodology_obs1.to_excel(writer, sheet_name='Methodology', index=False)
        
        # ========== SUMMARY TAB ==========
        obs1_summary = pd.DataFrame([
            {'Metric': 'OBSERVATION 1: GHOST APPLICATIONS', 'Value': ''},
            {'Metric': '', 'Value': ''},
            {'Metric': 'Definition', 'Value': 'Apps tagged as Key in KPAs but NOT mapped to entity'},
            {'Metric': 'Severity', 'Value': 'CRITICAL'},
            {'Metric': '', 'Value': ''},
            {'Metric': 'Entities affected', 'Value': len(ghost_entities)},
            {'Metric': '% of total', 'Value': f"{len(ghost_entities)/len(summary_df)*100:.1f}%"},
            {'Metric': 'Total ghost apps', 'Value': int(total_ghost_apps)},
            {'Metric': 'Avg per entity', 'Value': f"{total_ghost_apps/len(ghost_entities):.1f}"},
            {'Metric': '', 'Value': ''},
            {'Metric': 'RISK ASSESSMENT:', 'Value': ''},
            {'Metric': 'All entities: POSSIBLY MISSTATED', 'Value': len(ghost_entities)},
            {'Metric': '', 'Value': ''},
            {'Metric': 'Impact', 'Value': 'Ghost apps are WRONG apps - correct apps unknown'},
            {'Metric': 'Note', 'Value': 'Cannot validate accuracy without identifying correct apps'},
            {'Metric': '', 'Value': ''},
            {'Metric': 'See "Methodology" tab', 'Value': 'For complete analysis documentation'},
        ])
        obs1_summary.to_excel(writer, sheet_name='Summary', index=False)
        
        # ========== ALL GHOST APPS TAB ==========
        ghost_export = ghost_entities.sort_values('# Ghost Apps (Key but Not Mapped)', ascending=False)
        ghost_export.to_excel(writer, sheet_name='All Ghost Apps', index=False)
        
        # ========== TOP 10 TAB ==========
        top_ghost = ghost_export.head(10)
        top_ghost.to_excel(writer, sheet_name='Top 10', index=False)
        
        # ========== BY TEAM AND LEADER TAB ==========
        if RISKS_CORE_TEAM_ACTUAL and RISKS_AUDIT_LEADER_ACTUAL:
            team_leader_dist = ghost_entities.groupby(['Core Audit Team', 'Audit Leader']).agg({
                'Audit Entity ID': 'count',
                '# Ghost Apps (Key but Not Mapped)': 'sum'
            }).reset_index()
            team_leader_dist.columns = ['Core Audit Team', 'Audit Leader', '# Entities', 'Total Ghost Apps']
            team_leader_dist['Risk Assessment'] = 'All: Possibly Misstated'
            team_leader_dist =team_leader_dist.sort_values(['Core Audit Team', '# Entities'], ascending=[True, False])
            team_leader_dist.to_excel(writer, sheet_name='By Team and Leader', index=False)
        elif RISKS_CORE_TEAM_ACTUAL:
            team_dist = ghost_entities.groupby('Core Audit Team').agg({
                'Audit Entity ID': 'count',
                '# Ghost Apps (Key but Not Mapped)': 'sum'
            }).reset_index()
            team_dist.columns = ['Core Audit Team', '# Entities', 'Total Ghost Apps']
            team_dist = team_dist.sort_values('# Entities', ascending=False)
            team_dist.to_excel(writer, sheet_name='By Team', index=False)
        
    print(f"✓ {OUTPUT_OBSERVATION_1}")

# =============================================================================
# EXPORT OBSERVATION 2: PRIMARY APPS NOT KEY
# =============================================================================

if len(primary_issue) > 0:
    primary_higher_it = primary_issue[primary_issue['Primary Not Key: Higher than Current IT'] == True]
    primary_higher_is = primary_issue[primary_issue['Primary Not Key: Higher than Current IS'] == True]
    primary_higher_either = primary_issue[
        (primary_issue['Primary Not Key: Higher than Current IT'] == True) |
        (primary_issue['Primary Not Key: Higher than Current IS'] == True)
    ]
    
    # Split by L2 availability
    primary_higher_either_with_l2 = primary_higher_either[
        (primary_higher_either['Has IT L2 Mappings']) |
        (primary_higher_either['Has IS L2 Mappings'])
    ]
    
    primary_higher_either_without_l2 = primary_higher_either[
        (~primary_higher_either['Has IT L2 Mappings']) &
        (~primary_higher_either['Has IS L2 Mappings'])
    ]
    
    with pd.ExcelWriter(OUTPUT_OBSERVATION_2, engine='openpyxl') as writer:
        
        # ========== METHODOLOGY TAB (FIRST) ==========
        methodology_obs2 = create_methodology_tab(
            observation_number='2',
            observation_name='Primary Applications Not Tagged as Key',
            what_was_reviewed=[
                f'All {len(summary_df)} audit entities',
                f'All applications mapped as "Primary" to each entity from {RISKS_FILE}',
                f'All applications tagged as "Key" in KPAs from {KPA_FILE}',
                f'Current IT and IS risk ratings for each entity from {RISKS_FILE}',
                f'ARA scores for all Primary apps from {ARA_FILE}',
                f'L2 Key Risk mappings from {L2_MAPPING_FILE} to identify risk calculation pathways'
            ],
            data_sources={
                'Source File 1: Audit Entity Risks': {
                    'File Name': methodology_doc['risks_file'],
                    'Records': methodology_doc['total_entities_analyzed'],
                    'Key Columns Used': f'{RISKS_AE_ID_COL}, {RISKS_IT_COL}, {RISKS_IS_COL}, {RISKS_PRIMARY_APPS_COL}',
                    'Purpose': 'Source of Primary app mappings and current risk ratings'
                },
                'Source File 2: KPA Tagging': {
                    'File Name': methodology_doc['kpa_file'],
                    'Records': len(kpa_df),
                    'Key Columns Used': f'{KPA_AE_ID_COL}, {KPA_KEY_APPS_COL}',
                    'Purpose': 'Source of which apps are tagged as "Key"'
                },
                'Source File 3: ARA Scores': {
                    'File Name': methodology_doc['ara_file'],
                    'Records': methodology_doc['total_ara_records'],
                    'Key Columns Used': f'{ARA_APP_ID_COL}, {ARA_AVAILABILITY_COL}, {ARA_INTEGRITY_COL}, {ARA_CONFIDENTIALITY_COL}',
                    'Purpose': 'Risk scores to compare current vs potential risk'
                },
                'Source File 4: L2 Key Risk Mappings': {
                    'File Name': methodology_doc['l2_file'],
                    'Records': len(l2_df),
                    'Key Columns Used': f'{L2_AE_ID_COL}, {L2_KEY_RISK_COL}, {L2_L1_CATEGORIES_COL}',
                    'Purpose': 'Determine which entities have IT/IS L2 pathways for risk calculation'
                }
            },
            analysis_steps=[
                f'Extracted all Primary apps for each entity from {RISKS_FILE}',
                f'Extracted all Key-tagged apps for each entity from {KPA_FILE}',
                'Compared Primary apps to Key apps - identified Primary apps NOT tagged as Key',
                f'Retrieved current IT and IS risk ratings from {RISKS_FILE}',
                f'Retrieved ARA scores from {ARA_FILE} for Primary not Key apps',
                'Calculated IT risk from Primary not Key apps: max(Availability, Integrity)',
                'Calculated IS risk from Primary not Key apps: Confidentiality',
                'Compared calculated risk to CURRENT system risk',
                f'Retrieved L2 Key Risk mappings from {L2_MAPPING_FILE}',
                'Split entities by L2 availability: HIGH Priority (has L2s) vs MEDIUM Priority (needs L2s)',
                'Flagged entities where Primary not Key apps have HIGHER risk than current as "Possibly Understated"'
            ],
            output_interpretation={
                'Primary Apps Not Key': 'Applications mapped as Primary but NOT tagged as Key in any KPA',
                'Why High Priority': 'These apps may should be considered for risk but currently aren\'t',
                'ARA Validation Method': 'Compared ARA scores of untagged apps to CURRENT system risk',
                'Possibly Understated': f'{len(primary_higher_either)} entities where untagged apps have HIGHER risk than current',
                'Total Entities': f'{len(primary_issue)} entities with Primary apps not Key',
                'Total Apps': f'{int(total_primary_not_key)} Primary apps not tagged as Key',
                'HIGH Priority (has L2s)': f'{len(primary_higher_either_with_l2)} entities - Tag apps as Key (immediate impact)',
                'MEDIUM Priority (no L2s)': f'{len(primary_higher_either_without_l2)} entities - Map L2s first, then tag apps',
                'TWO-PART FIX': 'L2 mappings provide the pathway; Key tagging provides the content. BOTH required.',
                'Next Steps': 'Start with HIGH Priority entities (quick wins), then address MEDIUM Priority (more work)'
            }
        )
        methodology_obs2.to_excel(writer, sheet_name='Methodology', index=False)
        
        # ========== SUMMARY TAB ==========
        obs2_summary = pd.DataFrame([
            {'Metric': 'OBSERVATION 2: PRIMARY APPS NOT TAGGED AS KEY', 'Value': ''},
            {'Metric': '', 'Value': ''},
            {'Metric': 'Definition', 'Value': 'Apps mapped as Primary but NOT tagged as Key in any KPA'},
            {'Metric': 'Severity', 'Value': 'HIGH'},
            {'Metric': '', 'Value': ''},
            {'Metric': 'Entities with Primary apps', 'Value': len(summary_df[summary_df['Total Primary Apps'] > 0])},
            {'Metric': 'Entities with Primary NOT Key', 'Value': len(primary_issue)},
            {'Metric': '% non-compliance', 'Value': f"{len(primary_issue)/len(summary_df[summary_df['Total Primary Apps'] > 0])*100:.1f}%"},
            {'Metric': 'Total Primary apps NOT Key', 'Value': int(total_primary_not_key)},
            {'Metric': '', 'Value': ''},
            {'Metric': 'ARA VALIDATION (vs CURRENT risk):', 'Value': ''},
            {'Metric': 'Possibly understated (higher risk)', 'Value': len(primary_higher_either)},
            {'Metric': '', 'Value': ''},
            {'Metric': 'PRIORITY BREAKDOWN (TWO-PART FIX):', 'Value': ''},
            {'Metric': 'HIGH Priority (has relevant L2s)', 'Value': len(primary_higher_either_with_l2)},
            {'Metric': '  Fix', 'Value': 'Review and tag apps as Key'},
            {'Metric': '  Impact', 'Value': 'IMMEDIATE (L2 pathway exists)'},
            {'Metric': '', 'Value': ''},
            {'Metric': 'MEDIUM Priority (missing relevant L2s)', 'Value': len(primary_higher_either_without_l2)},
            {'Metric': '  Fix 1', 'Value': 'Map L2 Key Risks FIRST'},
            {'Metric': '  Fix 2', 'Value': 'Then review and tag apps as Key'},
            {'Metric': '  Impact', 'Value': 'BOTH fixes needed'},
            {'Metric': '', 'Value': ''},
            {'Metric': 'ROOT CAUSE', 'Value': 'Missing L2 mappings (foundation) AND missing Key tagging (content)'},
            {'Metric': 'BOTH must be addressed', 'Value': 'For accurate risk ratings'},
            {'Metric': '', 'Value': ''},
            {'Metric': 'See "Methodology" tab', 'Value': 'For complete analysis documentation'},
        ])
        obs2_summary.to_excel(writer, sheet_name='Summary', index=False)
        
        # ========== ALL PRIMARY NOT KEY TAB ==========
        primary_export = primary_issue.sort_values('# Primary Apps Not Key', ascending=False)
        primary_export.to_excel(writer, sheet_name='All Primary Not Key', index=False)
        
        # ========== POSSIBLY UNDERSTATED - HIGH PRIORITY TAB ==========
        if len(primary_higher_either_with_l2) > 0:
            primary_high_priority = primary_higher_either_with_l2.sort_values('# Primary Apps Not Key', ascending=False)
            primary_high_priority.to_excel(writer, sheet_name='HIGH Priority (has L2s)', index=False)
        
        # ========== POSSIBLY UNDERSTATED - MEDIUM PRIORITY TAB ==========
        if len(primary_higher_either_without_l2) > 0:
            primary_medium_priority = primary_higher_either_without_l2.sort_values('# Primary Apps Not Key', ascending=False)
            primary_medium_priority.to_excel(writer, sheet_name='MEDIUM Priority (needs L2s)', index=False)
        
        # ========== HIGH COUNT TAB ==========
        high_count = primary_issue[primary_issue['# Primary Apps Not Key'] > 5].sort_values('# Primary Apps Not Key', ascending=False)
        if len(high_count) > 0:
            high_count.to_excel(writer, sheet_name='High Count (6+)', index=False)
        
        # ========== NO RISK TAB ==========
        if len(primary_no_risk) > 0:
            primary_no_risk.to_excel(writer, sheet_name='No Risk (Confirmed)', index=False)
        
        # ========== BY TEAM AND LEADER TAB ==========
        if RISKS_CORE_TEAM_ACTUAL and RISKS_AUDIT_LEADER_ACTUAL:
            team_leader_dist = primary_issue.groupby(['Core Audit Team', 'Audit Leader']).agg({
                'Audit Entity ID': 'count',
                '# Primary Apps Not Key': 'sum',
                'Primary Not Key: Higher than Current IT': 'sum',
                'Primary Not Key: Higher than Current IS': 'sum',
                'Has IT L2 Mappings': 'sum',
                'Has IS L2 Mappings': 'sum'
            }).reset_index()
            team_leader_dist.columns = ['Core Audit Team', 'Audit Leader', '# Entities', 'Total Primary Not Key', 
                                        'Higher IT Risk', 'Higher IS Risk', '# with IT L2s', '# with IS L2s']
            team_leader_dist = team_leader_dist.sort_values(['Core Audit Team', '# Entities'], ascending=[True, False])
            team_leader_dist.to_excel(writer, sheet_name='By Team and Leader', index=False)
        elif RISKS_CORE_TEAM_ACTUAL:
            team_dist = primary_issue.groupby('Core Audit Team').agg({
                'Audit Entity ID': 'count',
                '# Primary Apps Not Key': 'sum',
                'Primary Not Key: Higher than Current IT': 'sum',
                'Primary Not Key: Higher than Current IS': 'sum'
            }).reset_index()
            team_dist.columns = ['Core Audit Team', '# Entities', 'Total Primary Not Key', 'Higher IT Risk', 'Higher IS Risk']
            team_dist = team_dist.sort_values('# Entities', ascending=False)
            team_dist.to_excel(writer, sheet_name='By Team', index=False)
    
    print(f"✓ {OUTPUT_OBSERVATION_2}")

# =============================================================================
# EXPORT OBSERVATION 3: SECONDARY APPS NOT KEY
# =============================================================================

if len(secondary_issue) > 0:
    secondary_higher_it = secondary_issue[secondary_issue['Secondary Not Key: Higher than Current IT'] == True]
    secondary_higher_is = secondary_issue[secondary_issue['Secondary Not Key: Higher than Current IS'] == True]
    secondary_higher_either = secondary_issue[
        (secondary_issue['Secondary Not Key: Higher than Current IT'] == True) |
        (secondary_issue['Secondary Not Key: Higher than Current IS'] == True)
    ]
    
    # Split by L2 availability
    secondary_higher_either_with_l2 = secondary_higher_either[
        (secondary_higher_either['Has IT L2 Mappings']) |
        (secondary_higher_either['Has IS L2 Mappings'])
    ]
    
    secondary_higher_either_without_l2 = secondary_higher_either[
        (~secondary_higher_either['Has IT L2 Mappings']) &
        (~secondary_higher_either['Has IS L2 Mappings'])
    ]
    
    with pd.ExcelWriter(OUTPUT_OBSERVATION_3, engine='openpyxl') as writer:
        
        # ========== METHODOLOGY TAB ==========
        methodology_obs3 = create_methodology_tab(
            observation_number='3',
            observation_name='Secondary Applications Not Tagged as Key',
            what_was_reviewed=[
                f'All {len(summary_df)} audit entities',
                f'All applications mapped as "Secondary" to each entity from {RISKS_FILE}',
                f'All applications tagged as "Key" in KPAs from {KPA_FILE}',
                f'Documented methodology rule: "Secondary apps should be identified as a key application in at least one KPA"',
                f'Current IT and IS risk ratings from {RISKS_FILE}',
                f'ARA scores for all Secondary apps from {ARA_FILE}',
                f'L2 Key Risk mappings from {L2_MAPPING_FILE} to identify risk calculation pathways'
            ],
            data_sources={
                'Source File 1: Audit Entity Risks': {
                    'File Name': methodology_doc['risks_file'],
                    'Records': methodology_doc['total_entities_analyzed'],
                    'Key Columns Used': f'{RISKS_AE_ID_COL}, {RISKS_IT_COL}, {RISKS_IS_COL}, {RISKS_SECONDARY_APPS_COL}',
                    'Purpose': 'Source of Secondary app mappings and current risk ratings'
                },
                'Source File 2: KPA Tagging': {
                    'File Name': methodology_doc['kpa_file'],
                    'Records': len(kpa_df),
                    'Key Columns Used': f'{KPA_AE_ID_COL}, {KPA_KEY_APPS_COL}',
                    'Purpose': 'Source of which apps are tagged as "Key"'
                },
                'Source File 3: ARA Scores': {
                    'File Name': methodology_doc['ara_file'],
                    'Records': methodology_doc['total_ara_records'],
                    'Key Columns Used': f'{ARA_APP_ID_COL}, {ARA_AVAILABILITY_COL}, {ARA_INTEGRITY_COL}, {ARA_CONFIDENTIALITY_COL}',
                    'Purpose': 'Risk scores to validate impact'
                },
                'Source File 4: L2 Key Risk Mappings': {
                    'File Name': methodology_doc['l2_file'],
                    'Records': len(l2_df),
                    'Key Columns Used': f'{L2_AE_ID_COL}, {L2_KEY_RISK_COL}, {L2_L1_CATEGORIES_COL}',
                    'Purpose': 'Determine which entities have IT/IS L2 pathways for risk calculation'
                }
            },
            analysis_steps=[
                f'Extracted all Secondary apps for each entity from {RISKS_FILE}',
                f'Extracted all Key-tagged apps for each entity from {KPA_FILE}',
                'Compared Secondary apps to Key apps - identified Secondary apps NOT tagged as Key',
                'Flagged as methodology violation (documented rule requires Secondary → Key)',
                f'Retrieved current IT and IS risk from {RISKS_FILE}',
                f'Retrieved ARA scores from {ARA_FILE} for Secondary not Key apps',
                'Compared ARA scores of untagged apps to CURRENT system risk',
                f'Retrieved L2 Key Risk mappings from {L2_MAPPING_FILE}',
                'Split entities by L2 availability: HIGH Priority (has L2s) vs MEDIUM Priority (needs L2s)',
                'Flagged "Possibly Understated" where untagged apps have higher risk than current'
            ],
            output_interpretation={
                'Secondary Apps Not Key': 'Apps mapped as Secondary but NOT tagged as Key - violates documented methodology',
                'Methodology Rule': 'Secondary apps should be identified as a key application in at least one KPA',
                'Severity': 'HIGH - Direct methodology violation + potential risk understatement',
                'Possibly Understated': f'{len(secondary_higher_either)} entities where untagged apps have higher risk',
                'HIGH Priority (has L2s)': f'{len(secondary_higher_either_with_l2)} entities - Tag apps as Key (immediate impact)',
                'MEDIUM Priority (no L2s)': f'{len(secondary_higher_either_without_l2)} entities - Map L2s first, then tag apps',
                'TWO-PART FIX': 'L2 mappings provide the pathway; Key tagging provides the content. BOTH required.',
                'Next Steps': 'Systematic tagging of Secondary apps as Key per methodology'
            }
        )
        methodology_obs3.to_excel(writer, sheet_name='Methodology', index=False)
        
        # ========== SUMMARY TAB ==========
        obs3_summary = pd.DataFrame([
            {'Metric': 'OBSERVATION 3: SECONDARY APPS NOT TAGGED AS KEY', 'Value': ''},
            {'Metric': '', 'Value': ''},
            {'Metric': 'Definition', 'Value': 'Apps mapped as Secondary but NOT tagged as Key in any KPA'},
            {'Metric': 'Rule', 'Value': 'Secondary apps should be Key in at least one KPA'},
            {'Metric': 'Severity', 'Value': 'HIGH - Methodology Violation'},
            {'Metric': '', 'Value': ''},
            {'Metric': 'Entities with Secondary apps', 'Value': len(summary_df[summary_df['Total Secondary Apps'] > 0])},
            {'Metric': 'Entities with Secondary NOT Key', 'Value': len(secondary_issue)},
            {'Metric': '% non-compliance', 'Value': f"{len(secondary_issue)/len(summary_df[summary_df['Total Secondary Apps'] > 0])*100:.1f}%"},
            {'Metric': 'Total Secondary apps NOT Key', 'Value': int(total_secondary_not_key)},
            {'Metric': '', 'Value': ''},
            {'Metric': 'ARA VALIDATION (vs CURRENT risk):', 'Value': ''},
            {'Metric': 'Possibly understated (higher risk)', 'Value': len(secondary_higher_either)},
            {'Metric': '', 'Value': ''},
            {'Metric': 'PRIORITY BREAKDOWN (TWO-PART FIX):', 'Value': ''},
            {'Metric': 'HIGH Priority (has relevant L2s)', 'Value': len(secondary_higher_either_with_l2)},
            {'Metric': '  Fix', 'Value': 'Tag Secondary apps as Key per methodology'},
            {'Metric': '  Impact', 'Value': 'IMMEDIATE (L2 pathway exists)'},
            {'Metric': '', 'Value': ''},
            {'Metric': 'MEDIUM Priority (missing relevant L2s)', 'Value': len(secondary_higher_either_without_l2)},
            {'Metric': '  Fix 1', 'Value': 'Map L2 Key Risks FIRST'},
            {'Metric': '  Fix 2', 'Value': 'Then tag Secondary apps as Key'},
            {'Metric': '  Impact', 'Value': 'BOTH fixes needed'},
            {'Metric': '', 'Value': ''},
            {'Metric': 'ROOT CAUSE', 'Value': 'Missing L2 mappings (foundation) AND missing Key tagging (content)'},
            {'Metric': 'BOTH must be addressed', 'Value': 'For accurate risk ratings'},
            {'Metric': '', 'Value': ''},
            {'Metric': 'See "Methodology" tab', 'Value': 'For complete analysis documentation'},
        ])
        obs3_summary.to_excel(writer, sheet_name='Summary', index=False)
        
        # ========== ALL SECONDARY NOT KEY TAB ==========
        secondary_export = secondary_issue.sort_values('# Secondary Apps Not Key', ascending=False)
        secondary_export.to_excel(writer, sheet_name='All Secondary Not Key', index=False)
        
        # ========== POSSIBLY UNDERSTATED - HIGH PRIORITY TAB ==========
        if len(secondary_higher_either_with_l2) > 0:
            secondary_high_priority = secondary_higher_either_with_l2.sort_values('# Secondary Apps Not Key', ascending=False)
            secondary_high_priority.to_excel(writer, sheet_name='HIGH Priority (has L2s)', index=False)
        
        # ========== POSSIBLY UNDERSTATED - MEDIUM PRIORITY TAB ==========
        if len(secondary_higher_either_without_l2) > 0:
            secondary_medium_priority = secondary_higher_either_without_l2.sort_values('# Secondary Apps Not Key', ascending=False)
            secondary_medium_priority.to_excel(writer, sheet_name='MEDIUM Priority (needs L2s)', index=False)
        
        # ========== NO RISK TAB ==========
        if len(secondary_no_risk) > 0:
            secondary_no_risk.to_excel(writer, sheet_name='No Risk (Confirmed)', index=False)
        
        # ========== BY TEAM AND LEADER TAB ==========
        if RISKS_CORE_TEAM_ACTUAL and RISKS_AUDIT_LEADER_ACTUAL:
            team_leader_dist = secondary_issue.groupby(['Core Audit Team', 'Audit Leader']).agg({
                'Audit Entity ID': 'count',
                '# Secondary Apps Not Key': 'sum',
                'Secondary Not Key: Higher than Current IT': 'sum',
                'Secondary Not Key: Higher than Current IS': 'sum',
                'Has IT L2 Mappings': 'sum',
                'Has IS L2 Mappings': 'sum'
            }).reset_index()
            team_leader_dist.columns = ['Core Audit Team', 'Audit Leader', '# Entities', 'Total Secondary Not Key',
                                        'Higher IT Risk', 'Higher IS Risk', '# with IT L2s', '# with IS L2s']
            team_leader_dist = team_leader_dist.sort_values(['Core Audit Team', '# Entities'], ascending=[True, False])
            team_leader_dist.to_excel(writer, sheet_name='By Team and Leader', index=False)
        elif RISKS_CORE_TEAM_ACTUAL:
            team_dist = secondary_issue.groupby('Core Audit Team').agg({
                'Audit Entity ID': 'count',
                '# Secondary Apps Not Key': 'sum',
                'Secondary Not Key: Higher than Current IT': 'sum',
                'Secondary Not Key: Higher than Current IS': 'sum'
            }).reset_index()
            team_dist.columns = ['Core Audit Team', '# Entities', 'Total Secondary Not Key', 'Higher IT Risk', 'Higher IS Risk']
            team_dist = team_dist.sort_values('# Entities', ascending=False)
            team_dist.to_excel(writer, sheet_name='By Team', index=False)
    
    print(f"✓ {OUTPUT_OBSERVATION_3}")

# =============================================================================
# EXPORT OBSERVATION 4: AUTOMATION FAILURES
# =============================================================================

if len(all_auto_fail) > 0:
    with pd.ExcelWriter(OUTPUT_OBSERVATION_4, engine='openpyxl') as writer:
        
        # ========== METHODOLOGY TAB ==========
        methodology_obs4 = create_methodology_tab(
            observation_number='4',
            observation_name='Automation Failures',
            what_was_reviewed=[
                f'All {len(summary_df)} audit entities',
                'Entities with Primary Key apps (apps mapped as Primary AND tagged as Key)',
                'Entities with Secondary Key apps (apps mapped as Secondary AND tagged as Key)',
                f'Current IT and IS risk applicability status from {RISKS_FILE}',
                f'L2 Key Risk mappings from {L2_MAPPING_FILE}',
                'Expected behavior: Key apps should automatically populate IT/IS risk'
            ],
            data_sources={
                'Source File 1: Audit Entity Risks': {
                    'File Name': methodology_doc['risks_file'],
                    'Records': methodology_doc['total_entities_analyzed'],
                    'Key Columns Used': f'{RISKS_AE_ID_COL}, {RISKS_IT_COL}, {RISKS_IS_COL}, {RISKS_PRIMARY_APPS_COL}, {RISKS_SECONDARY_APPS_COL}',
                    'Purpose': 'Source of current risk status and app mappings'
                },
                'Source File 2: KPA Tagging': {
                    'File Name': methodology_doc['kpa_file'],
                    'Records': len(kpa_df),
                    'Key Columns Used': f'{KPA_AE_ID_COL}, {KPA_KEY_APPS_COL}',
                    'Purpose': 'Identify which apps are tagged as Key'
                },
                'Source File 3: L2 Key Risk Mappings': {
                    'File Name': methodology_doc['l2_file'],
                    'Records': len(l2_df),
                    'Key Columns Used': f'{L2_AE_ID_COL}, {L2_KEY_RISK_COL}, {L2_L1_CATEGORIES_COL}',
                    'Purpose': 'Determine if entities have L2 pathways for risk calculation'
                }
            },
            analysis_steps=[
                'Identified entities with Primary Key apps (Primary mapped AND Key tagged)',
                'Identified entities with Secondary Key apps (Secondary mapped AND Key tagged)',
                f'Retrieved current IT/IS risk status from {RISKS_FILE}',
                'Risk values considered "applicable": Critical, High, Medium, Low',
                'Risk values considered "not applicable": N/A, blank, or any other value',
                'Flagged entities with Key apps but NO IT/IS risk as automation failures',
                f'Cross-referenced with L2 mappings from {L2_MAPPING_FILE}',
                'Note: Most "no risk" cases explained by missing L2 mappings (not automation failures)'
            ],
            output_interpretation={
                'Automation Failure': 'Key apps exist but IT/IS risk NOT populated',
                'Expected Behavior': 'When apps are tagged as Key, system should auto-populate risk from ARA scores',
                'Total Entities': f'{len(all_auto_fail)} entities',
                'Primary Key Failures': f'{len(primary_auto_fail)} entities',
                'Secondary Key Failures': f'{len(secondary_auto_fail)} entities',
                'L2 Context': f'{neither_l2} entities have NO L2 mappings (explains most "no risk" cases)',
                'Why High Priority': 'Risk should exist but is missing - automation not working as designed',
                'Next Steps': 'Investigate with IT Applications team - check for timing issues, manual overrides, or system bugs'
            }
        )
        methodology_obs4.to_excel(writer, sheet_name='Methodology', index=False)
        
        # ========== SUMMARY TAB ==========
        obs4_summary = pd.DataFrame([
            {'Metric': 'OBSERVATION 4: AUTOMATION FAILURES', 'Value': ''},
            {'Metric': '', 'Value': ''},
            {'Metric': 'Definition', 'Value': 'Key apps exist but IT/IS risk NOT populated'},
            {'Metric': 'Severity', 'Value': 'HIGH'},
            {'Metric': '', 'Value': ''},
            {'Metric': 'Primary Key + no risk', 'Value': len(primary_auto_fail)},
            {'Metric': 'Secondary Key + no risk', 'Value': len(secondary_auto_fail)},
            {'Metric': 'Total entities', 'Value': len(all_auto_fail)},
            {'Metric': '', 'Value': ''},
            {'Metric': 'Total Primary Key apps affected', 'Value': int(primary_auto_fail['Primary Key Apps'].sum()) if len(primary_auto_fail) > 0 else 0},
            {'Metric': 'Total Secondary Key apps affected', 'Value': int(secondary_auto_fail['Secondary Key Apps'].sum()) if len(secondary_auto_fail) > 0 else 0},
            {'Metric': '', 'Value': ''},
            {'Metric': 'Impact', 'Value': 'Risk should be populated but is not'},
            {'Metric': '', 'Value': ''},
            {'Metric': 'L2 CONTEXT:', 'Value': ''},
            {'Metric': f'{neither_l2} entities have NO L2 mappings', 'Value': 'This explains most "no risk" cases'},
            {'Metric': 'Note', 'Value': 'Check if these 3 entities have L2s or N/A ARA scores'},
            {'Metric': '', 'Value': ''},
            {'Metric': 'See "Methodology" tab', 'Value': 'For complete analysis documentation'},
        ])
        obs4_summary.to_excel(writer, sheet_name='Summary', index=False)
        
        # ========== ALL AUTOMATION FAILURES TAB ==========
        all_auto_fail_sorted = all_auto_fail.sort_values(['Primary Key Apps', 'Secondary Key Apps'], ascending=False)
        all_auto_fail_sorted.to_excel(writer, sheet_name='All Automation Failures', index=False)
        
        # ========== PRIMARY KEY FAILURES TAB ==========
        if len(primary_auto_fail) > 0:
            primary_auto_fail.to_excel(writer, sheet_name='Primary Key Failures', index=False)
        
        # ========== SECONDARY KEY FAILURES TAB ==========
        if len(secondary_auto_fail) > 0:
            secondary_auto_fail.to_excel(writer, sheet_name='Secondary Key Failures', index=False)
        
        # ========== BYTEAM AND LEADER TAB ==========
        if RISKS_CORE_TEAM_ACTUAL and RISKS_AUDIT_LEADER_ACTUAL:
            team_leader_dist = all_auto_fail.groupby(['Core Audit Team', 'Audit Leader']).agg({
                'Audit Entity ID': 'count',
                'Primary Key Apps': 'sum',
                'Secondary Key Apps': 'sum'
            }).reset_index()
            team_leader_dist.columns = ['Core Audit Team', 'Audit Leader', '# Entities', 'Total Primary Key Apps', 'Total Secondary Key Apps']
            team_leader_dist = team_leader_dist.sort_values(['Core Audit Team', '# Entities'], ascending=[True, False])
            team_leader_dist.to_excel(writer, sheet_name='By Team and Leader', index=False)
        elif RISKS_CORE_TEAM_ACTUAL:
            team_dist = all_auto_fail.groupby('Core Audit Team').agg({
                'Audit Entity ID': 'count',
                'Primary Key Apps': 'sum',
                'Secondary Key Apps': 'sum'
            }).reset_index()
            team_dist.columns = ['Core Audit Team', '# Entities', 'Total Primary Key Apps', 'Total Secondary Key Apps']
            team_dist = team_dist.sort_values('# Entities', ascending=False)
            team_dist.to_excel(writer, sheet_name='By Team', index=False)
    
    print(f"✓ {OUTPUT_OBSERVATION_4}")

# =============================================================================
# EXPORT EXECUTIVE SUMMARY
# =============================================================================

# Calculate overall metrics for executive summary
if len(primary_issue) > 0:
    primary_higher_either = len(primary_issue[
        (primary_issue['Primary Not Key: Higher than Current IT'] == True) |
        (primary_issue['Primary Not Key: Higher than Current IS'] == True)
    ])
    primary_higher_either_with_l2 = len(primary_issue[
        ((primary_issue['Primary Not Key: Higher than Current IT'] == True) |
         (primary_issue['Primary Not Key: Higher than Current IS'] == True)) &
        ((primary_issue['Has IT L2 Mappings']) | (primary_issue['Has IS L2 Mappings']))
    ])
    primary_higher_either_without_l2 = primary_higher_either - primary_higher_either_with_l2
else:
    primary_higher_either = 0
    primary_higher_either_with_l2 = 0
    primary_higher_either_without_l2 = 0

if len(secondary_issue) > 0:
    secondary_higher_either = len(secondary_issue[
        (secondary_issue['Secondary Not Key: Higher than Current IT'] == True) |
        (secondary_issue['Secondary Not Key: Higher than Current IS'] == True)
    ])
    secondary_higher_either_with_l2 = len(secondary_issue[
        ((secondary_issue['Secondary Not Key: Higher than Current IT'] == True) |
         (secondary_issue['Secondary Not Key: Higher than Current IS'] == True)) &
        ((secondary_issue['Has IT L2 Mappings']) | (secondary_issue['Has IS L2 Mappings']))
    ])
    secondary_higher_either_without_l2 = secondary_higher_either - secondary_higher_either_with_l2
else:
    secondary_higher_either = 0
    secondary_higher_either_with_l2 = 0
    secondary_higher_either_without_l2 = 0

with pd.ExcelWriter(OUTPUT_EXECUTIVE_SUMMARY, engine='openpyxl') as writer:
    
    # ========== METHODOLOGY TAB (FIRST) ==========
    exec_methodology = pd.DataFrame([
        {'Section': 'IT/IS RISK APPLICABILITY ANALYSIS', 'Detail': ''},
        {'Section': 'OVERALL METHODOLOGY DOCUMENTATION', 'Detail': ''},
        {'Section': '', 'Detail': ''},
        {'Section': 'Analysis Date', 'Detail': methodology_doc['analysis_date']},
        {'Section': 'Analyst', 'Detail': '[Your Name]'},
        {'Section': 'Scope', 'Detail': f"{methodology_doc['total_entities_analyzed']} audit entities"},
        {'Section': '', 'Detail': ''},
        {'Section': '=' * 70, 'Detail': ''},
        {'Section': 'OBJECTIVE', 'Detail': ''},
        {'Section': '=' * 70, 'Detail': ''},
        {'Section': '', 'Detail': ''},
        {'Section': 'Primary Objective', 'Detail': 'Validate accuracy of IT/IS risk ratings across audit universe'},
        {'Section': '', 'Detail': ''},
        {'Section': 'Specific Questions', 'Detail': ''},
        {'Section': '  1.', 'Detail': 'Are the correct applications being used to calculate risk?'},
        {'Section': '  2.', 'Detail': 'Are all relevant applications tagged as "Key" per methodology?'},
        {'Section': '  3.', 'Detail': 'Do current risk ratings reflect actual application risk levels (per ARA)?'},
        {'Section': '  4.', 'Detail': 'Is the automation working as designed?'},
        {'Section': '  5.', 'Detail': 'Are L2 Key Risk mappings in place to enable risk calculation?'},
        {'Section': '', 'Detail': ''},
        {'Section': '=' * 70, 'Detail': ''},
        {'Section': 'DATA SOURCES - ALL OBSERVATIONS', 'Detail': ''},
        {'Section': '=' * 70, 'Detail': ''},
        {'Section': '', 'Detail': ''},
        {'Section': 'File 1: Audit Entity Risks', 'Detail': ''},
        {'Section': '  File Name', 'Detail': methodology_doc['risks_file']},
        {'Section': '  Records', 'Detail': methodology_doc['total_entities_analyzed']},
        {'Section': '  Purpose', 'Detail': 'Master list of entities, risk ratings, and app mappings'},
        {'Section': '  Key Columns', 'Detail': f'{RISKS_AE_ID_COL}, {RISKS_IT_COL}, {RISKS_IS_COL}'},
        {'Section': '  Key Columns', 'Detail': f'{RISKS_PRIMARY_APPS_COL}, {RISKS_SECONDARY_APPS_COL}'},
        {'Section': '', 'Detail': ''},
        {'Section': 'File 2: KPA Tagging', 'Detail': ''},
        {'Section': '  File Name', 'Detail': methodology_doc['kpa_file']},
        {'Section': '  Records', 'Detail': len(kpa_df)},
        {'Section': '  Purpose', 'Detail': 'Applications tagged as "Key" in KPAs per entity'},
        {'Section': '  Key Columns', 'Detail': f'{KPA_AE_ID_COL}, {KPA_KEY_APPS_COL}'},
        {'Section': '', 'Detail': ''},
        {'Section': 'File 3: ARA Scores', 'Detail': ''},
        {'Section': '  File Name', 'Detail': methodology_doc['ara_file']},
        {'Section': '  Records', 'Detail': methodology_doc['total_ara_records']},
        {'Section': '  Records with Scores', 'Detail': methodology_doc['ara_records_with_scores']},
        {'Section': '  Purpose', 'Detail': 'Risk scores (Availability, Integrity, Confidentiality) per app'},
        {'Section': '  Key Columns', 'Detail': f'{ARA_APP_ID_COL}, {ARA_AVAILABILITY_COL}'},
        {'Section': '  Key Columns', 'Detail': f'{ARA_INTEGRITY_COL}, {ARA_CONFIDENTIALITY_COL}'},
        {'Section': '', 'Detail': ''},
        {'Section': 'File 4: L2 Key Risk Mappings', 'Detail': ''},
        {'Section': '  File Name', 'Detail': methodology_doc['l2_file']},
        {'Section': '  Records', 'Detail': len(l2_df)},
        {'Section': '  Purpose', 'Detail': 'L2 Key Risk mappings that establish RAI pathways for risk calculation'},
        {'Section': '  Key Columns', 'Detail': f'{L2_AE_ID_COL}, {L2_KEY_RISK_COL}, {L2_L1_CATEGORIES_COL}'},
        {'Section': '', 'Detail': ''},
        {'Section': '=' * 70, 'Detail': ''},
        {'Section': 'ANALYSIS APPROACH', 'Detail': ''},
        {'Section': '=' * 70, 'Detail': ''},
        {'Section': '', 'Detail': ''},
        {'Section': 'Step 1: Data Integration', 'Detail': 'Combined all four data sources by entity ID and app ID'},
        {'Section': '', 'Detail': ''},
        {'Section': 'Step 2: Issue Identification', 'Detail': 'Identified four categories of issues:'},
        {'Section': '  Observation 1', 'Detail': 'Ghost Apps - apps in KPAs not mapped to entity'},
        {'Section': '  Observation 2', 'Detail': 'Primary apps not tagged as Key'},
        {'Section': '  Observation 3', 'Detail': 'Secondary apps not tagged as Key (methodology violation)'},
        {'Section': '  Observation 4', 'Detail': 'Automation failures - Key apps but no risk'},
        {'Section': '', 'Detail': ''},
        {'Section': 'Step 3: L2 Key Risk Analysis', 'Detail': 'Analyzed L2 mappings to understand risk calculation pathways:'},
        {'Section': '  IT L2 Mappings', 'Detail': f'{both_l2 + only_it_l2} entities have IT L2 Key Risks mapped'},
        {'Section': '  IS L2 Mappings', 'Detail': f'{both_l2 + only_is_l2} entities have IS L2 Key Risks mapped'},
        {'Section': '  No L2 Mappings', 'Detail': f'{neither_l2} entities have NO IT or IS L2 mappings'},
        {'Section': '  Impact', 'Detail': 'Without L2 mappings, RAI cannot populate (no pathway for risk calculation)'},
        {'Section': '', 'Detail': ''},
        {'Section': 'Step 4: ARA Validation', 'Detail': 'For each issue, validated impact using ARA scores:'},
        {'Section': '  IT Risk Calculation', 'Detail': 'max(Availability, Integrity) across apps'},
        {'Section': '  IS Risk Calculation', 'Detail': 'max(Confidentiality) across apps'},
        {'Section': '  Comparison Logic', 'Detail': 'Compared to CURRENT system risk (not expected)'},
        {'Section': '', 'Detail': ''},
        {'Section': 'Step 5: Priority Classification', 'Detail': 'Categorized findings by L2 availability:'},
        {'Section': '  HIGH Priority', 'Detail': 'Entity has relevant L2s → Tag apps as Key (immediate impact)'},
        {'Section': '  MEDIUM Priority', 'Detail': 'Entity lacks L2s → Map L2s first, then tag apps'},
        {'Section': '', 'Detail': ''},
        {'Section': 'Step 6: Impact Assessment', 'Detail': 'Categorized findings:'},
        {'Section': '  Ghost Apps', 'Detail': 'POSSIBLY MISSTATED (wrong apps - cannot validate without correct apps)'},
        {'Section': '  Apps Not Key', 'Detail': 'POSSIBLY UNDERSTATED (when untagged apps have higher risk than current)'},
        {'Section': '  Apps Not Key', 'Detail': 'APPEARS CORRECT (when untagged apps have same/lower risk)'},
        {'Section': '', 'Detail': ''},
        {'Section': '=' * 70, 'Detail': ''},
        {'Section': 'KEY FINDINGS: TWO-PART FIX REQUIRED', 'Detail': ''},
        {'Section': '=' * 70, 'Detail': ''},
        {'Section': '', 'Detail': ''},
        {'Section': 'Finding 1: L2 Key Risk Mappings', 'Detail': 'Foundation for risk calculation'},
        {'Section': f'  {neither_l2} entities', 'Detail': 'Have NO IT or IS L2 mappings'},
        {'Section': '  Impact', 'Detail': 'RAI cannot populate without L2 pathway'},
        {'Section': '  Fix', 'Detail': 'Map relevant IT and IS L2 Key Risks to KPAs'},
        {'Section': '', 'Detail': ''},
        {'Section': 'Finding 2: Key Application Tagging', 'Detail': 'Content for risk calculation'},
        {'Section': f'  {len(primary_issue)} entities', 'Detail': 'Have Primary apps not tagged as Key'},
        {'Section': f'  {len(secondary_issue)} entities', 'Detail': 'Have Secondary apps not tagged as Key'},
        {'Section': '  Impact', 'Detail': 'Risk calculation missing input apps'},
        {'Section': '  Fix', 'Detail': 'Review and tag relevant apps as Key in KPAs'},
        {'Section': '', 'Detail': ''},
        {'Section': 'BOTH FIXES ARE REQUIRED', 'Detail': ''},
        {'Section': '  Without L2 mappings', 'Detail': 'No pathway → Even Key apps won\'t calculate risk'},
        {'Section': '  Without Key tagging', 'Detail': 'No content → Even with L2s, risk has no input'},
        {'Section': '  Order matters', 'Detail': 'Map L2s FIRST (pathway), then tag apps (content)'},
        {'Section': '', 'Detail': ''},
        {'Section': '=' * 70, 'Detail': ''},
        {'Section': 'KEY ASSUMPTIONS AND LIMITATIONS', 'Detail': ''},
        {'Section': '=' * 70, 'Detail': ''},
        {'Section': '', 'Detail': ''},
        {'Section': 'Assumption 1', 'Detail': 'ARA scores are current and accurate'},
        {'Section': 'Assumption 2', 'Detail': 'Application mappings in source file are correct'},
        {'Section': 'Assumption 3', 'Detail': 'Risk values Critical/High/Medium/Low indicate applicable risk'},
        {'Section': 'Assumption 4', 'Detail': 'L2 Key Risk mappings are current and complete'},
        {'Section': '', 'Detail': ''},
        {'Section': 'Limitation 1', 'Detail': 'Cannot determine which apps SHOULD be Key without business context'},
        {'Section': 'Limitation 2', 'Detail': 'Cannot identify correct apps for ghost apps without investigation'},
        {'Section': 'Limitation 3', 'Detail': 'Comparison is against CURRENT system risk (which may itself be wrong)'},
        {'Section': '', 'Detail': ''},
        {'Section': 'Language Used', 'Detail': '"Possibly misstated" - acknowledges lack of full context'},
        {'Section': '', 'Detail': '"Possibly understated" - ARA shows higher risk, but may have valid reasons'},
        {'Section': '', 'Detail': '"Appears correct" - based on current data, no indication of issue'},
        {'Section': '', 'Detail': ''},
        {'Section': '=' * 70, 'Detail': ''},
        {'Section': 'OBSERVATIONS SUMMARY', 'Detail': ''},
        {'Section': '=' * 70, 'Detail': ''},
        {'Section': '', 'Detail': ''},
        {'Section': 'Observation 1: Ghost Applications', 'Detail': ''},
        {'Section': '  Entities', 'Detail': len(ghost_entities) if len(ghost_entities) > 0 else 0},
        {'Section': '  Assessment', 'Detail': 'All: Possibly Misstated'},
        {'Section': '  Detail File', 'Detail': OUTPUT_OBSERVATION_1 if len(ghost_entities) > 0 else 'N/A'},
        {'Section': '', 'Detail': ''},
        {'Section': 'Observation 2: Primary Apps Not Key', 'Detail': ''},
        {'Section': '  Entities', 'Detail': len(primary_issue) if len(primary_issue) > 0 else 0},
        {'Section': '  Possibly Understated', 'Detail': primary_higher_either},
        {'Section': '    HIGH Priority (has L2s)', 'Detail': primary_higher_either_with_l2},
        {'Section': '    MEDIUM Priority (needs L2s)', 'Detail': primary_higher_either_without_l2},
        {'Section': '  Detail File', 'Detail': OUTPUT_OBSERVATION_2 if len(primary_issue) > 0 else 'N/A'},
        {'Section': '', 'Detail': ''},
        {'Section': 'Observation 3: Secondary Apps Not Key', 'Detail': ''},
        {'Section': '  Entities', 'Detail': len(secondary_issue) if len(secondary_issue) > 0 else 0},
        {'Section': '  Possibly Understated', 'Detail': secondary_higher_either},
        {'Section': '    HIGH Priority (has L2s)', 'Detail': secondary_higher_either_with_l2},
        {'Section': '    MEDIUM Priority (needs L2s)', 'Detail': secondary_higher_either_without_l2},
        {'Section': '  Detail File', 'Detail': OUTPUT_OBSERVATION_3 if len(secondary_issue) > 0 else 'N/A'},
        {'Section': '', 'Detail': ''},
        {'Section': 'Observation 4: Automation Failures', 'Detail': ''},
        {'Section': '  Entities', 'Detail': len(all_auto_fail) if len(all_auto_fail) > 0 else 0},
        {'Section': '  Assessment', 'Detail': 'Risk missing when it should exist'},
        {'Section': '  Detail File', 'Detail': OUTPUT_OBSERVATION_4 if len(all_auto_fail) > 0 else 'N/A'},
        {'Section': '', 'Detail': ''},
        {'Section': '=' * 70, 'Detail': ''},
        {'Section': 'REPERFORMANCE INSTRUCTIONS', 'Detail': ''},
        {'Section': '=' * 70, 'Detail': ''},
        {'Section': '', 'Detail': ''},
        {'Section': 'To reperform this entire analysis:', 'Detail': ''},
        {'Section': '', 'Detail': ''},
        {'Section': '1. Obtain Source Files', 'Detail': ''},
        {'Section': '   •', 'Detail': methodology_doc['risks_file']},
        {'Section': '   •', 'Detail': methodology_doc['kpa_file']},
        {'Section': '   •', 'Detail': methodology_doc['ara_file']},
        {'Section': '   •', 'Detail': methodology_doc['l2_file']},
        {'Section': '', 'Detail': ''},
        {'Section': '2. Verify File Structure', 'Detail': ''},
        {'Section': '   • Ensure column names match configuration in script', 'Detail': ''},
        {'Section': '   • Verify data types (IDs as text, risks as text)', 'Detail': ''},
        {'Section': '   • Check for expected number of records', 'Detail': ''},
        {'Section': '', 'Detail': ''},
        {'Section': '3. Run Python Script', 'Detail': ''},
        {'Section': '   • Script name', 'Detail': '[To be filled in]'},
        {'Section': '   • Script version', 'Detail': 'v2.0 - ' + methodology_doc['analysis_date']},
        {'Section': '   • Python version', 'Detail': '3.7 or higher'},
        {'Section': '   • Required libraries', 'Detail': 'pandas, openpyxl'},
        {'Section': '', 'Detail': ''},
        {'Section': '4. Review Outputs', 'Detail': ''},
        {'Section': '   •', 'Detail': OUTPUT_EXECUTIVE_SUMMARY + ' (this file)'},
        {'Section': '   •', 'Detail': OUTPUT_OBSERVATION_1 + ' (if ghost apps found)'},
        {'Section': '   •', 'Detail': OUTPUT_OBSERVATION_2 + ' (if Primary not Key found)'},
        {'Section': '   •', 'Detail': OUTPUT_OBSERVATION_3 + ' (if Secondary not Key found)'},
        {'Section': '   •', 'Detail': OUTPUT_OBSERVATION_4 + ' (if automation failures found)'},
        {'Section': '   •', 'Detail': OUTPUT_FULL_ANALYSIS + ' (complete dataset)'},
        {'Section': '', 'Detail': ''},
        {'Section': '5. Compare Results', 'Detail': ''},
        {'Section': '   • Check entity counts match', 'Detail': ''},
        {'Section': '   • Verify issue counts match', 'Detail': ''},
        {'Section': '   • Spot-check specific entities', 'Detail': ''},
        {'Section': '', 'Detail': ''},
        {'Section': 'Script Logic', 'Detail': 'See individual Observation files for detailed step-by-step methodology'},
    ])
    exec_methodology.to_excel(writer, sheet_name='Methodology', index=False)
    
    # ========== EXECUTIVE SUMMARY TAB ==========
    exec_summary = pd.DataFrame([
        {'Metric': 'IT/IS RISK APPLICABILITY ANALYSIS', 'Value': '', 'Details': ''},
        {'Metric': 'EXECUTIVE SUMMARY (ARA-Validated with L2 Context)', 'Value': '', 'Details': ''},
        {'Metric': 'Comparison: Apps vs CURRENT SYSTEM RISK', 'Value': '', 'Details': ''},
        {'Metric': '', 'Value': '', 'Details': ''},
        {'Metric': 'Analysis Date', 'Value': methodology_doc['analysis_date'], 'Details': ''},
        {'Metric': 'Scope', 'Value': len(summary_df), 'Details': 'audit entities analyzed'},
        {'Metric': '', 'Value': '', 'Details': ''},
        {'Metric': 'OBSERVATION 1: Ghost Applications', 'Value': '', 'Details': 'CRITICAL'},
        {'Metric': '└─ Entities affected', 'Value': len(ghost_entities) if len(ghost_entities) > 0 else 0, 'Details': f"{len(ghost_entities)/len(summary_df)*100:.1f}%" if len(ghost_entities) > 0 else '0%'},
        {'Metric': '└─ Total ghost apps', 'Value': int(total_ghost_apps) if len(ghost_entities) > 0 else 0, 'Details': ''},
        {'Metric': '└─ Risk Assessment', 'Value': len(ghost_entities) if len(ghost_entities) > 0 else 0, 'Details': 'POSSIBLY MISSTATED (wrong apps)'},
        {'Metric': '', 'Value': '', 'Details': ''},
        {'Metric': 'OBSERVATION 2: Primary Apps Not Key', 'Value': '', 'Details': 'HIGH'},
        {'Metric': '└─ Entities affected', 'Value': len(primary_issue) if len(primary_issue) > 0 else 0, 'Details': f"{len(primary_issue)/len(summary_df)*100:.1f}%" if len(primary_issue) > 0 else '0%'},
        {'Metric': '└─ Total Primary apps not Key', 'Value': int(total_primary_not_key) if len(primary_issue) > 0 else 0, 'Details': ''},
        {'Metric': '└─ ARA: Possibly understated', 'Value': primary_higher_either, 'Details': 'higher risk than current'},
        {'Metric': '   └─ HIGH Priority (has L2s)', 'Value': primary_higher_either_with_l2, 'Details': 'immediate impact'},
        {'Metric': '   └─ MEDIUM Priority (needs L2s)', 'Value': primary_higher_either_without_l2, 'Details': 'L2s + tagging'},
        {'Metric': '', 'Value': '', 'Details': ''},
        {'Metric': 'OBSERVATION 3: Secondary Apps Not Key', 'Value': '', 'Details': 'HIGH'},
        {'Metric': '└─ Entities affected', 'Value': len(secondary_issue) if len(secondary_issue) > 0 else 0, 'Details': f"{len(secondary_issue)/len(summary_df)*100:.1f}%" if len(secondary_issue) > 0 else '0%'},
        {'Metric': '└─ Total Secondary apps not Key', 'Value': int(total_secondary_not_key) if len(secondary_issue) > 0 else 0, 'Details': 'methodology violation'},
        {'Metric': '└─ ARA: Possibly understated', 'Value': secondary_higher_either, 'Details': 'higher risk than current'},
        {'Metric': '   └─ HIGH Priority (has L2s)', 'Value': secondary_higher_either_with_l2, 'Details': 'immediate impact'},
        {'Metric': '   └─ MEDIUM Priority (needs L2s)', 'Value': secondary_higher_either_without_l2, 'Details': 'L2s + tagging'},
        {'Metric': '', 'Value': '', 'Details': ''},
        {'Metric': 'OBSERVATION 4: Automation Failures', 'Value': '', 'Details': 'HIGH'},
        {'Metric': '└─ Entities affected', 'Value': len(all_auto_fail) if len(all_auto_fail) > 0 else 0, 'Details': 'Key apps but no risk'},
        {'Metric': '', 'Value': '', 'Details': ''},
        {'Metric': 'TOTAL ENTITIES WITH ANY ISSUE', 'Value': len(summary_df[summary_df['ANY ISSUE']]), 'Details': f"{len(summary_df[summary_df['ANY ISSUE']])/len(summary_df)*100:.1f}%"},
        {'Metric': '', 'Value': '', 'Details': ''},
        {'Metric': 'L2 KEY RISK CONTEXT', 'Value': '', 'Details': ''},
        {'Metric': '└─ Both IT and IS L2s mapped', 'Value': both_l2, 'Details': f"{both_l2/len(summary_df)*100:.1f}%"},
        {'Metric': '└─ Only IT L2s mapped', 'Value': only_it_l2, 'Details': f"{only_it_l2/len(summary_df)*100:.1f}%"},
        {'Metric': '└─ Only IS L2s mapped', 'Value': only_is_l2, 'Details': f"{only_is_l2/len(summary_df)*100:.1f}%"},
        {'Metric': '└─ NO IT or IS L2s mapped', 'Value': neither_l2, 'Details': f"{neither_l2/len(summary_df)*100:.1f}%"},
        {'Metric': '', 'Value': '', 'Details': ''},
        {'Metric': 'TWO-PART FIX REQUIRED', 'Value': '', 'Details': ''},
        {'Metric': '1. L2 Key Risk Mappings (Foundation)', 'Value': f'{neither_l2} entities need L2s', 'Details': 'Establishes RAI pathway'},
        {'Metric': '2. Key Application Tagging (Content)', 'Value': f'{len(summary_df[summary_df["ANY ISSUE"]])} entities need review', 'Details': 'Provides risk input'},
        {'Metric': 'BOTH fixes required', 'Value': 'L2s provide pathway; Key tagging provides content', 'Details': ''},
        {'Metric': '', 'Value': '', 'Details': ''},
        {'Metric': 'See "Methodology" tab', 'Value': 'For complete analysis documentation', 'Details': ''},
    ])
    exec_summary.to_excel(writer, sheet_name='Executive Summary', index=False)
    
    # ========== OBSERVATION COMPARISON TAB ==========
    obs_comparison = pd.DataFrame([
        {
            'Observation': '1 - Ghost Apps',
            'Severity': 'CRITICAL',
            'Entities': len(ghost_entities) if len(ghost_entities) > 0 else 0,
            '% of Total': f"{len(ghost_entities)/len(summary_df)*100:.1f}%" if len(ghost_entities) > 0 else '0%',
            'Apps Affected': int(total_ghost_apps) if len(ghost_entities) > 0 else 0,
            'ARA Assessment': f"All {len(ghost_entities)} POSSIBLY MISSTATED (wrong apps)" if len(ghost_entities) > 0 else 'None',
            'File': OUTPUT_OBSERVATION_1 if len(ghost_entities) > 0 else 'N/A'
        },
        {
            'Observation': '2 - Primary Not Key',
            'Severity': 'HIGH',
            'Entities': len(primary_issue) if len(primary_issue) > 0 else 0,
            '% of Total': f"{len(primary_issue)/len(summary_df)*100:.1f}%" if len(primary_issue) > 0 else '0%',
            'Apps Affected': int(total_primary_not_key) if len(primary_issue) > 0 else 0,
            'ARA Assessment': f"HIGH Priority (has L2s): {primary_higher_either_with_l2}, MEDIUM Priority (needs L2s): {primary_higher_either_without_l2}" if len(primary_issue) > 0 else 'None',
            'File': OUTPUT_OBSERVATION_2 if len(primary_issue) > 0 else 'N/A'
        },
        {
            'Observation': '3 - Secondary Not Key',
            'Severity': 'HIGH',
            'Entities': len(secondary_issue) if len(secondary_issue) > 0 else 0,
            '% of Total': f"{len(secondary_issue)/len(summary_df)*100:.1f}%" if len(secondary_issue) > 0 else '0%',
            'Apps Affected': int(total_secondary_not_key) if len(secondary_issue) > 0 else 0,
            'ARA Assessment': f"HIGH Priority (has L2s): {secondary_higher_either_with_l2}, MEDIUM Priority (needs L2s): {secondary_higher_either_without_l2}" if len(secondary_issue) > 0 else 'None',
            'File': OUTPUT_OBSERVATION_3 if len(secondary_issue) > 0 else 'N/A'
        },
        {
            'Observation': '4 - Automation Failures',
            'Severity': 'HIGH',
            'Entities': len(all_auto_fail) if len(all_auto_fail) > 0 else 0,
            '% of Total': f"{len(all_auto_fail)/len(summary_df)*100:.1f}%" if len(all_auto_fail) > 0 else '0%',
            'Apps Affected': int(primary_auto_fail['Primary Key Apps'].sum() + secondary_auto_fail['Secondary Key Apps'].sum()) if len(all_auto_fail) > 0 else 0,
            'ARA Assessment': 'Risk should exist but missing',
            'File': OUTPUT_OBSERVATION_4 if len(all_auto_fail) > 0 else 'N/A'
        }
    ])
    obs_comparison.to_excel(writer, sheet_name='Observation Comparison', index=False)
    
    # ========== BY TEAM AND LEADER TAB ==========
    if RISKS_CORE_TEAM_ACTUAL and RISKS_AUDIT_LEADER_ACTUAL:
        team_leader_summary = summary_df.groupby(['Core Audit Team', 'Audit Leader']).agg({
            'Audit Entity ID': 'count',
            'CRITICAL: Ghost Apps': 'sum',
            'HIGH: Primary Not Key': 'sum',
            'HIGH: Secondary Not Key': 'sum',
            'Primary Key Auto Failure': 'sum',
            'Secondary Key Auto Failure': 'sum',
            'Ghost Apps Present': 'sum',
            'Primary Not Key: Higher than Current IT': 'sum',
            'Primary Not Key: Higher than Current IS': 'sum',
            'Secondary Not Key: Higher than Current IT': 'sum',
            'Secondary Not Key: Higher than Current IS': 'sum',
            'Has IT L2 Mappings': 'sum',
            'Has IS L2 Mappings': 'sum'
        }).reset_index()
        
        team_leader_summary.columns = [
            'Core Audit Team',
            'Audit Leader',
            'Total Entities',
            'Ghost Apps',
            'Primary Not Key',
            'Secondary Not Key',
            'Primary Auto Fail',
            'Secondary Auto Fail',
            'Ghost: Possibly Misstated',
            'Primary: Higher IT (ARA)',
            'Primary: Higher IS (ARA)',
            'Secondary: Higher IT (ARA)',
            'Secondary: Higher IS (ARA)',
            '# Entities with IT L2s',
            '# Entities with IS L2s'
        ]
        
        team_leader_summary['Total Issues'] = (
            team_leader_summary['Ghost Apps'] +
            team_leader_summary['Primary Not Key'] +
            team_leader_summary['Secondary Not Key'] +
            team_leader_summary['Primary Auto Fail'] +
            team_leader_summary['Secondary Auto Fail']
        )
        
        team_leader_summary['ARA: Possibly Misstated'] = (
            team_leader_summary['Ghost: Possibly Misstated'] +
            team_leader_summary['Primary: Higher IT (ARA)'] +
            team_leader_summary['Primary: Higher IS (ARA)'] +
            team_leader_summary['Secondary: Higher IT (ARA)'] +
            team_leader_summary['Secondary: Higher IS (ARA)']
        )
        
        team_leader_summary['% Entities With Issues'] = round((team_leader_summary['Total Issues'] / team_leader_summary['Total Entities']) * 100, 1)
        
        team_leader_summary = team_leader_summary.sort_values(['Core Audit Team', 'ARA: Possibly Misstated'], ascending=[True, False])
        
        team_leader_summary.to_excel(writer, sheet_name='By Team and Leader', index=False)
    
    elif RISKS_CORE_TEAM_ACTUAL:
        team_summary = summary_df.groupby('Core Audit Team').agg({
            'Audit Entity ID': 'count',
            'CRITICAL: Ghost Apps': 'sum',
            'HIGH: Primary Not Key': 'sum',
            'HIGH: Secondary Not Key': 'sum',
            'Primary Key Auto Failure': 'sum',
            'Secondary Key Auto Failure': 'sum',
            'Ghost Apps Present': 'sum',
            'Primary Not Key: Higher than Current IT': 'sum',
            'Primary Not Key: Higher than Current IS': 'sum',
            'Secondary Not Key: Higher than Current IT': 'sum',
            'Secondary Not Key: Higher than Current IS': 'sum',
            'Has IT L2 Mappings': 'sum',
            'Has IS L2 Mappings': 'sum'
        }).reset_index()
        
        team_summary.columns = [
            'Core Audit Team',
            'Total Entities',
            'Ghost Apps',
            'Primary Not Key',
            'Secondary Not Key',
            'Primary Auto Fail',
            'Secondary Auto Fail',
            'Ghost: Possibly Misstated',
            'Primary: Higher IT (ARA)',
            'Primary: Higher IS (ARA)',
            'Secondary: Higher IT (ARA)',
            'Secondary: Higher IS (ARA)',
            '# Entities with IT L2s',
            '# Entities with IS L2s'
        ]
        
        team_summary['Total Issues'] = (
            team_summary['Ghost Apps'] +
            team_summary['Primary Not Key'] +
            team_summary['Secondary Not Key'] +
            team_summary['Primary Auto Fail'] +
            team_summary['Secondary Auto Fail']
        )
        
        team_summary['ARA: Possibly Misstated'] = (
            team_summary['Ghost: Possibly Misstated'] +
            team_summary['Primary: Higher IT (ARA)'] +
            team_summary['Primary: Higher IS (ARA)'] +
            team_summary['Secondary: Higher IT (ARA)'] +
            team_summary['Secondary: Higher IS (ARA)']
        )
        
        team_summary['% Entities With Issues'] = round((team_summary['Total Issues'] / team_summary['Total Entities']) * 100, 1)
        
        team_summary = team_summary.sort_values('ARA: Possibly Misstated', ascending=False)
        
        team_summary.to_excel(writer, sheet_name='By Team', index=False)

print(f"✓ {OUTPUT_EXECUTIVE_SUMMARY}")

# =============================================================================
# EXPORT FULL ANALYSIS (SOURCE DATA)
# =============================================================================

# Reorder columns for better readability
cols_order = [
    'Audit Entity ID',
    'Core Audit Team',
    'Audit Leader',
    
    # L2 MAPPINGS (NEW)
    'Has IT L2 Mappings',
    'Has IS L2 Mappings',
    'Has Third Party L2 Mappings',
    '# IT L2 Key Risks',
    '# IS L2 Key Risks',
    '# Third Party L2 Key Risks',
    
    # Flags
    'CRITICAL: Ghost Apps',
    'HIGH: Primary Not Key',
    'HIGH: Secondary Not Key',
    'ANY ISSUE',
    
    # Issue counts
    '# Ghost Apps (Key but Not Mapped)',
    '# Primary Apps Not Key',
    '# Secondary Apps Not Key',
    
    # Current risk
    'Current IT Risk',
    'Current IS Risk',
    'Any IT/IS Risk Applicable',
    
    # Risk assessments
    'IT Risk Assessment',
    'IS Risk Assessment',
    'Possibly Misstated IT Risk',
    'Possibly Misstated IS Risk',
    
    # ARA comparison results
    'Primary Not Key: Higher than Current IT',
    'Primary Not Key: Higher than Current IS',
    'Secondary Not Key: Higher than Current IT',
    'Secondary Not Key: Higher than Current IS',
    'ALL Mapped Apps: Higher than Current IT',
    'ALL Mapped Apps: Higher than Current IS',
    
    # Risk from different app sets
    'Risk from Key Apps (incl ghosts)',
    'IS Risk from Key Apps (incl ghosts)',
    'Risk from ALL Mapped Apps',
    'IS Risk from ALL Mapped Apps',
    'Ghost Apps IT Risk',
    'Ghost Apps IS Risk',
    'Primary Not Key IT Risk',
    'Primary Not Key IS Risk',
    'Secondary Not Key IT Risk',
    'Secondary Not Key IS Risk',
    
    # App counts
    'Total Primary Apps',
    'Total Secondary Apps',
    'Total Mapped Apps',
    'Primary Key Apps',
    'Secondary Key Apps',
    'Total Key Apps',
    
    # Detail columns
    'Ghost App IDs',
    'Primary Not Key IDs',
    'Secondary Not Key IDs',
    'Key App Driving IT (incl ghosts)',
    'Key App Driving IS (incl ghosts)',
    
    # L2 detail
    'IT L2 Risk Names',
    'IS L2 Risk Names',
    'Third Party L2 Risk Names',
]

# Add remaining columns not in the order list
remaining_cols = [col for col in summary_df.columns if col not in cols_order]
summary_df_export = summary_df[cols_order + remaining_cols]

summary_df_export.to_excel(OUTPUT_FULL_ANALYSIS, index=False)
print(f"✓ {OUTPUT_FULL_ANALYSIS}")

# =============================================================================
# FINAL SUMMARY
# =============================================================================

print("\n" + "="*70)
print("ANALYSIS COMPLETE")
print("="*70)
print(f"\n📊 Files Created:")
print(f"   {OUTPUT_EXECUTIVE_SUMMARY} ← Start here (includes Methodology)")
if len(ghost_entities) > 0:
    print(f"   {OUTPUT_OBSERVATION_1} (Methodology tab included)")
if len(primary_issue) > 0:
    print(f"   {OUTPUT_OBSERVATION_2} (Methodology tab included)")
if len(secondary_issue) > 0:
    print(f"   {OUTPUT_OBSERVATION_3} (Methodology tab included)")
if len(all_auto_fail) > 0:
    print(f"   {OUTPUT_OBSERVATION_4} (Methodology tab included)")
print(f"   {OUTPUT_FULL_ANALYSIS} (Complete dataset)")

print(f"\n📁 Each observation file contains:")
print(f"   - Methodology tab (FIRST - documents what was reviewed)")
print(f"   - Summary tab (key metrics)")
print(f"   - Analysis tabs (all data, ARA validation, priority breakdown)")
if RISKS_CORE_TEAM_ACTUAL and RISKS_AUDIT_LEADER_ACTUAL:
    print(f"   - By Team and Leader tab (accountability)")
elif RISKS_CORE_TEAM_ACTUAL:
    print(f"   - By Team tab (distribution)")

print(f"\n✓ METHODOLOGY DOCUMENTED")
print(f"   All files include complete reperformance instructions")
print(f"   Data sources, analysis steps, and interpretation documented")
print(f"   Audit-ready workpaper trail")

print(f"\n✓ ARA VALIDATION COMPLETE")
print(f"   Comparison: Apps vs CURRENT SYSTEM RISK")
print(f"   Ghost apps: Possibly misstated (unknown correct apps)")
print(f"   Untagged apps: Possibly understated when higher than current")
print(f"   {possibly_misstated_either} entities with possibly misstated risk")
print(f"   IT and IS tracked separately throughout")

print(f"\n✓ L2 KEY RISK CONTEXT ADDED")
print(f"   {both_l2} entities have both IT and IS L2 mappings")
print(f"   {neither_l2} entities have NO IT or IS L2 mappings")
print(f"   Priority breakdown: HIGH (has L2s) vs MEDIUM (needs L2s)")
print(f"   Two-part fix documented: L2 mappings + Key tagging")

print(f"\n📋 TO REPERFORM THIS ANALYSIS:")
print(f"   1. See 'Methodology' tab in {OUTPUT_EXECUTIVE_SUMMARY}")
print(f"   2. Follow documented steps with source files")
print(f"   3. Compare results to these outputs")

print(f"\n🔑 KEY TAKEAWAY:")
print(f"   TWO FIXES REQUIRED:")
print(f"   1. L2 Key Risk Mappings (foundation/pathway)")
print(f"   2. Key Application Tagging (content/input)")
print(f"   BOTH must be addressed for accurate risk ratings")

print("\n" + "="*70)
