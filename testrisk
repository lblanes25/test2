"""
IT/IS RISK APPLICABILITY ANALYSIS
Version: 1.0
Created: [Date]
Analyst: [Your Name]

SCRIPT LOCATION: [To be filled in - path to this script file]

PURPOSE:
Validates accuracy of IT/IS risk ratings across audit universe by:
1. Identifying ghost applications (apps in KPAs not mapped to entity)
2. Identifying apps not tagged as Key (Primary and Secondary)
3. Validating impact using ARA scores
4. Comparing to current system risk

OUTPUTS:
- 00_ExecutiveSummary.xlsx (overall results with methodology)
- Observation1_GhostApps.xlsx (if found)
- Observation2_PrimaryNotKey.xlsx (if found)
- Observation3_SecondaryNotKey.xlsx (if found)
- Observation4_AutomationFailures.xlsx (if found)
- SourceData_FullAnalysis.xlsx (complete dataset)

Each output file includes Methodology tab for reperformance.

CONFIGURATION:
Update file names and column names in CONFIGURATION section below.
"""

import pandas as pd
import re

# =============================================================================
# CONFIGURATION - UPDATE YOUR FILE/COLUMN NAMES HERE
# =============================================================================

# Input file names
RISKS_FILE = "audit_entity_risks.xlsx"
KPA_FILE = "kpa_tagging.xlsx"
ARA_FILE = "all_applications.xlsx"

# Sheet names
RISKS_SHEET = 0
KPA_SHEET = 0
ARA_SHEET = 0

# Column names in RISKS file (case-insensitive matching will be applied)
RISKS_AE_ID_COL = "Audit Entity ID"
RISKS_IT_COL = "Information Technology Inherent Risk"
RISKS_IS_COL = "Information Security Inherent Risk"
RISKS_PRIMARY_APPS_COL = "Primary IT applications (mapped)"
RISKS_SECONDARY_APPS_COL = "Secondary IT applications (Related or Relied on)"
RISKS_CORE_TEAM_COL = "Core Audit Team"
RISKS_AUDIT_LEADER_COL = "Audit Leader"

# Column names in KPA file (case-insensitive matching will be applied)
KPA_AE_ID_COL = "Audit Entity ID"
KPA_ID_COL = "KPA ID"
KPA_KEY_APPS_COL = "KEY PRIMARY & SECONDARY IT applications"

# Column names in ARA file
ARA_APP_ID_COL = "Application Risk Assessment(ARA) Records (Centall Applications)"
ARA_AVAILABILITY_COL = "Availability Risk"
ARA_INTEGRITY_COL = "Integrity Risk"
ARA_CONFIDENTIALITY_COL = "Confidentiality Risk"

# Output file names - ORGANIZED BY OBSERVATION
OUTPUT_OBSERVATION_1 = "Observation1_GhostApps.xlsx"
OUTPUT_OBSERVATION_2 = "Observation2_PrimaryNotKey.xlsx"
OUTPUT_OBSERVATION_3 = "Observation3_SecondaryNotKey.xlsx"
OUTPUT_OBSERVATION_4 = "Observation4_AutomationFailures.xlsx"
OUTPUT_EXECUTIVE_SUMMARY = "00_ExecutiveSummary.xlsx"
OUTPUT_FULL_ANALYSIS = "SourceData_FullAnalysis.xlsx"

# Risk values that indicate the risk IS applicable
RISK_APPLICABLE_VALUES = ['Critical', 'High', 'Medium', 'Low']

# Risk scale for comparison (in order of severity)
RISK_SCALE = {
    'Critical': 4,
    'High': 3,
    'Medium': 2,
    'Low': 1,
    'N/A': 0,
    None: 0,
    '': 0
}

# =============================================================================
# LOAD DATA
# =============================================================================

print("="*70)
print("LOADING DATA")
print("="*70)

risks_df = pd.read_excel(RISKS_FILE, sheet_name=RISKS_SHEET)
kpa_df = pd.read_excel(KPA_FILE, sheet_name=KPA_SHEET)
ara_df = pd.read_excel(ARA_FILE, sheet_name=ARA_SHEET)

print(f"✓ Loaded {len(risks_df)} audit entities from risks file")
print(f"✓ Loaded {len(kpa_df)} KPA records")
print(f"✓ Loaded {len(ara_df)} ARA records")
print()

# =============================================================================
# HELPER FUNCTION: CASE-INSENSITIVE COLUMN MATCHING
# =============================================================================

def find_column(df, target_col, optional=False):
    """
    Find a column in the dataframe using case-insensitive matching.
    Returns the actual column name from the dataframe.
    If optional=True, returns None if column not found.
    """
    if target_col is None:
        return None
        
    col_map = {col.lower().strip(): col for col in df.columns}
    actual_col = col_map.get(target_col.lower().strip())
    
    if actual_col is None and not optional:
        raise ValueError(f"Column '{target_col}' not found in dataframe. Available columns: {list(df.columns)}")
    
    return actual_col

# Map configured column names to actual column names
RISKS_AE_ID_ACTUAL = find_column(risks_df, RISKS_AE_ID_COL)
RISKS_IT_ACTUAL = find_column(risks_df, RISKS_IT_COL)
RISKS_IS_ACTUAL = find_column(risks_df, RISKS_IS_COL)
RISKS_PRIMARY_APPS_ACTUAL = find_column(risks_df, RISKS_PRIMARY_APPS_COL)
RISKS_SECONDARY_APPS_ACTUAL = find_column(risks_df, RISKS_SECONDARY_APPS_COL)
RISKS_CORE_TEAM_ACTUAL = find_column(risks_df, RISKS_CORE_TEAM_COL, optional=True)
RISKS_AUDIT_LEADER_ACTUAL = find_column(risks_df, RISKS_AUDIT_LEADER_COL, optional=True)

KPA_AE_ID_ACTUAL = find_column(kpa_df, KPA_AE_ID_COL)
KPA_ID_ACTUAL = find_column(kpa_df, KPA_ID_COL)
KPA_KEY_APPS_ACTUAL = find_column(kpa_df, KPA_KEY_APPS_COL)

ARA_APP_ID_ACTUAL = find_column(ara_df, ARA_APP_ID_COL)
ARA_AVAILABILITY_ACTUAL = find_column(ara_df, ARA_AVAILABILITY_COL)
ARA_INTEGRITY_ACTUAL = find_column(ara_df, ARA_INTEGRITY_COL)
ARA_CONFIDENTIALITY_ACTUAL = find_column(ara_df, ARA_CONFIDENTIALITY_COL)

print("="*70)
print("COLUMN MAPPING")
print("="*70)
print(f"✓ Risks file - AE ID: '{RISKS_AE_ID_ACTUAL}'")
print(f"✓ Risks file - IT Risk: '{RISKS_IT_ACTUAL}'")
print(f"✓ Risks file - IS Risk: '{RISKS_IS_ACTUAL}'")
if RISKS_CORE_TEAM_ACTUAL:
    print(f"✓ Risks file - Core Team: '{RISKS_CORE_TEAM_ACTUAL}'")
if RISKS_AUDIT_LEADER_ACTUAL:
    print(f"✓ Risks file - Audit Leader: '{RISKS_AUDIT_LEADER_ACTUAL}'")
print(f"✓ KPA file - AE ID: '{KPA_AE_ID_ACTUAL}'")
print(f"✓ ARA file - App ID: '{ARA_APP_ID_ACTUAL}'")
print(f"✓ ARA file - Availability: '{ARA_AVAILABILITY_ACTUAL}'")
print(f"✓ ARA file - Integrity: '{ARA_INTEGRITY_ACTUAL}'")
print(f"✓ ARA file - Confidentiality: '{ARA_CONFIDENTIALITY_ACTUAL}'")
print()

# =============================================================================
# CREATE ARA LOOKUP DICTIONARY
# =============================================================================

print("="*70)
print("BUILDING ARA LOOKUP")
print("="*70)

ara_lookup = {}
for _, row in ara_df.iterrows():
    app_id = str(row[ARA_APP_ID_ACTUAL]).strip()
    ara_lookup[app_id] = {
        'availability': row[ARA_AVAILABILITY_ACTUAL] if pd.notna(row[ARA_AVAILABILITY_ACTUAL]) else 'N/A',
        'integrity': row[ARA_INTEGRITY_ACTUAL] if pd.notna(row[ARA_INTEGRITY_ACTUAL]) else 'N/A',
        'confidentiality': row[ARA_CONFIDENTIALITY_ACTUAL] if pd.notna(row[ARA_CONFIDENTIALITY_ACTUAL]) else 'N/A'
    }

print(f"✓ Created ARA lookup for {len(ara_lookup)} applications")
print()

# =============================================================================
# HELPER FUNCTION: PARSE MULTI-VALUE CELLS
# =============================================================================

def split_ids(value):
    """
    Convert comma/newline/semicolon-separated IDs into a clean list.
    Strips whitespace from each ID and filters out empty strings.
    """
    if pd.isna(value):
        return []
    ids = re.split(r'[\n,;]+', str(value).strip())
    return [x.strip() for x in ids if x.strip()]

# =============================================================================
# HELPER FUNCTIONS: ARA RISK CALCULATIONS
# =============================================================================

def get_risk_level(risk_value):
    """Convert risk value to numeric level for comparison"""
    if pd.isna(risk_value):
        return 0
    return RISK_SCALE.get(str(risk_value).strip(), 0)

def risk_to_string(risk_level):
    """Convert numeric risk level back to string"""
    for key, value in RISK_SCALE.items():
        if value == risk_level and key not in ['N/A', None, '']:
            return key
    return 'N/A'

def calculate_it_risk_from_apps(app_ids, ara_lookup):
    """
    Calculate IT risk from list of apps using ARA scores.
    IT Risk = max(Availability, Integrity) across all apps.
    Returns tuple: (risk_level_numeric, risk_string, detail_dict)
    """
    if not app_ids:
        return 0, 'N/A', {}
    
    max_risk = 0
    detail = {'apps_evaluated': [], 'max_app': None, 'max_score_type': None}
    
    for app_id in app_ids:
        if not app_id or app_id not in ara_lookup:
            continue
            
        ara = ara_lookup[app_id]
        avail_level = get_risk_level(ara['availability'])
        integ_level = get_risk_level(ara['integrity'])
        
        # IT Risk is the HIGHER of availability or integrity
        app_it_risk = max(avail_level, integ_level)
        
        detail['apps_evaluated'].append({
            'app_id': app_id,
            'availability': ara['availability'],
            'integrity': ara['integrity'],
            'it_risk': risk_to_string(app_it_risk)
        })
        
        if app_it_risk > max_risk:
            max_risk = app_it_risk
            detail['max_app'] = app_id
            detail['max_score_type'] = 'Availability' if avail_level > integ_level else 'Integrity'
    
    return max_risk, risk_to_string(max_risk), detail

def calculate_is_risk_from_apps(app_ids, ara_lookup):
    """
    Calculate IS risk from list of apps using ARA scores.
    IS Risk = max(Confidentiality) across all apps.
    Returns tuple: (risk_level_numeric, risk_string, detail_dict)
    """
    if not app_ids:
        return 0, 'N/A', {}
    
    max_risk = 0
    detail = {'apps_evaluated': [], 'max_app': None}
    
    for app_id in app_ids:
        if not app_id or app_id not in ara_lookup:
            continue
            
        ara = ara_lookup[app_id]
        confid_level = get_risk_level(ara['confidentiality'])
        
        detail['apps_evaluated'].append({
            'app_id': app_id,
            'confidentiality': ara['confidentiality'],
            'is_risk': risk_to_string(confid_level)
        })
        
        if confid_level > max_risk:
            max_risk = confid_level
            detail['max_app'] = app_id
    
    return max_risk, risk_to_string(max_risk), detail

# =============================================================================
# EXTRACT PRIMARY AND SECONDARY APPS PER AUDIT ENTITY
# =============================================================================

risks_df['Primary_List'] = risks_df[RISKS_PRIMARY_APPS_ACTUAL].apply(split_ids)
risks_df['Secondary_List'] = risks_df[RISKS_SECONDARY_APPS_ACTUAL].apply(split_ids)

ae_primary_map = dict(zip(risks_df[RISKS_AE_ID_ACTUAL], risks_df['Primary_List']))
ae_secondary_map = dict(zip(risks_df[RISKS_AE_ID_ACTUAL], risks_df['Secondary_List']))

# Extract team info if available
if RISKS_CORE_TEAM_ACTUAL:
    ae_core_team_map = dict(zip(risks_df[RISKS_AE_ID_ACTUAL], risks_df[RISKS_CORE_TEAM_ACTUAL]))
else:
    ae_core_team_map = {}

if RISKS_AUDIT_LEADER_ACTUAL:
    ae_audit_leader_map = dict(zip(risks_df[RISKS_AE_ID_ACTUAL], risks_df[RISKS_AUDIT_LEADER_ACTUAL]))
else:
    ae_audit_leader_map = {}

# =============================================================================
# EXTRACT KEY-TAGGED APPS FROM KPA DATA (PER ENTITY)
# =============================================================================

kpa_df['Key_List'] = kpa_df[KPA_KEY_APPS_ACTUAL].apply(split_ids)

# Aggregate all Key apps per AE (across all KPAs)
kpa_key_map = (
    kpa_df.groupby(KPA_AE_ID_ACTUAL)['Key_List']
    .apply(lambda x: set([item for sublist in x for item in sublist]))
    .to_dict()
)

# =============================================================================
# MAIN ANALYSIS: BUILD COMPREHENSIVE DATASET WITH ARA VALIDATION
# =============================================================================

print("="*70)
print("ANALYZING DATA WITH ARA VALIDATION")
print("="*70)
print("Comparison Logic: Apps vs CURRENT SYSTEM RISK")
print()

rows = []

for ae_id in risks_df[RISKS_AE_ID_ACTUAL]:
    # Get primary and secondary apps
    primary_apps = ae_primary_map.get(ae_id, [])
    secondary_apps = ae_secondary_map.get(ae_id, [])
    
    # Get team info
    core_team = ae_core_team_map.get(ae_id, 'Unknown') if ae_core_team_map else 'Unknown'
    audit_leader = ae_audit_leader_map.get(ae_id, 'Unknown') if ae_audit_leader_map else 'Unknown'
    
    # Get all mapped apps
    all_mapped_apps = set(primary_apps + secondary_apps)
    
    # Get Key apps for THIS entity's KPAs
    key_apps_set = kpa_key_map.get(ae_id, set())
    
    # ========== GHOST APP DETECTION ==========
    ghost_apps = [aid for aid in key_apps_set if aid and aid not in all_mapped_apps]
    
    # ========== PRIMARY APP ANALYSIS ==========
    primary_key = [aid for aid in primary_apps if aid and aid in key_apps_set]
    primary_not_key = [aid for aid in primary_apps if aid and aid not in key_apps_set]
    
    # ========== SECONDARY APP ANALYSIS ==========
    secondary_key = [aid for aid in secondary_apps if aid and aid in key_apps_set]
    secondary_not_key = [aid for aid in secondary_apps if aid and aid not in key_apps_set]
    
    # Calculate metrics
    total_primary = len([aid for aid in primary_apps if aid])
    total_secondary = len([aid for aid in secondary_apps if aid])
    total_apps = total_primary + total_secondary
    total_mapped_apps = len(all_mapped_apps)
    
    total_primary_key = len(primary_key)
    total_secondary_key = len(secondary_key)
    total_key_apps = len(key_apps_set)
    
    num_ghost_apps = len(ghost_apps)
    num_primary_not_key = len(primary_not_key)
    num_secondary_not_key = len(secondary_not_key)
    
    pct_primary_not_key = round((num_primary_not_key / total_primary) * 100, 1) if total_primary else 0
    pct_secondary_not_key = round((num_secondary_not_key / total_secondary) * 100, 1) if total_secondary else 0
    
    # Pull CURRENT risk from system
    risks_row = risks_df[risks_df[RISKS_AE_ID_ACTUAL] == ae_id]
    
    if len(risks_row) > 0:
        current_it_risk = risks_row[RISKS_IT_ACTUAL].values[0]
        current_is_risk = risks_row[RISKS_IS_ACTUAL].values[0]
    else:
        current_it_risk = 'N/A'
        current_is_risk = 'N/A'
    
    # Get numeric levels for CURRENT system risk
    current_it_level = get_risk_level(current_it_risk)
    current_is_level = get_risk_level(current_is_risk)
    
    # ========== ARA VALIDATION: COMPARE AGAINST CURRENT SYSTEM RISK ==========
    
    # Calculate risk from ALL mapped apps (what it COULD be if all were Key)
    all_mapped_app_ids = list(all_mapped_apps)
    all_apps_it_level, all_apps_it_risk, _ = calculate_it_risk_from_apps(all_mapped_app_ids, ara_lookup)
    all_apps_is_level, all_apps_is_risk, _ = calculate_is_risk_from_apps(all_mapped_app_ids, ara_lookup)
    
    # Calculate risk from Key apps (including ghost apps - what system is using)
    key_app_ids = list(key_apps_set)
    key_apps_it_level, key_apps_it_risk, it_detail = calculate_it_risk_from_apps(key_app_ids, ara_lookup)
    key_apps_is_level, key_apps_is_risk, is_detail = calculate_is_risk_from_apps(key_app_ids, ara_lookup)
    
    # Calculate risk from ghost apps alone
    ghost_it_level = 0
    ghost_is_level = 0
    ghost_it_risk = 'N/A'
    ghost_is_risk = 'N/A'
    if ghost_apps:
        ghost_it_level, ghost_it_risk, _ = calculate_it_risk_from_apps(ghost_apps, ara_lookup)
        ghost_is_level, ghost_is_risk, _ = calculate_is_risk_from_apps(ghost_apps, ara_lookup)
    
    # Calculate risk from untagged apps
    primary_not_key_it_level = 0
    primary_not_key_is_level = 0
    primary_not_key_it_risk = 'N/A'
    primary_not_key_is_risk = 'N/A'
    if primary_not_key:
        primary_not_key_it_level, primary_not_key_it_risk, _ = calculate_it_risk_from_apps(primary_not_key, ara_lookup)
        primary_not_key_is_level, primary_not_key_is_risk, _ = calculate_is_risk_from_apps(primary_not_key, ara_lookup)
    
    secondary_not_key_it_level = 0
    secondary_not_key_is_level = 0
    secondary_not_key_it_risk = 'N/A'
    secondary_not_key_is_risk = 'N/A'
    if secondary_not_key:
        secondary_not_key_it_level, secondary_not_key_it_risk, _ = calculate_it_risk_from_apps(secondary_not_key, ara_lookup)
        secondary_not_key_is_level, secondary_not_key_is_risk, _ = calculate_is_risk_from_apps(secondary_not_key, ara_lookup)
    
    # ========== KEY COMPARISON: Against CURRENT SYSTEM RISK ==========
    
    # Would risk be HIGHER than current if we included ghost apps' correct counterparts?
    # (We can't calculate this without knowing what the correct apps are, so we note the ghost apps exist)
    has_ghost_apps = num_ghost_apps > 0
    
    # Would risk be HIGHER than current if Primary not Key apps were tagged?
    primary_would_increase_it = primary_not_key_it_level > current_it_level
    primary_would_increase_is = primary_not_key_is_level > current_is_level
    
    # Would risk be HIGHER than current if Secondary not Key apps were tagged?
    secondary_would_increase_it = secondary_not_key_it_level > current_it_level
    secondary_would_increase_is = secondary_not_key_is_level > current_is_level
    
    # Would risk be HIGHER than current if ALL mapped apps were tagged?
    all_apps_would_increase_it = all_apps_it_level > current_it_level
    all_apps_would_increase_is = all_apps_is_level > current_is_level
    
    # Risk status assessment
    if has_ghost_apps:
        it_risk_assessment = 'Possibly Misstated (Ghost Apps)'
        is_risk_assessment = 'Possibly Misstated (Ghost Apps)'
    elif all_apps_would_increase_it or all_apps_would_increase_is:
        it_risk_assessment = 'Possibly Understated' if all_apps_would_increase_it else 'Appears Correct'
        is_risk_assessment = 'Possibly Understated' if all_apps_would_increase_is else 'Appears Correct'
    else:
        it_risk_assessment = 'Appears Correct'
        is_risk_assessment = 'Appears Correct'
    
    # Build output row
    rows.append({
        'Audit Entity ID': ae_id,
        'Core Audit Team': core_team,
        'Audit Leader': audit_leader,
        
        # Mapping counts
        'Total Primary Apps': total_primary,
        'Total Secondary Apps': total_secondary,
        'Total Mapped Apps': total_mapped_apps,
        
        # Key designation counts
        'Primary Key Apps': total_primary_key,
        'Secondary Key Apps': total_secondary_key,
        'Total Key Apps': total_key_apps,
        
        # Issues - Ghost Apps (CRITICAL)
        '# Ghost Apps (Key but Not Mapped)': num_ghost_apps,
        'Ghost App IDs': ','.join(ghost_apps) if ghost_apps else '',
        
        # Issues - Primary Apps Not Key
        '# Primary Apps Not Key': num_primary_not_key,
        '% Primary Apps Not Key': pct_primary_not_key,
        'Primary Not Key IDs': ','.join(primary_not_key) if primary_not_key else '',
        
        # Issues - Secondary Apps Not Key
        '# Secondary Apps Not Key': num_secondary_not_key,
        '% Secondary Apps Not Key': pct_secondary_not_key,
        'Secondary Not Key IDs': ','.join(secondary_not_key) if secondary_not_key else '',
        
        # CURRENT Risk (what's in the system NOW)
        'Current IT Risk': current_it_risk,
        'Current IS Risk': current_is_risk,
        
        # ARA ANALYSIS: What risks WOULD be from different app sets
        'Risk from Key Apps (incl ghosts)': key_apps_it_risk,
        'IS Risk from Key Apps (incl ghosts)': key_apps_is_risk,
        'Risk from ALL Mapped Apps': all_apps_it_risk,
        'IS Risk from ALL Mapped Apps': all_apps_is_risk,
        
        # Ghost app risk levels
        'Ghost Apps IT Risk': ghost_it_risk,
        'Ghost Apps IS Risk': ghost_is_risk,
        
        # Untagged apps risk levels
        'Primary Not Key IT Risk': primary_not_key_it_risk,
        'Primary Not Key IS Risk': primary_not_key_is_risk,
        'Secondary Not Key IT Risk': secondary_not_key_it_risk,
        'Secondary Not Key IS Risk': secondary_not_key_is_risk,
        
        # COMPARISON: Would apps change CURRENT risk?
        'Primary Not Key: Higher than Current IT': primary_would_increase_it,
        'Primary Not Key: Higher than Current IS': primary_would_increase_is,
        'Secondary Not Key: Higher than Current IT': secondary_would_increase_it,
        'Secondary Not Key: Higher than Current IS': secondary_would_increase_is,
        'ALL Mapped Apps: Higher than Current IT': all_apps_would_increase_it,
        'ALL Mapped Apps: Higher than Current IS': all_apps_would_increase_is,
        
        # Risk Assessment
        'IT Risk Assessment': it_risk_assessment,
        'IS Risk Assessment': is_risk_assessment,
        
        # Reference info
        'Key App Driving IT (incl ghosts)': it_detail.get('max_app', 'N/A'),
        'Key App Driving IS (incl ghosts)': is_detail.get('max_app', 'N/A'),
    })

# =============================================================================
# CREATE SUMMARY DATAFRAME
# =============================================================================

summary_df = pd.DataFrame(rows)

print(f"✓ Analyzed {len(summary_df)} audit entities")
print()

# =============================================================================
# HELPER FUNCTION: CHECK IF RISK IS APPLICABLE
# =============================================================================

def is_risk_applicable(risk_value):
    """Check if a risk value indicates the risk is applicable"""
    if pd.isna(risk_value):
        return False
    return str(risk_value).strip() in RISK_APPLICABLE_VALUES

# Add boolean columns
summary_df['IT Risk Applicable'] = summary_df['Current IT Risk'].apply(is_risk_applicable)
summary_df['IS Risk Applicable'] = summary_df['Current IS Risk'].apply(is_risk_applicable)
summary_df['Any IT/IS Risk Applicable'] = summary_df['IT Risk Applicable'] | summary_df['IS Risk Applicable']

# =============================================================================
# FLAG CRITICAL ISSUES
# =============================================================================

# CRITICAL: Ghost Apps
summary_df['CRITICAL: Ghost Apps'] = summary_df['# Ghost Apps (Key but Not Mapped)'] > 0

# HIGH: Primary apps not Key
summary_df['HIGH: Primary Not Key'] = summary_df['# Primary Apps Not Key'] > 0

# HIGH: Secondary apps not Key
summary_df['HIGH: Secondary Not Key'] = summary_df['# Secondary Apps Not Key'] > 0

# COMBINED: Any mapping/tagging issues
summary_df['ANY ISSUE'] = (
    summary_df['CRITICAL: Ghost Apps'] |
    summary_df['HIGH: Primary Not Key'] |
    summary_df['HIGH: Secondary Not Key']
)

# Specific impact flags
summary_df['Ghost Apps Present'] = summary_df['# Ghost Apps (Key but Not Mapped)'] > 0

summary_df['Primary Not Key + No Risk'] = (
    (summary_df['# Primary Apps Not Key'] > 0) &
    (summary_df['Primary Key Apps'] == 0) &
    (summary_df['Secondary Key Apps'] == 0) &
    (~summary_df['Any IT/IS Risk Applicable'])
)

summary_df['Secondary Not Key + No Risk'] = (
    (summary_df['# Secondary Apps Not Key'] > 0) &
    (summary_df['Total Key Apps'] == 0) &
    (~summary_df['Any IT/IS Risk Applicable'])
)

# Automation failures
summary_df['Primary Key Auto Failure'] = (
    (summary_df['Primary Key Apps'] > 0) &
    (~summary_df['Any IT/IS Risk Applicable'])
)

summary_df['Secondary Key Auto Failure'] = (
    (summary_df['Secondary Key Apps'] > 0) &
    (~summary_df['Any IT/IS Risk Applicable'])
)

# ARA-validated impact flags (compared to CURRENT risk)
summary_df['Possibly Misstated IT Risk'] = (
    (summary_df['IT Risk Assessment'] == 'Possibly Misstated (Ghost Apps)') |
    (summary_df['IT Risk Assessment'] == 'Possibly Understated')
)

summary_df['Possibly Misstated IS Risk'] = (
    (summary_df['IS Risk Assessment'] == 'Possibly Misstated (Ghost Apps)') |
    (summary_df['IS Risk Assessment'] == 'Possibly Understated')
)

# =============================================================================
# CONSOLE OUTPUT WITH ARA-VALIDATED STATISTICS
# =============================================================================

print("="*70)
print("OBSERVATION 1: GHOST APPLICATIONS")
print("="*70)
print()

ghost_entities = summary_df[summary_df['CRITICAL: Ghost Apps']]
total_ghost_apps = summary_df['# Ghost Apps (Key but Not Mapped)'].sum()

if len(ghost_entities) > 0:
    print(f"⚠️  CRITICAL DATA INTEGRITY ISSUE")
    print(f"   Entities affected: {len(ghost_entities)} ({len(ghost_entities)/len(summary_df)*100:.1f}%)")
    print(f"   Total ghost apps: {int(total_ghost_apps)}")
    print(f"   Avg per entity: {total_ghost_apps/len(ghost_entities):.1f}")
    print(f"   ")
    print(f"   ✓ RISK ASSESSMENT:")
    print(f"   ALL {len(ghost_entities)} entities have POSSIBLY MISSTATED risk")
    print(f"   (Ghost apps are wrong apps - correct apps may have different risk)")
    print(f"   ")
    print(f"   Impact: Cannot validate accuracy without knowing correct apps")
else:
    print(f"✓ No ghost applications detected")

print()

# =============================================================================

print("="*70)
print("OBSERVATION 2: PRIMARY APPS NOT TAGGED AS KEY")
print("="*70)
print()

primary_issue = summary_df[summary_df['HIGH: Primary Not Key']]
total_primary_not_key = summary_df['# Primary Apps Not Key'].sum()
primary_no_risk = summary_df[summary_df['Primary Not Key + No Risk']]

if len(primary_issue) > 0:
    # Check how many would have HIGHER risk than CURRENT if Primary apps were Key
    primary_higher_it = primary_issue[primary_issue['Primary Not Key: Higher than Current IT'] == True]
    primary_higher_is = primary_issue[primary_issue['Primary Not Key: Higher than Current IS'] == True]
    primary_higher_either = primary_issue[
        (primary_issue['Primary Not Key: Higher than Current IT'] == True) |
        (primary_issue['Primary Not Key: Higher than Current IS'] == True)
    ]
    
    print(f"⚠️  HIGH PRIORITY ISSUE")
    print(f"   Entities with Primary apps: {len(summary_df[summary_df['Total Primary Apps'] > 0])}")
    print(f"   Entities with Primary NOT Key: {len(primary_issue)} ({len(primary_issue)/len(summary_df[summary_df['Total Primary Apps'] > 0])*100:.1f}% of entities with Primary)")
    print(f"   Total Primary apps NOT Key: {int(total_primary_not_key)}")
    print(f"   ")
    print(f"   ✓ ARA VALIDATION (vs CURRENT system risk):")
    print(f"   Higher IT Risk than current: {len(primary_higher_it)} entities")
    print(f"   Higher IS Risk than current: {len(primary_higher_is)} entities")
    print(f"   Higher risk (either IT or IS): {len(primary_higher_either)} entities → POSSIBLY UNDERSTATED")
    print(f"   Same/lower risk: {len(primary_issue) - len(primary_higher_either)} entities → Appears correct")
    print(f"   ")
    print(f"   Distribution:")
    print(f"   1-2 apps not Key: {len(primary_issue[primary_issue['# Primary Apps Not Key'] <= 2])}")
    print(f"   3-5 apps not Key: {len(primary_issue[(primary_issue['# Primary Apps Not Key'] > 2) & (primary_issue['# Primary Apps Not Key'] <= 5)])}")
    print(f"   6+ apps not Key: {len(primary_issue[primary_issue['# Primary Apps Not Key'] > 5])}")
else:
    print(f"✓ No issues with Primary app tagging")

print()

# =============================================================================

print("="*70)
print("OBSERVATION 3: SECONDARY APPS NOT TAGGED AS KEY")
print("="*70)
print()

secondary_issue = summary_df[summary_df['HIGH: Secondary Not Key']]
total_secondary_not_key = summary_df['# Secondary Apps Not Key'].sum()
secondary_no_risk = summary_df[summary_df['Secondary Not Key + No Risk']]

if len(secondary_issue) > 0:
    # Check how many would have HIGHER risk than CURRENT if Secondary apps were Key
    secondary_higher_it = secondary_issue[secondary_issue['Secondary Not Key: Higher than Current IT'] == True]
    secondary_higher_is = secondary_issue[secondary_issue['Secondary Not Key: Higher than Current IS'] == True]
    secondary_higher_either = secondary_issue[
        (secondary_issue['Secondary Not Key: Higher than Current IT'] == True) |
        (secondary_issue['Secondary Not Key: Higher than Current IS'] == True)
    ]
    
    print(f"⚠️  HIGH PRIORITY ISSUE - METHODOLOGY VIOLATION")
    print(f"   Entities with Secondary apps: {len(summary_df[summary_df['Total Secondary Apps'] > 0])}")
    print(f"   Entities with Secondary NOT Key: {len(secondary_issue)} ({len(secondary_issue)/len(summary_df[summary_df['Total Secondary Apps'] > 0])*100:.1f}% of entities with Secondary)")
    print(f"   Total Secondary apps NOT Key: {int(total_secondary_not_key)}")
    print(f"   ")
    print(f"   ✓ ARA VALIDATION (vs CURRENT system risk):")
    print(f"   Higher IT Risk than current: {len(secondary_higher_it)} entities")
    print(f"   Higher IS Risk than current: {len(secondary_higher_is)} entities")
    print(f"   Higher risk (either IT or IS): {len(secondary_higher_either)} entities → POSSIBLY UNDERSTATED")
    print(f"   Same/lower risk: {len(secondary_issue) - len(secondary_higher_either)} entities → Appears correct")
else:
    print(f"✓ No issues with Secondary app tagging")

print()

# =============================================================================

print("="*70)
print("OBSERVATION 4: AUTOMATION FAILURES")
print("="*70)
print()

primary_auto_fail = summary_df[summary_df['Primary Key Auto Failure']]
secondary_auto_fail = summary_df[summary_df['Secondary Key Auto Failure']]
all_auto_fail = summary_df[summary_df['Primary Key Auto Failure'] | summary_df['Secondary Key Auto Failure']]

if len(all_auto_fail) > 0:
    print(f"⚠️  AUTOMATION FAILURES DETECTED")
    print(f"   Primary Key apps + no risk: {len(primary_auto_fail)}")
    if len(primary_auto_fail) > 0:
        print(f"   └─ Total Primary Key apps affected: {int(primary_auto_fail['Primary Key Apps'].sum())}")
    print(f"   Secondary Key apps + no risk: {len(secondary_auto_fail)}")
    if len(secondary_auto_fail) > 0:
        print(f"   └─ Total Secondary Key apps affected: {int(secondary_auto_fail['Secondary Key Apps'].sum())}")
    print(f"   ")
    print(f"   Total entities with automation failures: {len(all_auto_fail)}")
else:
    print(f"✓ No automation failures detected")

print()

# =============================================================================
# SUMMARY STATISTICS
# =============================================================================

print("="*70)
print("OVERALL ARA-VALIDATED IMPACT SUMMARY")
print("="*70)
print()

# Count entities with possibly misstated risk
possibly_misstated_it = len(summary_df[summary_df['Possibly Misstated IT Risk']])
possibly_misstated_is = len(summary_df[summary_df['Possibly Misstated IS Risk']])
possibly_misstated_either = len(summary_df[
    (summary_df['Possibly Misstated IT Risk']) |
    (summary_df['Possibly Misstated IS Risk'])
])

print(f"Entities with POSSIBLY MISSTATED risk:")
print(f"   IT Risk: {possibly_misstated_it} entities")
print(f"   IS Risk: {possibly_misstated_is} entities")
print(f"   Either IT or IS Risk: {possibly_misstated_either} entities ({possibly_misstated_either/len(summary_df)*100:.1f}%)")
print()
print(f"Breakdown:")
print(f"   Ghost apps (possibly wrong): {len(ghost_entities)} entities")
if len(primary_issue) > 0:
    primary_higher_either = len(primary_issue[
        (primary_issue['Primary Not Key: Higher than Current IT'] == True) |
        (primary_issue['Primary Not Key: Higher than Current IS'] == True)
    ])
    print(f"   Primary not Key (possibly understated): {primary_higher_either} entities")
if len(secondary_issue) > 0:
    secondary_higher_either = len(secondary_issue[
        (secondary_issue['Secondary Not Key: Higher than Current IT'] == True) |
        (secondary_issue['Secondary Not Key: Higher than Current IS'] == True)
    ])
    print(f"   Secondary not Key (possibly understated): {secondary_higher_either} entities")

print()

# =============================================================================
# CREATE METHODOLOGY DOCUMENTATION
# =============================================================================

print("="*70)
print("DOCUMENTING METHODOLOGY")
print("="*70)

# Count apps in ARA file for documentation
total_ara_apps = len(ara_lookup)
ara_apps_with_scores = len([app for app, scores in ara_lookup.items() 
                             if scores['availability'] != 'N/A' or 
                                scores['integrity'] != 'N/A' or 
                                scores['confidentiality'] != 'N/A'])

# Document what was analyzed
methodology_doc = {
    'analysis_date': pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S'),
    'total_entities_analyzed': len(summary_df),
    'total_ara_records': total_ara_apps,
    'ara_records_with_scores': ara_apps_with_scores,
    'risks_file': RISKS_FILE,
    'kpa_file': KPA_FILE,
    'ara_file': ARA_FILE,
}

print(f"✓ Documented methodology")
print()

# =============================================================================
# HELPER FUNCTION: CREATE METHODOLOGY TAB
# =============================================================================

def create_methodology_tab(observation_number, observation_name, what_was_reviewed, 
                          data_sources, analysis_steps, output_interpretation):
    """
    Creates a standardized methodology documentation tab.
    """
    methodology_df = pd.DataFrame([
        {'Section': 'OBSERVATION METHODOLOGY', 'Detail': ''},
        {'Section': '', 'Detail': ''},
        {'Section': 'Observation Number', 'Detail': observation_number},
        {'Section': 'Observation Name', 'Detail': observation_name},
        {'Section': 'Analysis Date', 'Detail': methodology_doc['analysis_date']},
        {'Section': 'Analyst', 'Detail': '[Your Name]'},
        {'Section': '', 'Detail': ''},
        {'Section': '=' * 70, 'Detail': ''},
        {'Section': 'WHAT WAS REVIEWED', 'Detail': ''},
        {'Section': '=' * 70, 'Detail': ''},
    ])
    
    # Add what was reviewed items
    for item in what_was_reviewed:
        methodology_df = pd.concat([methodology_df, pd.DataFrame([{'Section': '  • ', 'Detail': item}])], ignore_index=True)
    
    methodology_df = pd.concat([methodology_df, pd.DataFrame([
        {'Section': '', 'Detail': ''},
        {'Section': '=' * 70, 'Detail': ''},
        {'Section': 'DATA SOURCES', 'Detail': ''},
        {'Section': '=' * 70, 'Detail': ''},
    ])], ignore_index=True)
    
    # Add data sources
    for source_name, source_detail in data_sources.items():
        methodology_df = pd.concat([methodology_df, pd.DataFrame([
            {'Section': source_name, 'Detail': ''},
        ])], ignore_index=True)
        for detail_key, detail_value in source_detail.items():
            methodology_df = pd.concat([methodology_df, pd.DataFrame([
                {'Section': f'  {detail_key}', 'Detail': str(detail_value)},
            ])], ignore_index=True)
        methodology_df = pd.concat([methodology_df, pd.DataFrame([{'Section': '', 'Detail': ''}])], ignore_index=True)
    
    methodology_df = pd.concat([methodology_df, pd.DataFrame([
        {'Section': '=' * 70, 'Detail': ''},
        {'Section': 'ANALYSIS STEPS', 'Detail': ''},
        {'Section': '=' * 70, 'Detail': ''},
    ])], ignore_index=True)
    
    # Add analysis steps
    for i, step in enumerate(analysis_steps, 1):
        methodology_df = pd.concat([methodology_df, pd.DataFrame([
            {'Section': f'Step {i}', 'Detail': step},
        ])], ignore_index=True)
    
    methodology_df = pd.concat([methodology_df, pd.DataFrame([
        {'Section': '', 'Detail': ''},
        {'Section': '=' * 70, 'Detail': ''},
        {'Section': 'OUTPUT INTERPRETATION', 'Detail': ''},
        {'Section': '=' * 70, 'Detail': ''},
    ])], ignore_index=True)
    
    # Add output interpretation
    for key, value in output_interpretation.items():
        methodology_df = pd.concat([methodology_df, pd.DataFrame([
            {'Section': key, 'Detail': value},
        ])], ignore_index=True)
    
    methodology_df = pd.concat([methodology_df, pd.DataFrame([
        {'Section': '', 'Detail': ''},
        {'Section': '=' * 70, 'Detail': ''},
        {'Section': 'REPERFORMANCE INSTRUCTIONS', 'Detail': ''},
        {'Section': '=' * 70, 'Detail': ''},
        {'Section': '', 'Detail': ''},
        {'Section': 'To reperform this analysis:', 'Detail': ''},
        {'Section': '1. Obtain the three source files listed above', 'Detail': ''},
        {'Section': '2. Run the Python script with these files as inputs', 'Detail': ''},
        {'Section': '3. The script will regenerate all outputs', 'Detail': ''},
        {'Section': '4. Compare results to this file', 'Detail': ''},
        {'Section': '', 'Detail': ''},
        {'Section': 'Script Location', 'Detail': '[To be filled in]'},
        {'Section': 'Script Version', 'Detail': 'v1.0 - ' + methodology_doc['analysis_date']},
    ])], ignore_index=True)
    
    return methodology_df

# =============================================================================
# EXPORT OBSERVATION 1: GHOST APPS
# =============================================================================

print("="*70)
print("EXPORTING OBSERVATION FILES")
print("="*70)

if len(ghost_entities) > 0:
    with pd.ExcelWriter(OUTPUT_OBSERVATION_1, engine='openpyxl') as writer:
        
        # ========== METHODOLOGY TAB (FIRST) ==========
        methodology_obs1 = create_methodology_tab(
            observation_number='1',
            observation_name='Ghost Applications',
            what_was_reviewed=[
                f'All {len(summary_df)} audit entities',
                f'All {len(kpa_df)} KPA records across all entities',
                f'All application mappings (Primary and Secondary) for each entity',
                'Applications tagged as "Key" in KPAs for each entity',
                f'ARA scores (Availability, Integrity, Confidentiality) for {total_ara_apps} applications'
            ],
            data_sources={
                'Source File 1: Audit Entity Risks': {
                    'File Name': methodology_doc['risks_file'],
                    'Records': methodology_doc['total_entities_analyzed'],
                    'Key Columns Used': f'{RISKS_AE_ID_COL}, {RISKS_IT_COL}, {RISKS_IS_COL}, {RISKS_PRIMARY_APPS_COL}, {RISKS_SECONDARY_APPS_COL}, {RISKS_CORE_TEAM_COL}, {RISKS_AUDIT_LEADER_COL}',
                    'Purpose': 'Source of entity list, current risk ratings, and application mappings'
                },
                'Source File 2: KPA Tagging': {
                    'File Name': methodology_doc['kpa_file'],
                    'Records': len(kpa_df),
                    'Key Columns Used': f'{KPA_AE_ID_COL}, {KPA_KEY_APPS_COL}',
                    'Purpose': 'Source of applications tagged as "Key" in KPAs per entity'
                },
                'Source File 3: ARA Scores': {
                    'File Name': methodology_doc['ara_file'],
                    'Records': methodology_doc['total_ara_records'],
                    'Records with Scores': methodology_doc['ara_records_with_scores'],
                    'Key Columns Used': f'{ARA_APP_ID_COL}, {ARA_AVAILABILITY_COL}, {ARA_INTEGRITY_COL}, {ARA_CONFIDENTIALITY_COL}',
                    'Purpose': 'Source of risk scores for each application'
                }
            },
            analysis_steps=[
                f'Extracted all applications mapped to each entity (Primary + Secondary) from {RISKS_FILE}',
                f'Extracted all applications tagged as "Key" in KPAs for each entity from {KPA_FILE}',
                'For each entity, compared Key-tagged apps against mapped apps',
                'Identified "ghost apps" = apps tagged as Key in KPAs but NOT in mapped apps list',
                'Flagged entities with any ghost apps as CRITICAL issue',
                f'Retrieved ARA scores from {ARA_FILE} for ghost apps and mapped apps',
                'Calculated what risk would be from ghost apps vs what mapped apps would give',
                'Assessed impact: All entities with ghost apps have POSSIBLY MISSTATED risk (wrong apps being used)'
            ],
            output_interpretation={
                'Ghost Apps': 'Applications in an entity\'s KPAs that are NOT mapped to that entity (Primary or Secondary)',
                'Why Critical': 'Risk calculation uses wrong application data - the apps don\'t belong to this entity',
                'Risk Assessment': 'POSSIBLY MISSTATED - Cannot validate accuracy without identifying correct apps',
                'Entities Affected': f'{len(ghost_entities)} entities ({len(ghost_entities)/len(summary_df)*100:.1f}%)',
                'Total Ghost Apps': f'{int(total_ghost_apps)} apps across all affected entities',
                'Next Steps': 'Investigate each entity to identify correct apps, update KPAs, recalculate risk'
            }
        )
        methodology_obs1.to_excel(writer, sheet_name='Methodology', index=False)
        
        # ========== SUMMARY TAB ==========
        obs1_summary = pd.DataFrame([
            {'Metric': 'OBSERVATION 1: GHOST APPLICATIONS', 'Value': ''},
            {'Metric': '', 'Value': ''},
            {'Metric': 'Definition', 'Value': 'Apps tagged as Key in KPAs but NOT mapped to entity'},
            {'Metric': 'Severity', 'Value': 'CRITICAL'},
            {'Metric': '', 'Value': ''},
            {'Metric': 'Entities affected', 'Value': len(ghost_entities)},
            {'Metric': '% of total', 'Value': f"{len(ghost_entities)/len(summary_df)*100:.1f}%"},
            {'Metric': 'Total ghost apps', 'Value': int(total_ghost_apps)},
            {'Metric': 'Avg per entity', 'Value': f"{total_ghost_apps/len(ghost_entities):.1f}"},
            {'Metric': '', 'Value': ''},
            {'Metric': 'RISK ASSESSMENT:', 'Value': ''},
            {'Metric': 'All entities: POSSIBLY MISSTATED', 'Value': len(ghost_entities)},
            {'Metric': '', 'Value': ''},
            {'Metric': 'Impact', 'Value': 'Ghost apps are WRONG apps - correct apps unknown'},
            {'Metric': 'Note', 'Value': 'Cannot validate accuracy without identifying correct apps'},
            {'Metric': '', 'Value': ''},
            {'Metric': 'See "Methodology" tab', 'Value': 'For complete analysis documentation'},
        ])
        obs1_summary.to_excel(writer, sheet_name='Summary', index=False)
        
        # ========== ALL GHOST APPS TAB ==========
        ghost_export = ghost_entities.sort_values('# Ghost Apps (Key but Not Mapped)', ascending=False)
        ghost_export.to_excel(writer, sheet_name='All Ghost Apps', index=False)
        
        # ========== TOP 10 TAB ==========
        top_ghost = ghost_export.head(10)
        top_ghost.to_excel(writer, sheet_name='Top 10', index=False)
        
        # ========== BY TEAM AND LEADER TAB ==========
        if RISKS_CORE_TEAM_ACTUAL and RISKS_AUDIT_LEADER_ACTUAL:
            team_leader_dist = ghost_entities.groupby(['Core Audit Team', 'Audit Leader']).agg({
                'Audit Entity ID': 'count',
                '# Ghost Apps (Key but Not Mapped)': 'sum'
            }).reset_index()
            team_leader_dist.columns = ['Core Audit Team', 'Audit Leader', '# Entities', 'Total Ghost Apps']
            team_leader_dist['Risk Assessment'] = 'All: Possibly Misstated'
            team_leader_dist = team_leader_dist.sort_values(['Core Audit Team', '# Entities'], ascending=[True, False])
            team_leader_dist.to_excel(writer, sheet_name='By Team and Leader', index=False)
        elif RISKS_CORE_TEAM_ACTUAL:
            team_dist = ghost_entities.groupby('Core Audit Team').agg({
                'Audit Entity ID': 'count',
                '# Ghost Apps (Key but Not Mapped)': 'sum'
            }).reset_index()
            team_dist.columns = ['Core Audit Team', '# Entities', 'Total Ghost Apps']
            team_dist = team_dist.sort_values('# Entities', ascending=False)
            team_dist.to_excel(writer, sheet_name='By Team', index=False)
        
    print(f"✓ {OUTPUT_OBSERVATION_1}")

# =============================================================================
# EXPORT OBSERVATION 2: PRIMARY APPS NOT KEY
# =============================================================================

if len(primary_issue) > 0:
    primary_higher_it = primary_issue[primary_issue['Primary Not Key: Higher than Current IT'] == True]
    primary_higher_is = primary_issue[primary_issue['Primary Not Key: Higher than Current IS'] == True]
    primary_higher_either = primary_issue[
        (primary_issue['Primary Not Key: Higher than Current IT'] == True) |
        (primary_issue['Primary Not Key: Higher than Current IS'] == True)
    ]
    
    with pd.ExcelWriter(OUTPUT_OBSERVATION_2, engine='openpyxl') as writer:
        
        # ========== METHODOLOGY TAB (FIRST) ==========
        methodology_obs2 = create_methodology_tab(
            observation_number='2',
            observation_name='Primary Applications Not Tagged as Key',
            what_was_reviewed=[
                f'All {len(summary_df)} audit entities',
                f'All applications mapped as "Primary" to each entity from {RISKS_FILE}',
                f'All applications tagged as "Key" in KPAs from {KPA_FILE}',
                f'Current IT and IS risk ratings for each entity from {RISKS_FILE}',
                f'ARA scores for all Primary apps from {ARA_FILE}'
            ],
            data_sources={
                'Source File 1: Audit Entity Risks': {
                    'File Name': methodology_doc['risks_file'],
                    'Records': methodology_doc['total_entities_analyzed'],
                    'Key Columns Used': f'{RISKS_AE_ID_COL}, {RISKS_IT_COL}, {RISKS_IS_COL}, {RISKS_PRIMARY_APPS_COL}, {RISKS_CORE_TEAM_COL}, {RISKS_AUDIT_LEADER_COL}',
                    'Purpose': 'Source of Primary app mappings and current risk ratings'
                },
                'Source File 2: KPA Tagging': {
                    'File Name': methodology_doc['kpa_file'],
                    'Records': len(kpa_df),
                    'Key Columns Used': f'{KPA_AE_ID_COL}, {KPA_KEY_APPS_COL}',
                    'Purpose': 'Source of which apps are tagged as "Key"'
                },
                'Source File 3: ARA Scores': {
                    'File Name': methodology_doc['ara_file'],
                    'Records': methodology_doc['total_ara_records'],
                    'Key Columns Used': f'{ARA_APP_ID_COL}, {ARA_AVAILABILITY_COL}, {ARA_INTEGRITY_COL}, {ARA_CONFIDENTIALITY_COL}',
                    'Purpose': 'Risk scores to compare current vs potential risk'
                }
            },
            analysis_steps=[
                f'Extracted all Primary apps for each entity from {RISKS_FILE}',
                f'Extracted all Key-tagged apps for each entity from {KPA_FILE}',
                'Compared Primary apps to Key apps - identified Primary apps NOT tagged as Key',
                f'Retrieved current IT and IS risk ratings from {RISKS_FILE}',
                f'Retrieved ARA scores from {ARA_FILE} for Primary not Key apps',
                'Calculated IT risk from Primary not Key apps: max(Availability, Integrity)',
                'Calculated IS risk from Primary not Key apps: Confidentiality',
                'Compared calculated risk to CURRENT system risk',
                'Flagged entities where Primary not Key apps have HIGHER risk than current as "Possibly Understated"',
                'Flagged entities where Primary not Key apps have same/lower risk as "Appears Correct"'
            ],
            output_interpretation={
                'Primary Apps Not Key': 'Applications mapped as Primary but NOT tagged as Key in any KPA',
                'Why High Priority': 'These apps may should be considered for risk but currently aren\'t',
                'ARA Validation Method': 'Compared ARA scores of untagged apps to CURRENT system risk',
                'Possibly Understated': f'{len(primary_higher_either)} entities where untagged apps have HIGHER risk than current',
                'Appears Correct': f'{len(primary_issue) - len(primary_higher_either)} entities where untagged apps have same/lower risk',
                'Total Entities': f'{len(primary_issue)} entities with Primary apps not Key',
                'Total Apps': f'{int(total_primary_not_key)} Primary apps not tagged as Key',
                'IT Specific': f'{len(primary_higher_it)} entities would have higher IT risk',
                'IS Specific': f'{len(primary_higher_is)} entities would have higher IS risk',
                'Next Steps': 'Sample "Possibly Understated" entities to determine if apps SHOULD be Key'
            }
        )
        methodology_obs2.to_excel(writer, sheet_name='Methodology', index=False)
        
        # ========== SUMMARY TAB ==========
        obs2_summary = pd.DataFrame([
            {'Metric': 'OBSERVATION 2: PRIMARY APPS NOT TAGGED AS KEY', 'Value': ''},
            {'Metric': '', 'Value': ''},
            {'Metric': 'Definition', 'Value': 'Apps mapped as Primary but NOT tagged as Key in any KPA'},
            {'Metric': 'Severity', 'Value': 'HIGH'},
            {'Metric': '', 'Value': ''},
            {'Metric': 'Entities with Primary apps', 'Value': len(summary_df[summary_df['Total Primary Apps'] > 0])},
            {'Metric': 'Entities with Primary NOT Key', 'Value': len(primary_issue)},
            {'Metric': '% non-compliance', 'Value': f"{len(primary_issue)/len(summary_df[summary_df['Total Primary Apps'] > 0])*100:.1f}%"},
            {'Metric': 'Total Primary apps NOT Key', 'Value': int(total_primary_not_key)},
            {'Metric': '', 'Value': ''},
            {'Metric': 'ARA VALIDATION (vs CURRENT risk):', 'Value': ''},
            {'Metric': 'Higher IT Risk than current', 'Value': len(primary_higher_it)},
            {'Metric': 'Higher IS Risk than current', 'Value': len(primary_higher_is)},
            {'Metric': 'Higher risk (either): POSSIBLY UNDERSTATED', 'Value': len(primary_higher_either)},
            {'Metric': 'Same/lower risk: Appears correct', 'Value': len(primary_issue) - len(primary_higher_either)},
            {'Metric': '', 'Value': ''},
            {'Metric': 'Distribution:', 'Value': ''},
            {'Metric': '1-2 apps not Key', 'Value': len(primary_issue[primary_issue['# Primary Apps Not Key'] <= 2])},
            {'Metric': '3-5 apps not Key', 'Value': len(primary_issue[(primary_issue['# Primary Apps Not Key'] > 2) & (primary_issue['# Primary Apps Not Key'] <= 5)])},
            {'Metric': '6+ apps not Key', 'Value': len(primary_issue[primary_issue['# Primary Apps Not Key'] > 5])},
            {'Metric': '', 'Value': ''},
            {'Metric': 'See "Methodology" tab', 'Value': 'For complete analysis documentation'},
        ])
        obs2_summary.to_excel(writer, sheet_name='Summary', index=False)
        
        # ========== ALL PRIMARY NOT KEY TAB ==========
        primary_export = primary_issue.sort_values('# Primary Apps Not Key', ascending=False)
        primary_export.to_excel(writer, sheet_name='All Primary Not Key', index=False)
        
        # ========== POSSIBLY UNDERSTATED TAB ==========
        primary_understated = primary_higher_either.sort_values('# Primary Apps Not Key', ascending=False)
        primary_understated.to_excel(writer, sheet_name='Possibly Understated (ARA)', index=False)
        
        # ========== HIGH COUNT TAB ==========
        high_count = primary_issue[primary_issue['# Primary Apps Not Key'] > 5].sort_values('# Primary Apps Not Key', ascending=False)
        high_count.to_excel(writer, sheet_name='High Count (6+)', index=False)
        
        # ========== NO RISK TAB ==========
        primary_no_risk.to_excel(writer, sheet_name='No Risk (Confirmed)', index=False)
        
        # ========== BY TEAM AND LEADER TAB ==========
        if RISKS_CORE_TEAM_ACTUAL and RISKS_AUDIT_LEADER_ACTUAL:
            team_leader_dist = primary_issue.groupby(['Core Audit Team', 'Audit Leader']).agg({
                'Audit Entity ID': 'count',
                '# Primary Apps Not Key': 'sum',
                'Primary Not Key: Higher than Current IT': 'sum',
                'Primary Not Key: Higher than Current IS': 'sum'
            }).reset_index()
            team_leader_dist.columns = ['Core Audit Team', 'Audit Leader', '# Entities', 'Total Primary Not Key', 'Higher IT Risk', 'Higher IS Risk']
            team_leader_dist['Possibly Understated'] = team_leader_dist['Higher IT Risk'] + team_leader_dist['Higher IS Risk']
            team_leader_dist = team_leader_dist.sort_values(['Core Audit Team', 'Possibly Understated'], ascending=[True, False])
            team_leader_dist.to_excel(writer, sheet_name='By Team and Leader', index=False)
        elif RISKS_CORE_TEAM_ACTUAL:
            team_dist = primary_issue.groupby('Core Audit Team').agg({
                'Audit Entity ID': 'count',
                '# Primary Apps Not Key': 'sum',
                'Primary Not Key: Higher than Current IT': 'sum',
                'Primary Not Key: Higher than Current IS': 'sum'
            }).reset_index()
            team_dist.columns = ['Core Audit Team', '# Entities', 'Total Primary Not Key', 'Higher IT Risk', 'Higher IS Risk']
            team_dist = team_dist.sort_values('# Entities', ascending=False)
            team_dist.to_excel(writer, sheet_name='By Team', index=False)
    
    print(f"✓ {OUTPUT_OBSERVATION_2}")

# =============================================================================
# EXPORT OBSERVATION 3: SECONDARY APPS NOT KEY
# =============================================================================

if len(secondary_issue) > 0:
    secondary_higher_it = secondary_issue[secondary_issue['Secondary Not Key: Higher than Current IT'] == True]
    secondary_higher_is = secondary_issue[secondary_issue['Secondary Not Key: Higher than Current IS'] == True]
    secondary_higher_either = secondary_issue[
        (secondary_issue['Secondary Not Key: Higher than Current IT'] == True) |
        (secondary_issue['Secondary Not Key: Higher than Current IS'] == True)
    ]
    
    with pd.ExcelWriter(OUTPUT_OBSERVATION_3, engine='openpyxl') as writer:
        
        # ========== METHODOLOGY TAB ==========
        methodology_obs3 = create_methodology_tab(
            observation_number='3',
            observation_name='Secondary Applications Not Tagged as Key',
            what_was_reviewed=[
                f'All {len(summary_df)} audit entities',
                f'All applications mapped as "Secondary" to each entity from {RISKS_FILE}',
                f'All applications tagged as "Key" in KPAs from {KPA_FILE}',
                f'Documented methodology rule: "Secondary apps should be identified as a key application in at least one KPA"',
                f'Current IT and IS risk ratings from {RISKS_FILE}',
                f'ARA scores for all Secondary apps from {ARA_FILE}'
            ],
            data_sources={
                'Source File 1: Audit Entity Risks': {
                    'File Name': methodology_doc['risks_file'],
                    'Records': methodology_doc['total_entities_analyzed'],
                    'Key Columns Used': f'{RISKS_AE_ID_COL}, {RISKS_IT_COL}, {RISKS_IS_COL}, {RISKS_SECONDARY_APPS_COL}',
                    'Purpose': 'Source of Secondary app mappings and current risk ratings'
                },
                'Source File 2: KPA Tagging': {
                    'File Name': methodology_doc['kpa_file'],
                    'Records': len(kpa_df),
                    'Key Columns Used': f'{KPA_AE_ID_COL}, {KPA_KEY_APPS_COL}',
                    'Purpose': 'Source of which apps are tagged as "Key"'
                },
                'Source File 3: ARA Scores': {
                    'File Name': methodology_doc['ara_file'],
                    'Records': methodology_doc['total_ara_records'],
                    'Key Columns Used': f'{ARA_APP_ID_COL}, {ARA_AVAILABILITY_COL}, {ARA_INTEGRITY_COL}, {ARA_CONFIDENTIALITY_COL}',
                    'Purpose': 'Risk scores to validate impact'
                }
            },
            analysis_steps=[
                f'Extracted all Secondary apps for each entity from {RISKS_FILE}',
                f'Extracted all Key-tagged apps for each entity from {KPA_FILE}',
                'Compared Secondary apps to Key apps - identified Secondary apps NOT tagged as Key',
                'Flagged as methodology violation (documented rule requires Secondary → Key)',
                f'Retrieved current IT and IS risk from {RISKS_FILE}',
                f'Retrieved ARA scores from {ARA_FILE} for Secondary not Key apps',
                'Compared ARA scores of untagged apps to CURRENT system risk',
                'Flagged "Possibly Understated" where untagged apps have higher risk than current',
                'Flagged "Appears Correct" where untagged apps have same/lower risk'
            ],
            output_interpretation={
                'Secondary Apps Not Key': 'Apps mapped as Secondary but NOT tagged as Key - violates documented methodology',
                'Methodology Rule': 'Secondary apps should be identified as a key application in at least one KPA',
                'Severity': 'HIGH - Direct methodology violation + potential risk understatement',
                'Possibly Understated': f'{len(secondary_higher_either)} entities where untagged apps have higher risk',
                'Appears Correct': f'{len(secondary_issue) - len(secondary_higher_either)} entities where untagged apps have same/lower risk',
                'IT Specific': f'{len(secondary_higher_it)} entities would have higher IT risk',
                'IS Specific': f'{len(secondary_higher_is)} entities would have higher IS risk',
                'Next Steps': 'Systematic tagging of Secondary apps as Key per methodology'
            }
        )
        methodology_obs3.to_excel(writer, sheet_name='Methodology', index=False)
        
        # ========== SUMMARY TAB ==========
        obs3_summary = pd.DataFrame([
            {'Metric': 'OBSERVATION 3: SECONDARY APPS NOT TAGGED AS KEY', 'Value': ''},
            {'Metric': '', 'Value': ''},
            {'Metric': 'Definition', 'Value': 'Apps mapped as Secondary but NOT tagged as Key in any KPA'},
            {'Metric': 'Rule', 'Value': 'Secondary apps should be Key in at least one KPA'},
            {'Metric': 'Severity', 'Value': 'HIGH - Methodology Violation'},
            {'Metric': '', 'Value': ''},
            {'Metric': 'Entities with Secondary apps', 'Value': len(summary_df[summary_df['Total Secondary Apps'] > 0])},
            {'Metric': 'Entities with Secondary NOT Key', 'Value': len(secondary_issue)},
            {'Metric': '% non-compliance', 'Value': f"{len(secondary_issue)/len(summary_df[summary_df['Total Secondary Apps'] > 0])*100:.1f}%"},
            {'Metric': 'Total Secondary apps NOT Key', 'Value': int(total_secondary_not_key)},
            {'Metric': '', 'Value': ''},
            {'Metric': 'ARA VALIDATION (vs CURRENT risk):', 'Value': ''},
            {'Metric': 'Higher IT Risk than current', 'Value': len(secondary_higher_it)},
            {'Metric': 'Higher IS Risk than current', 'Value': len(secondary_higher_is)},
            {'Metric': 'Higher risk (either): POSSIBLY UNDERSTATED', 'Value': len(secondary_higher_either)},
            {'Metric': 'Same/lower risk: Appears correct', 'Value': len(secondary_issue) - len(secondary_higher_either)},
            {'Metric': '', 'Value': ''},
            {'Metric': 'See "Methodology" tab', 'Value': 'For complete analysis documentation'},
        ])
        obs3_summary.to_excel(writer, sheet_name='Summary', index=False)
        
        # ========== ALL SECONDARY NOT KEY TAB ==========
        secondary_export = secondary_issue.sort_values('# Secondary Apps Not Key', ascending=False)
        secondary_export.to_excel(writer, sheet_name='All Secondary Not Key', index=False)
        
        # ========== POSSIBLY UNDERSTATED TAB ==========
        secondary_understated = secondary_higher_either.sort_values('# Secondary Apps Not Key', ascending=False)
        secondary_understated.to_excel(writer, sheet_name='Possibly Understated (ARA)', index=False)
        
        # ========== NO RISK TAB ==========
        secondary_no_risk.to_excel(writer, sheet_name='No Risk (Confirmed)', index=False)
        
        # ========== BY TEAM AND LEADER TAB ==========
        if RISKS_CORE_TEAM_ACTUAL and RISKS_AUDIT_LEADER_ACTUAL:
            team_leader_dist = secondary_issue.groupby(['Core Audit Team', 'Audit Leader']).agg({
                'Audit Entity ID': 'count',
                '# Secondary Apps Not Key': 'sum',
                'Secondary Not Key: Higher than Current IT': 'sum',
                'Secondary Not Key: Higher than Current IS': 'sum'
            }).reset_index()
            team_leader_dist.columns = ['Core Audit Team', 'Audit Leader', '# Entities', 'Total Secondary Not Key', 'Higher IT Risk', 'Higher IS Risk']
            team_leader_dist['Possibly Understated'] = team_leader_dist['Higher IT Risk'] + team_leader_dist['Higher IS Risk']
            team_leader_dist = team_leader_dist.sort_values(['Core Audit Team', 'Possibly Understated'], ascending=[True, False])
            team_leader_dist.to_excel(writer, sheet_name='By Team and Leader', index=False)
        elif RISKS_CORE_TEAM_ACTUAL:
            team_dist = secondary_issue.groupby('Core Audit Team').agg({
                'Audit Entity ID': 'count',
                '# Secondary Apps Not Key': 'sum',
                'Secondary Not Key: Higher than Current IT': 'sum',
                'Secondary Not Key: Higher than Current IS': 'sum'
            }).reset_index()
            team_dist.columns = ['Core Audit Team', '# Entities', 'Total Secondary Not Key', 'Higher IT Risk', 'Higher IS Risk']
            team_dist = team_dist.sort_values('# Entities', ascending=False)
            team_dist.to_excel(writer, sheet_name='By Team', index=False)
    
    print(f"✓ {OUTPUT_OBSERVATION_3}")

# =============================================================================
# EXPORT OBSERVATION 4: AUTOMATION FAILURES
# =============================================================================

if len(all_auto_fail) > 0:
    with pd.ExcelWriter(OUTPUT_OBSERVATION_4, engine='openpyxl') as writer:
        
        # ========== METHODOLOGY TAB ==========
        methodology_obs4 = create_methodology_tab(
            observation_number='4',
            observation_name='Automation Failures',
            what_was_reviewed=[
                f'All {len(summary_df)} audit entities',
                'Entities with Primary Key apps (apps mapped as Primary AND tagged as Key)',
                'Entities with Secondary Key apps (apps mapped as Secondary AND tagged as Key)',
                f'Current IT and IS risk applicability status from {RISKS_FILE}',
                'Expected behavior: Key apps should automatically populate IT/IS risk'
            ],
            data_sources={
                'Source File 1: Audit Entity Risks': {
                    'File Name': methodology_doc['risks_file'],
                    'Records': methodology_doc['total_entities_analyzed'],
                    'Key Columns Used': f'{RISKS_AE_ID_COL}, {RISKS_IT_COL}, {RISKS_IS_COL}, {RISKS_PRIMARY_APPS_COL}, {RISKS_SECONDARY_APPS_COL}',
                    'Purpose': 'Source of current risk status and app mappings'
                },
                'Source File 2: KPA Tagging': {
                    'File Name': methodology_doc['kpa_file'],
                    'Records': len(kpa_df),
                    'Key Columns Used': f'{KPA_AE_ID_COL}, {KPA_KEY_APPS_COL}',
                    'Purpose': 'Identify which apps are tagged as Key'
                }
            },
            analysis_steps=[
                'Identified entities with Primary Key apps (Primary mapped AND Key tagged)',
                'Identified entities with Secondary Key apps (Secondary mapped AND Key tagged)',
                f'Retrieved current IT/IS risk status from {RISKS_FILE}',
                'Risk values considered "applicable": Critical, High, Medium, Low',
                'Risk values considered "not applicable": N/A, blank, or any other value',
                'Flagged entities with Key apps but NO IT/IS risk as automation failures',
                'Separated into Primary Key failures and Secondary Key failures'
            ],
            output_interpretation={
                'Automation Failure': 'Key apps exist but IT/IS risk NOT populated',
                'Expected Behavior': 'When apps are tagged as Key, system should auto-populate risk from ARA scores',
                'Primary Key Failures': f'{len(primary_auto_fail)} entities',
                'Secondary Key Failures': f'{len(secondary_auto_fail)} entities',
                'Total Entities': f'{len(all_auto_fail)} entities',
                'Why High Priority': 'Risk should exist but is missing - automation not working as designed',
                'Next Steps': 'Investigate with IT Applications team - check for timing issues, manual overrides, or system bugs'
            }
        )
        methodology_obs4.to_excel(writer, sheet_name='Methodology', index=False)
        
        # ========== SUMMARY TAB ==========
        obs4_summary = pd.DataFrame([
            {'Metric': 'OBSERVATION 4: AUTOMATION FAILURES', 'Value': ''},
            {'Metric': '', 'Value': ''},
            {'Metric': 'Definition', 'Value': 'Key apps exist but IT/IS risk NOT populated'},
            {'Metric': 'Severity', 'Value': 'HIGH'},
            {'Metric': '', 'Value': ''},
            {'Metric': 'Primary Key + no risk', 'Value': len(primary_auto_fail)},
            {'Metric': 'Secondary Key + no risk', 'Value': len(secondary_auto_fail)},
            {'Metric': 'Total entities', 'Value': len(all_auto_fail)},
            {'Metric': '', 'Value': ''},
            {'Metric': 'Total Primary Key apps affected', 'Value': int(primary_auto_fail['Primary Key Apps'].sum()) if len(primary_auto_fail) > 0 else 0},
            {'Metric': 'Total Secondary Key apps affected', 'Value': int(secondary_auto_fail['Secondary Key Apps'].sum()) if len(secondary_auto_fail) > 0 else 0},
            {'Metric': '', 'Value': ''},
            {'Metric': 'Impact', 'Value': 'Risk should be populated but is not'},
            {'Metric': '', 'Value': ''},
            {'Metric': 'See "Methodology" tab', 'Value': 'For complete analysis documentation'},
        ])
        obs4_summary.to_excel(writer, sheet_name='Summary', index=False)
        
        # ========== ALL AUTOMATION FAILURES TAB ==========
        all_auto_fail_sorted = all_auto_fail.sort_values(['Primary Key Apps', 'Secondary Key Apps'], ascending=False)
        all_auto_fail_sorted.to_excel(writer, sheet_name='All Automation Failures', index=False)
        
        # ========== PRIMARY KEY FAILURES TAB ==========
        if len(primary_auto_fail) > 0:
            primary_auto_fail.to_excel(writer, sheet_name='Primary Key Failures', index=False)
        
        # ========== SECONDARY KEY FAILURES TAB ==========
        if len(secondary_auto_fail) > 0:
            secondary_auto_fail.to_excel(writer, sheet_name='Secondary Key Failures', index=False)
        
        # ========== BY TEAM AND LEADER TAB ==========
        if RISKS_CORE_TEAM_ACTUAL and RISKS_AUDIT_LEADER_ACTUAL:
            team_leader_dist = all_auto_fail.groupby(['Core Audit Team', 'Audit Leader']).agg({
                'Audit Entity ID': 'count',
                'Primary Key Apps': 'sum',
                'Secondary Key Apps': 'sum'
            }).reset_index()
            team_leader_dist.columns = ['Core Audit Team', 'Audit Leader', '# Entities', 'Total Primary Key Apps', 'Total Secondary Key Apps']
            team_leader_dist = team_leader_dist.sort_values(['Core Audit Team', '# Entities'], ascending=[True, False])
            team_leader_dist.to_excel(writer, sheet_name='By Team and Leader', index=False)
        elif RISKS_CORE_TEAM_ACTUAL:
            team_dist = all_auto_fail.groupby('Core Audit Team').agg({
                'Audit Entity ID': 'count',
                'Primary Key Apps': 'sum',
                'Secondary Key Apps': 'sum'
            }).reset_index()
            team_dist.columns = ['Core Audit Team', '# Entities', 'Total Primary Key Apps', 'Total Secondary Key Apps']
            team_dist = team_dist.sort_values('# Entities', ascending=False)
            team_dist.to_excel(writer, sheet_name='By Team', index=False)
    
    print(f"✓ {OUTPUT_OBSERVATION_4}")

# =============================================================================
# EXPORT EXECUTIVE SUMMARY
# =============================================================================

# Calculate overall metrics for executive summary
if len(primary_issue) > 0:
    primary_higher_either = len(primary_issue[
        (primary_issue['Primary Not Key: Higher than Current IT'] == True) |
        (primary_issue['Primary Not Key: Higher than Current IS'] == True)
    ])
else:
    primary_higher_either = 0

if len(secondary_issue) > 0:
    secondary_higher_either = len(secondary_issue[
        (secondary_issue['Secondary Not Key: Higher than Current IT'] == True) |
        (secondary_issue['Secondary Not Key: Higher than Current IS'] == True)
    ])
else:
    secondary_higher_either = 0

with pd.ExcelWriter(OUTPUT_EXECUTIVE_SUMMARY, engine='openpyxl') as writer:
    
    # ========== METHODOLOGY TAB (FIRST) ==========
    exec_methodology = pd.DataFrame([
        {'Section': 'IT/IS RISK APPLICABILITY ANALYSIS', 'Detail': ''},
        {'Section': 'OVERALL METHODOLOGY DOCUMENTATION', 'Detail': ''},
        {'Section': '', 'Detail': ''},
        {'Section': 'Analysis Date', 'Detail': methodology_doc['analysis_date']},
        {'Section': 'Analyst', 'Detail': '[Your Name]'},
        {'Section': 'Scope', 'Detail': f"{methodology_doc['total_entities_analyzed']} audit entities"},
        {'Section': '', 'Detail': ''},
        {'Section': '=' * 70, 'Detail': ''},
        {'Section': 'OBJECTIVE', 'Detail': ''},
        {'Section': '=' * 70, 'Detail': ''},
        {'Section': '', 'Detail': ''},
        {'Section': 'Primary Objective', 'Detail': 'Validate accuracy of IT/IS risk ratings across audit universe'},
        {'Section': '', 'Detail': ''},
        {'Section': 'Specific Questions', 'Detail': ''},
        {'Section': '  1.', 'Detail': 'Are the correct applications being used to calculate risk?'},
        {'Section': '  2.', 'Detail': 'Are all relevant applications tagged as "Key" per methodology?'},
        {'Section': '  3.', 'Detail': 'Do current risk ratings reflect actual application risk levels (per ARA)?'},
        {'Section': '  4.', 'Detail': 'Is the automation working as designed?'},
        {'Section': '', 'Detail': ''},
        {'Section': '=' * 70, 'Detail': ''},
        {'Section': 'DATA SOURCES - ALL OBSERVATIONS', 'Detail': ''},
        {'Section': '=' * 70, 'Detail': ''},
        {'Section': '', 'Detail': ''},
        {'Section': 'File 1: Audit Entity Risks', 'Detail': ''},
        {'Section': '  File Name', 'Detail': methodology_doc['risks_file']},
        {'Section': '  Records', 'Detail': methodology_doc['total_entities_analyzed']},
        {'Section': '  Purpose', 'Detail': 'Master list of entities, risk ratings, and app mappings'},
        {'Section': '  Key Columns', 'Detail': f'{RISKS_AE_ID_COL}, {RISKS_IT_COL}, {RISKS_IS_COL}'},
        {'Section': '  Key Columns', 'Detail': f'{RISKS_PRIMARY_APPS_COL}, {RISKS_SECONDARY_APPS_COL}'},
        {'Section': '  Key Columns', 'Detail': f'{RISKS_CORE_TEAM_COL}, {RISKS_AUDIT_LEADER_COL}'},
        {'Section': '', 'Detail': ''},
        {'Section': 'File 2: KPA Tagging', 'Detail': ''},
        {'Section': '  File Name', 'Detail': methodology_doc['kpa_file']},
        {'Section': '  Records', 'Detail': len(kpa_df)},
        {'Section': '  Purpose', 'Detail': 'Applications tagged as "Key" in KPAs per entity'},
        {'Section': '  Key Columns', 'Detail': f'{KPA_AE_ID_COL}, {KPA_KEY_APPS_COL}'},
        {'Section': '', 'Detail': ''},
        {'Section': 'File 3: ARA Scores', 'Detail': ''},
        {'Section': '  File Name', 'Detail': methodology_doc['ara_file']},
        {'Section': '  Records', 'Detail': methodology_doc['total_ara_records']},
        {'Section': '  Records with Scores', 'Detail': methodology_doc['ara_records_with_scores']},
        {'Section': '  Purpose', 'Detail': 'Risk scores (Availability, Integrity, Confidentiality) per app'},
        {'Section': '  Key Columns', 'Detail': f'{ARA_APP_ID_COL}, {ARA_AVAILABILITY_COL}'},
        {'Section': '  Key Columns', 'Detail': f'{ARA_INTEGRITY_COL}, {ARA_CONFIDENTIALITY_COL}'},
        {'Section': '', 'Detail': ''},
        {'Section': '=' * 70, 'Detail': ''},
        {'Section': 'ANALYSIS APPROACH', 'Detail': ''},
        {'Section': '=' * 70, 'Detail': ''},
        {'Section': '', 'Detail': ''},
        {'Section': 'Step 1: Data Integration', 'Detail': 'Combined all three data sources by entity ID and app ID'},
        {'Section': '', 'Detail': ''},
        {'Section': 'Step 2: Issue Identification', 'Detail': 'Identified four categories of issues:'},
        {'Section': '  Observation 1', 'Detail': 'Ghost Apps - apps in KPAs not mapped to entity'},
        {'Section': '  Observation 2', 'Detail': 'Primary apps not tagged as Key'},
        {'Section': '  Observation 3', 'Detail': 'Secondary apps not tagged as Key (methodology violation)'},
        {'Section': '  Observation 4', 'Detail': 'Automation failures - Key apps but no risk'},
        {'Section': '', 'Detail': ''},
        {'Section': 'Step 3: ARA Validation', 'Detail': 'For each issue, validated impact using ARA scores:'},
        {'Section': '  IT Risk Calculation', 'Detail': 'max(Availability, Integrity) across apps'},
        {'Section': '  IS Risk Calculation', 'Detail': 'max(Confidentiality) across apps'},
        {'Section': '  Comparison Logic', 'Detail': 'Compared to CURRENT system risk (not expected)'},
        {'Section': '', 'Detail': ''},
        {'Section': 'Step 4: Impact Assessment', 'Detail': 'Categorized findings:'},
        {'Section': '  Ghost Apps', 'Detail': 'POSSIBLY MISSTATED (wrong apps - cannot validate without correct apps)'},
        {'Section': '  Apps Not Key', 'Detail': 'POSSIBLY UNDERSTATED (when untagged apps have higher risk than current)'},
        {'Section': '  Apps Not Key', 'Detail': 'APPEARS CORRECT (when untagged apps have same/lower risk)'},
        {'Section': '', 'Detail': ''},
        {'Section': '=' * 70, 'Detail': ''},
        {'Section': 'KEY ASSUMPTIONS AND LIMITATIONS', 'Detail': ''},
        {'Section': '=' * 70, 'Detail': ''},
        {'Section': '', 'Detail': ''},
        {'Section': 'Assumption 1', 'Detail': 'ARA scores are current and accurate'},
        {'Section': 'Assumption 2', 'Detail': 'Application mappings in source file are correct'},
        {'Section': 'Assumption 3', 'Detail': 'Risk values Critical/High/Medium/Low indicate applicable risk'},
        {'Section': '', 'Detail': ''},
        {'Section': 'Limitation 1', 'Detail': 'Cannot determine which apps SHOULD be Key without business context'},
        {'Section': 'Limitation 2', 'Detail': 'Cannot identify correct apps for ghost apps without investigation'},
        {'Section': 'Limitation 3', 'Detail': 'Comparison is against CURRENT system risk (which may itself be wrong)'},
        {'Section': '', 'Detail': ''},
        {'Section': 'Language Used', 'Detail': '"Possibly misstated" - acknowledges lack of full context'},
        {'Section': '', 'Detail': '"Possibly understated" - ARA shows higher risk, but may have valid reasons'},
        {'Section': '', 'Detail': '"Appears correct" - based on current data, no indication of issue'},
        {'Section': '', 'Detail': ''},
        {'Section': '=' * 70, 'Detail': ''},
        {'Section': 'OBSERVATIONS SUMMARY', 'Detail': ''},
        {'Section': '=' * 70, 'Detail': ''},
        {'Section': '', 'Detail': ''},
        {'Section': 'Observation 1: Ghost Applications', 'Detail': ''},
        {'Section': '  Entities', 'Detail': len(ghost_entities) if len(ghost_entities) > 0 else 0},
        {'Section': '  Assessment', 'Detail': 'All: Possibly Misstated'},
        {'Section': '  Detail File', 'Detail': OUTPUT_OBSERVATION_1 if len(ghost_entities) > 0 else 'N/A'},
        {'Section': '', 'Detail': ''},
        {'Section': 'Observation 2: Primary Apps Not Key', 'Detail': ''},
        {'Section': '  Entities', 'Detail': len(primary_issue) if len(primary_issue) > 0 else 0},
        {'Section': '  Possibly Understated', 'Detail': primary_higher_either},
        {'Section': '  Appears Correct', 'Detail': len(primary_issue) - primary_higher_either if len(primary_issue) > 0 else 0},
        {'Section': '  Detail File', 'Detail': OUTPUT_OBSERVATION_2 if len(primary_issue) > 0 else 'N/A'},
        {'Section': '', 'Detail': ''},
        {'Section': 'Observation 3: Secondary Apps Not Key', 'Detail': ''},
        {'Section': '  Entities', 'Detail': len(secondary_issue) if len(secondary_issue) > 0 else 0},
        {'Section': '  Possibly Understated', 'Detail': secondary_higher_either},
        {'Section': '  Appears Correct', 'Detail': len(secondary_issue) - secondary_higher_either if len(secondary_issue) > 0 else 0},
        {'Section': '  Detail File', 'Detail': OUTPUT_OBSERVATION_3 if len(secondary_issue) > 0 else 'N/A'},
        {'Section': '', 'Detail': ''},
        {'Section': 'Observation 4: Automation Failures', 'Detail': ''},
        {'Section': '  Entities', 'Detail': len(all_auto_fail) if len(all_auto_fail) > 0 else 0},
        {'Section': '  Assessment', 'Detail': 'Risk missing when it should exist'},
        {'Section': '  Detail File', 'Detail': OUTPUT_OBSERVATION_4 if len(all_auto_fail) > 0 else 'N/A'},
        {'Section': '', 'Detail': ''},
        {'Section': '=' * 70, 'Detail': ''},
        {'Section': 'REPERFORMANCE INSTRUCTIONS', 'Detail': ''},
        {'Section': '=' * 70, 'Detail': ''},
        {'Section': '', 'Detail': ''},
        {'Section': 'To reperform this entire analysis:', 'Detail': ''},
        {'Section': '', 'Detail': ''},
        {'Section': '1. Obtain Source Files', 'Detail': ''},
        {'Section': '   •', 'Detail': methodology_doc['risks_file']},
        {'Section': '   •', 'Detail': methodology_doc['kpa_file']},
        {'Section': '   •', 'Detail': methodology_doc['ara_file']},
        {'Section': '', 'Detail': ''},
        {'Section': '2. Verify File Structure', 'Detail': ''},
        {'Section': '   • Ensure column names match configuration in script', 'Detail': ''},
        {'Section': '   • Verify data types (IDs as text, risks as text)', 'Detail': ''},
        {'Section': '   • Check for expected number of records', 'Detail': ''},
        {'Section': '', 'Detail': ''},
        {'Section': '3. Run Python Script', 'Detail': ''},
        {'Section': '   • Script name', 'Detail': '[To be filled in]'},
        {'Section': '   • Script version', 'Detail': 'v1.0 - ' + methodology_doc['analysis_date']},
        {'Section': '   • Python version', 'Detail': '3.7 or higher'},
        {'Section': '   • Required libraries', 'Detail': 'pandas, openpyxl'},
        {'Section': '', 'Detail': ''},
        {'Section': '4. Review Outputs', 'Detail': ''},
        {'Section': '   •', 'Detail': OUTPUT_EXECUTIVE_SUMMARY + ' (this file)'},
        {'Section': '   •', 'Detail': OUTPUT_OBSERVATION_1 + ' (if ghost apps found)'},
        {'Section': '   •', 'Detail': OUTPUT_OBSERVATION_2 + ' (if Primary not Key found)'},
        {'Section': '   •', 'Detail': OUTPUT_OBSERVATION_3 + ' (if Secondary not Key found)'},
        {'Section': '   •', 'Detail': OUTPUT_OBSERVATION_4 + ' (if automation failures found)'},
        {'Section': '   •', 'Detail': OUTPUT_FULL_ANALYSIS + ' (complete dataset)'},
        {'Section': '', 'Detail': ''},
        {'Section': '5. Compare Results', 'Detail': ''},
        {'Section': '   • Check entity counts match', 'Detail': ''},
        {'Section': '   • Verify issue counts match', 'Detail': ''},
        {'Section': '   • Spot-check specific entities', 'Detail': ''},
        {'Section': '', 'Detail': ''},
        {'Section': 'Script Logic', 'Detail': 'See individual Observation files for detailed step-by-step methodology'},
    ])
    exec_methodology.to_excel(writer, sheet_name='Methodology', index=False)
    
    # ========== EXECUTIVE SUMMARY TAB ==========
    exec_summary = pd.DataFrame([
        {'Metric': 'IT/IS RISK APPLICABILITY ANALYSIS', 'Value': '', 'Details': ''},
        {'Metric': 'EXECUTIVE SUMMARY (ARA-Validated)', 'Value': '', 'Details': ''},
        {'Metric': 'Comparison: Apps vs CURRENT SYSTEM RISK', 'Value': '', 'Details': ''},
        {'Metric': '', 'Value': '', 'Details': ''},
        {'Metric': 'Analysis Date', 'Value': methodology_doc['analysis_date'], 'Details': ''},
        {'Metric': 'Scope', 'Value': len(summary_df), 'Details': 'audit entities analyzed'},
        {'Metric': '', 'Value': '', 'Details': ''},
        {'Metric': 'OBSERVATION 1: Ghost Applications', 'Value': '', 'Details': 'CRITICAL'},
        {'Metric': '└─ Entities affected', 'Value': len(ghost_entities) if len(ghost_entities) > 0 else 0, 'Details': f"{len(ghost_entities)/len(summary_df)*100:.1f}%" if len(ghost_entities) > 0 else '0%'},
        {'Metric': '└─ Total ghost apps', 'Value': int(total_ghost_apps) if len(ghost_entities) > 0 else 0, 'Details': ''},
        {'Metric': '└─ Risk Assessment', 'Value': len(ghost_entities) if len(ghost_entities) > 0 else 0, 'Details': 'POSSIBLY MISSTATED (wrong apps)'},
        {'Metric': '', 'Value': '', 'Details': ''},
        {'Metric': 'OBSERVATION 2: Primary Apps Not Key', 'Value': '', 'Details': 'HIGH'},
        {'Metric': '└─ Entities affected', 'Value': len(primary_issue) if len(primary_issue) > 0 else 0, 'Details': f"{len(primary_issue)/len(summary_df)*100:.1f}%" if len(primary_issue) > 0 else '0%'},
        {'Metric': '└─ Total Primary apps not Key', 'Value': int(total_primary_not_key) if len(primary_issue) > 0 else 0, 'Details': ''},
        {'Metric': '└─ ARA: Possibly understated', 'Value': primary_higher_either, 'Details': 'higher risk than current'},
        {'Metric': '└─ ARA: Appears correct', 'Value': len(primary_issue) - primary_higher_either if len(primary_issue) > 0 else 0, 'Details': 'same/lower risk'},
        {'Metric': '', 'Value': '', 'Details': ''},
        {'Metric': 'OBSERVATION 3: Secondary Apps Not Key', 'Value': '', 'Details': 'HIGH'},
        {'Metric': '└─ Entities affected', 'Value': len(secondary_issue) if len(secondary_issue) > 0 else 0, 'Details': f"{len(secondary_issue)/len(summary_df)*100:.1f}%" if len(secondary_issue) > 0 else '0%'},
        {'Metric': '└─ Total Secondary apps not Key', 'Value': int(total_secondary_not_key) if len(secondary_issue) > 0 else 0, 'Details': 'methodology violation'},
        {'Metric': '└─ ARA: Possibly understated', 'Value': secondary_higher_either, 'Details': 'higher risk than current'},
        {'Metric': '└─ ARA: Appears correct', 'Value': len(secondary_issue) - secondary_higher_either if len(secondary_issue) > 0 else 0, 'Details': 'same/lower risk'},
        {'Metric': '', 'Value': '', 'Details': ''},
        {'Metric': 'OBSERVATION 4: Automation Failures', 'Value': '', 'Details': 'HIGH'},
        {'Metric': '└─ Entities affected', 'Value': len(all_auto_fail) if len(all_auto_fail) > 0 else 0, 'Details': 'Key apps but no risk'},
        {'Metric': '', 'Value': '', 'Details': ''},
        {'Metric': 'TOTAL ENTITIES WITH ANY ISSUE', 'Value': len(summary_df[summary_df['ANY ISSUE']]), 'Details': f"{len(summary_df[summary_df['ANY ISSUE']])/len(summary_df)*100:.1f}%"},
        {'Metric': '', 'Value': '', 'Details': ''},
        {'Metric': 'ARA-VALIDATED IMPACT SUMMARY', 'Value': '', 'Details': ''},
        {'Metric': '└─ Possibly misstated (ghost apps)', 'Value': len(ghost_entities), 'Details': 'entities'},
        {'Metric': '└─ Possibly understated (Primary not Key)', 'Value': primary_higher_either, 'Details': 'entities'},
        {'Metric': '└─ Possibly understated (Secondary not Key)', 'Value': secondary_higher_either, 'Details': 'entities'},
        {'Metric': 'TOTAL POSSIBLY MISSTATED RISK', 'Value': possibly_misstated_either, 'Details': f"{possibly_misstated_either/len(summary_df)*100:.1f}%"},
        {'Metric': '', 'Value': '', 'Details': ''},
        {'Metric': 'See "Methodology" tab', 'Value': 'For complete analysis documentation', 'Details': ''},
    ])
    exec_summary.to_excel(writer, sheet_name='Executive Summary', index=False)
    
    # ========== OBSERVATION COMPARISON TAB ==========
    obs_comparison = pd.DataFrame([
        {
            'Observation': '1 - Ghost Apps',
            'Severity': 'CRITICAL',
            'Entities': len(ghost_entities) if len(ghost_entities) > 0 else 0,
            '% of Total': f"{len(ghost_entities)/len(summary_df)*100:.1f}%" if len(ghost_entities) > 0 else '0%',
            'Apps Affected': int(total_ghost_apps) if len(ghost_entities) > 0 else 0,
            'ARA Assessment': f"All {len(ghost_entities)} POSSIBLY MISSTATED (wrong apps)" if len(ghost_entities) > 0 else 'None',
            'File': OUTPUT_OBSERVATION_1 if len(ghost_entities) > 0 else 'N/A'
        },
        {
            'Observation': '2 - Primary Not Key',
            'Severity': 'HIGH',
            'Entities': len(primary_issue) if len(primary_issue) > 0 else 0,
            '% of Total': f"{len(primary_issue)/len(summary_df)*100:.1f}%" if len(primary_issue) > 0 else '0%',
            'Apps Affected': int(total_primary_not_key) if len(primary_issue) > 0 else 0,
            'ARA Assessment': f"{primary_higher_either} possibly understated, {len(primary_issue) - primary_higher_either if len(primary_issue) > 0 else 0} appear correct" if len(primary_issue) > 0 else 'None',
            'File': OUTPUT_OBSERVATION_2 if len(primary_issue) > 0 else 'N/A'
        },
        {
            'Observation': '3 - Secondary Not Key',
            'Severity': 'HIGH',
            'Entities': len(secondary_issue) if len(secondary_issue) > 0 else 0,
            '% of Total': f"{len(secondary_issue)/len(summary_df)*100:.1f}%" if len(secondary_issue) > 0 else '0%',
            'Apps Affected': int(total_secondary_not_key) if len(secondary_issue) > 0 else 0,
            'ARA Assessment': f"{secondary_higher_either} possibly understated, {len(secondary_issue) - secondary_higher_either if len(secondary_issue) > 0 else 0} appear correct" if len(secondary_issue) > 0 else 'None',
            'File': OUTPUT_OBSERVATION_3 if len(secondary_issue) > 0 else 'N/A'
        },
        {
            'Observation': '4 - Automation Failures',
            'Severity': 'HIGH',
            'Entities': len(all_auto_fail) if len(all_auto_fail) > 0 else 0,
            '% of Total': f"{len(all_auto_fail)/len(summary_df)*100:.1f}%" if len(all_auto_fail) > 0 else '0%',
            'Apps Affected': int(primary_auto_fail['Primary Key Apps'].sum() + secondary_auto_fail['Secondary Key Apps'].sum()) if len(all_auto_fail) > 0 else 0,
            'ARA Assessment': 'Risk should exist but missing',
            'File': OUTPUT_OBSERVATION_4 if len(all_auto_fail) > 0 else 'N/A'
        }
    ])
    obs_comparison.to_excel(writer, sheet_name='Observation Comparison', index=False)
    
    # ========== BY TEAM AND LEADER TAB ==========
    if RISKS_CORE_TEAM_ACTUAL and RISKS_AUDIT_LEADER_ACTUAL:
        team_leader_summary = summary_df.groupby(['Core Audit Team', 'Audit Leader']).agg({
            'Audit Entity ID': 'count',
            'CRITICAL: Ghost Apps': 'sum',
            'HIGH: Primary Not Key': 'sum',
            'HIGH: Secondary Not Key': 'sum',
            'Primary Key Auto Failure': 'sum',
            'Secondary Key Auto Failure': 'sum',
            'Ghost Apps Present': 'sum',
            'Primary Not Key: Higher than Current IT': 'sum',
            'Primary Not Key: Higher than Current IS': 'sum',
            'Secondary Not Key: Higher than Current IT': 'sum',
            'Secondary Not Key: Higher than Current IS': 'sum'
        }).reset_index()
        
        team_leader_summary.columns = [
            'Core Audit Team',
            'Audit Leader',
            'Total Entities',
            'Ghost Apps',
            'Primary Not Key',
            'Secondary Not Key',
            'Primary Auto Fail',
            'Secondary Auto Fail',
            'Ghost: Possibly Misstated',
            'Primary: Higher IT (ARA)',
            'Primary: Higher IS (ARA)',
            'Secondary: Higher IT (ARA)',
            'Secondary: Higher IS (ARA)'
        ]
        
        team_leader_summary['Total Issues'] = (
            team_leader_summary['Ghost Apps'] +
            team_leader_summary['Primary Not Key'] +
            team_leader_summary['Secondary Not Key'] +
            team_leader_summary['Primary Auto Fail'] +
            team_leader_summary['Secondary Auto Fail']
        )
        
        team_leader_summary['ARA: Possibly Misstated'] = (
            team_leader_summary['Ghost: Possibly Misstated'] +
            team_leader_summary['Primary: Higher IT (ARA)'] +
            team_leader_summary['Primary: Higher IS (ARA)'] +
            team_leader_summary['Secondary: Higher IT (ARA)'] +
            team_leader_summary['Secondary: Higher IS (ARA)']
        )
        
        team_leader_summary['% Entities With Issues'] = round((team_leader_summary['Total Issues'] / team_leader_summary['Total Entities']) * 100, 1)
        
        team_leader_summary = team_leader_summary.sort_values(['Core Audit Team', 'ARA: Possibly Misstated'], ascending=[True, False])
        
        team_leader_summary.to_excel(writer, sheet_name='By Team and Leader', index=False)
    
    elif RISKS_CORE_TEAM_ACTUAL:
        team_summary = summary_df.groupby('Core Audit Team').agg({
            'Audit Entity ID': 'count',
            'CRITICAL: Ghost Apps': 'sum',
            'HIGH: Primary Not Key': 'sum',
            'HIGH: Secondary Not Key': 'sum',
            'Primary Key Auto Failure': 'sum',
            'Secondary Key Auto Failure': 'sum',
            'Ghost Apps Present': 'sum',
            'Primary Not Key: Higher than Current IT': 'sum',
            'Primary Not Key: Higher than Current IS': 'sum',
            'Secondary Not Key: Higher than Current IT': 'sum',
            'Secondary Not Key: Higher than Current IS': 'sum'
        }).reset_index()
        
        team_summary.columns = [
            'Core Audit Team',
            'Total Entities',
            'Ghost Apps',
            'Primary Not Key',
            'Secondary Not Key',
            'Primary Auto Fail',
            'Secondary Auto Fail',
            'Ghost: Possibly Misstated',
            'Primary: Higher IT (ARA)',
            'Primary: Higher IS (ARA)',
            'Secondary: Higher IT (ARA)',
            'Secondary: Higher IS (ARA)'
        ]
        
        team_summary['Total Issues'] = (
            team_summary['Ghost Apps'] +
            team_summary['Primary Not Key'] +
            team_summary['Secondary Not Key'] +
            team_summary['Primary Auto Fail'] +
            team_summary['Secondary Auto Fail']
        )
        
        team_summary['ARA: Possibly Misstated'] = (
            team_summary['Ghost: Possibly Misstated'] +
            team_summary['Primary: Higher IT (ARA)'] +
            team_summary['Primary: Higher IS (ARA)'] +
            team_summary['Secondary: Higher IT (ARA)'] +
            team_summary['Secondary: Higher IS (ARA)']
        )
        
        team_summary['% Entities With Issues'] = round((team_summary['Total Issues'] / team_summary['Total Entities']) * 100, 1)
        
        team_summary = team_summary.sort_values('ARA: Possibly Misstated', ascending=False)
        
        team_summary.to_excel(writer, sheet_name='By Team', index=False)

print(f"✓ {OUTPUT_EXECUTIVE_SUMMARY}")

# =============================================================================
# EXPORT FULL ANALYSIS (SOURCE DATA)
# =============================================================================

# Reorder columns for better readability
cols_order = [
    'Audit Entity ID',
    'Core Audit Team',
    'Audit Leader',
    
    # Flags
    'CRITICAL: Ghost Apps',
    'HIGH: Primary Not Key',
    'HIGH: Secondary Not Key',
    'ANY ISSUE',
    
    # Issue counts
    '# Ghost Apps (Key but Not Mapped)',
    '# Primary Apps Not Key',
    '# Secondary Apps Not Key',
    
    # Current risk
    'Current IT Risk',
    'Current IS Risk',
    'Any IT/IS Risk Applicable',
    
    # Risk assessments
    'IT Risk Assessment',
    'IS Risk Assessment',
    'Possibly Misstated IT Risk',
    'Possibly Misstated IS Risk',
    
    # ARA comparison results
    'Primary Not Key: Higher than Current IT',
    'Primary Not Key: Higher than Current IS',
    'Secondary Not Key: Higher than Current IT',
    'Secondary Not Key: Higher than Current IS',
    'ALL Mapped Apps: Higher than Current IT',
    'ALL Mapped Apps: Higher than Current IS',
    
    # Risk from different app sets
    'Risk from Key Apps (incl ghosts)',
    'IS Risk from Key Apps (incl ghosts)',
    'Risk from ALL Mapped Apps',
    'IS Risk from ALL Mapped Apps',
    'Ghost Apps IT Risk',
    'Ghost Apps IS Risk',
    'Primary Not Key IT Risk',
    'Primary Not Key IS Risk',
    'Secondary Not Key IT Risk',
    'Secondary Not Key IS Risk',
    
    # App counts
    'Total Primary Apps',
    'Total Secondary Apps',
    'Total Mapped Apps',
    'Primary Key Apps',
    'Secondary Key Apps',
    'Total Key Apps',
    
    # Detail columns
    'Ghost App IDs',
    'Primary Not Key IDs',
    'Secondary Not Key IDs',
    'Key App Driving IT (incl ghosts)',
    'Key App Driving IS (incl ghosts)',
]

# Add remaining columns not in the order list
remaining_cols = [col for col in summary_df.columns if col not in cols_order]
summary_df_export = summary_df[cols_order + remaining_cols]

summary_df_export.to_excel(OUTPUT_FULL_ANALYSIS, index=False)
print(f"✓ {OUTPUT_FULL_ANALYSIS}")

# =============================================================================
# FINAL SUMMARY
# =============================================================================

print("\n" + "="*70)
print("ANALYSIS COMPLETE")
print("="*70)
print(f"\n📊 Files Created:")
print(f"   {OUTPUT_EXECUTIVE_SUMMARY} ← Start here (includes Methodology)")
if len(ghost_entities) > 0:
    print(f"   {OUTPUT_OBSERVATION_1} (Methodology tab included)")
if len(primary_issue) > 0:
    print(f"   {OUTPUT_OBSERVATION_2} (Methodology tab included)")
if len(secondary_issue) > 0:
    print(f"   {OUTPUT_OBSERVATION_3} (Methodology tab included)")
if len(all_auto_fail) > 0:
    print(f"   {OUTPUT_OBSERVATION_4} (Methodology tab included)")
print(f"   {OUTPUT_FULL_ANALYSIS} (Complete dataset)")

print(f"\n📁 Each observation file contains:")
print(f"   - Methodology tab (FIRST - documents what was reviewed)")
print(f"   - Summary tab (key metrics)")
print(f"   - Analysis tabs (all data, ARA validation, samples)")
if RISKS_CORE_TEAM_ACTUAL and RISKS_AUDIT_LEADER_ACTUAL:
    print(f"   - By Team and Leader tab (accountability)")
elif RISKS_CORE_TEAM_ACTUAL:
    print(f"   - By Team tab (distribution)")

print(f"\n✓ METHODOLOGY DOCUMENTED")
print(f"   All files include complete reperformance instructions")
print(f"   Data sources, analysis steps, and interpretation documented")
print(f"   Audit-ready workpaper trail")

print(f"\n✓ ARA VALIDATION COMPLETE")
print(f"   Comparison: Apps vs CURRENT SYSTEM RISK")
print(f"   Ghost apps: Possibly misstated (unknown correct apps)")
print(f"   Untagged apps: Possibly understated when higher than current")
print(f"   {possibly_misstated_either} entities with possibly misstated risk")
print(f"   IT and IS tracked separately throughout")

print(f"\n📋 TO REPERFORM THIS ANALYSIS:")
print(f"   1. See 'Methodology' tab in {OUTPUT_EXECUTIVE_SUMMARY}")
print(f"   2. Follow documented steps with source files")
print(f"   3. Compare results to these outputs")

print("\n" + "="*70)
